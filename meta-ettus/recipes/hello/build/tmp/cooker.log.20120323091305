# do_package_write_deb=None
# ROOT_FLASH_SIZE=280
ROOT_FLASH_SIZE="280"
# STAGING_BINDIR_CROSS=${STAGING_BINDIR}/crossscripts
STAGING_BINDIR_CROSS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin/crossscripts"
# SDK_PACKAGE_ARCHS=all any noarch ${SDK_ARCH}-nativesdk
SDK_PACKAGE_ARCHS="all any noarch x86_64-nativesdk"
# localstatedir=${base_prefix}/var
export localstatedir="/var"
# STAGING_INCDIR_NATIVE=${STAGING_DIR_NATIVE}${includedir_native}
STAGING_INCDIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/include"
# prefix=/usr
export prefix="/usr"
# FREESMARTPHONE_GIT=git://git.freesmartphone.org
FREESMARTPHONE_GIT="git://git.freesmartphone.org"
# CPP=${HOST_PREFIX}gcc -E${TOOLCHAIN_OPTIONS} ${HOST_CC_ARCH}
export CPP="i586-poky-linux-gcc -E --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86  -m32   -march=i586"
# INHERIT_INSANE=insane
INHERIT_INSANE="insane"
# CVSDIR=${CO_DIR}/cvs
CVSDIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads/cvs"
# BBFILE_COLLECTIONS= normal yocto
BBFILE_COLLECTIONS="normal yocto"
# mandir=${datadir}/man
export mandir="/usr/share/man"
# PREFERRED_VERSION_gcc-cross-intermediate=${GCCVERSION}
PREFERRED_VERSION_gcc-cross-intermediate="4.6%"
# bindir_cross=/bin
bindir_cross="/bin"
# HOST_CC_ARCH=${TARGET_CC_ARCH}
HOST_CC_ARCH="-m32   -march=i586"
# BASEDEPENDS=${@base_dep_prepend(d)}
BASEDEPENDS="virtual/i586-poky-linux-gcc virtual/i586-poky-linux-compilerlibs virtual/libc"
# PREFERRED_PROVIDER_libgcc-nativesdk=libgcc-nativesdk
PREFERRED_PROVIDER_libgcc-nativesdk="libgcc-nativesdk"
# FAKEROOTDIRS=${PSEUDO_LOCALSTATEDIR}
FAKEROOTDIRS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/pseudo/"
# BB_CONSOLELOG=${TMPDIR}/cooker.log.${DATETIME}
BB_CONSOLELOG="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/cooker.log.20120323091305"
# TUNE_PKGARCH_TMP=${@bb.utils.contains("TUNE_FEATURES", "m32", "x86", "x86_64", d)}
TUNE_PKGARCH_TMP="x86"
# STRIP=${HOST_PREFIX}strip
export STRIP="i586-poky-linux-strip"
# STAGING_DATADIR=${STAGING_DIR_HOST}${datadir}
STAGING_DATADIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/share"
# target_datadir=/usr/share
target_datadir="/usr/share"
# USE_PR_SERV=${@[1,0][((not d.getVar('PRSERV_HOST', True)) or (not d.getVar('PRSERV_PORT', True))) and (not d.getVar('PRSERV_LOCKDOWN', True))]}
USE_PR_SERV="0"
# CCACHE=${@bb.which(d.getVar('PATH', True), 'ccache') and 'ccache '}
CCACHE="ccache"
# IMAGE_ROOTFS=${WORKDIR}/rootfs
IMAGE_ROOTFS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs"
# FETCHCOMMAND_cvs=/usr/bin/env cvs '-d${CVSROOT}' co ${CVSCOOPTS} ${CVSMODULE}
FETCHCOMMAND_cvs="/usr/bin/env cvs '-d${CVSROOT}' co ${CVSCOOPTS} ${CVSMODULE}"
# base_bindir_native=/bin
base_bindir_native="/bin"
# DEPENDS=${BASEDEPENDS} 
DEPENDS="virtual/i586-poky-linux-gcc virtual/i586-poky-linux-compilerlibs virtual/libc"
# BASE_LIB_tune-x86-64-x32=libx32
BASE_LIB_tune-x86-64-x32="libx32"
# KERNELORG_MIRROR=http://kernel.org/pub
KERNELORG_MIRROR="http://kernel.org/pub"
# SECTION_${PN}-dbg=devel
SECTION_bblayers-dbg="devel"
# DATETIME=${DATE}${TIME}
DATETIME="20120323091305"
# P=${PN}-${PV}
P="bblayers-1.0"
# SOLIBS_darwin9=.*.dylib
SOLIBS_darwin9=".*.dylib"
# FILESPATH=${@base_set_filespath([ "${FILE_DIRNAME}/${PF}", "${FILE_DIRNAME}/${P}", "${FILE_DIRNAME}/${PN}", "${FILE_DIRNAME}/${BP}", "${FILE_DIRNAME}/${BPN}", "${FILE_DIRNAME}/files", "${FILE_DIRNAME}" ], d)}
FILESPATH="/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0-r0/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers-1.0/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/files/:/media/OE/poky/meta-ettus/recipes/hello/build/conf/linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/i586:/media/OE/poky/meta-ettus/recipes/hello/build/conf/build-linux:/media/OE/poky/meta-ettus/recipes/hello/build/conf/pn-bblayers:/media/OE/poky/meta-ettus/recipes/hello/build/conf/qemux86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/x86:/media/OE/poky/meta-ettus/recipes/hello/build/conf/poky:/media/OE/poky/meta-ettus/recipes/hello/build/conf/forcevariable:/media/OE/poky/meta-ettus/recipes/hello/build/conf/libc-glibc:/media/OE/poky/meta-ettus/recipes/hello/build/conf/"
# IMAGE_FEATURES= ${EXTRA_IMAGE_FEATURES}
IMAGE_FEATURES="debug-tweaks"
# DEPLOY_DIR_TOOLS=${DEPLOY_DIR}/tools
DEPLOY_DIR_TOOLS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/tools"
# TUNE_ARCH=${@bb.utils.contains("TUNE_FEATURES", "m32", "${X86ARCH32}", "" ,d)}${@bb.utils.contains("TUNE_FEATURES", "mx32", "${X86ARCH64}", "" ,d)}${@bb.utils.contains("TUNE_FEATURES", "m64", "${X86ARCH64}", "" ,d)}
TUNE_ARCH="i586"
# QADEPENDS=prelink-native
QADEPENDS="prelink-native"
# WHITELIST_GPLv3=less
WHITELIST_GPLv3="less"
# E_SVN=svn://svn.enlightenment.org/svn/e
E_SVN="svn://svn.enlightenment.org/svn/e"
# PSEUDO_PASSWD=${STAGING_DIR_TARGET}
PSEUDO_PASSWD="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# BUILD_CXXFLAGS=${BUILD_CFLAGS} -fpermissive
export BUILD_CXXFLAGS="-isystem/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/include -O2 -pipe -fpermissive"
# STAGING_DIR_TCBOOTSTRAP=${STAGING_DIR_TARGET}-tcbootstrap
STAGING_DIR_TCBOOTSTRAP="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86-tcbootstrap"
# OBJCOPY=${HOST_PREFIX}objcopy
export OBJCOPY="i586-poky-linux-objcopy"
# TUNE_FEATURES_tune-x86=m32
TUNE_FEATURES_tune-x86="m32"
# FAKEROOTENV=PSEUDO_PREFIX=${STAGING_DIR_NATIVE}${prefix_native} PSEUDO_LOCALSTATEDIR=${PSEUDO_LOCALSTATEDIR} PSEUDO_PASSWD=${PSEUDO_PASSWD} PSEUDO_NOSYMLINKEXP=1 PSEUDO_DISABLED=0
FAKEROOTENV="PSEUDO_PREFIX=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr PSEUDO_LOCALSTATEDIR=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/pseudo/ PSEUDO_PASSWD=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86 PSEUDO_NOSYMLINKEXP=1 PSEUDO_DISABLED=0"
# PREFERRED_VERSION_cross-localedef-native=${EGLIBCVERSION}
PREFERRED_VERSION_cross-localedef-native="2.13"
# PALMTOP_USE_MULTITHREADED_QT=None
# SOLIBSDEV_darwin8=.dylib
SOLIBSDEV_darwin8=".dylib"
# SOLIBSDEV_darwin9=.dylib
SOLIBSDEV_darwin9=".dylib"
# USER=mmoselhy
export USER="mmoselhy"
# SRC_URI=
# SSTATEPOSTINSTFUNCS=
# includedir_native=${prefix_native}/include
includedir_native="/usr/include"
# OES_BITBAKE_CONF=1
OES_BITBAKE_CONF="1"
# QADEPENDS_virtclass-nativesdk=
# SUMMARY_${PN}-doc=${SUMMARY} - Documentation files
SUMMARY_bblayers-doc="bblayers version 1.0-r0 - Documentation files"
# SYSROOT_PREPROCESS_FUNCS=
# MACHINE_EXTRA_RRECOMMENDS=
# STAGING_BINDIR=${STAGING_DIR_HOST}${bindir}
STAGING_BINDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin"
# SVNDIR=${CO_DIR}/svn
SVNDIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads/svn"
# PREFERRED_PROVIDER_dbus-glib-native=dbus-glib-native
PREFERRED_PROVIDER_dbus-glib-native="dbus-glib-native"
# UPDATECOMMAND=ERROR, this must be a BitBake bug
UPDATECOMMAND="ERROR, this must be a BitBake bug"
# XSERVER=xserver-xorg mesa-dri-driver-swrast xf86-input-vmmouse xf86-input-keyboard xf86-input-evdev xf86-video-vmware qemugl
XSERVER="xserver-xorg mesa-dri-driver-swrast xf86-input-vmmouse xf86-input-keyboard xf86-input-evdev xf86-video-vmware qemugl"
# EXTENDPE=${@['','${PE\x7d_'][d.getVar('PE',1) > 0]}
# FILESDIR=${@bb.which(d.getVar('FILESPATH', True), '.')}
FILESDIR="/media/OE/poky/meta-ettus/recipes/hello/build/conf/."
# PREFERRED_VERSION_gcc-cross-initial=${GCCVERSION}
PREFERRED_VERSION_gcc-cross-initial="4.6%"
# BBINCLUDED=/media/OE/poky/meta-ettus/recipes/hello/build/conf/local.conf /media/OE/poky/meta/classes/image-prelink.bbclass /media/OE/poky/meta/classes/packagedata.bbclass /media/OE/poky/meta/conf/machine/include/qemu.inc /media/OE/poky/meta/conf/distro/include/as-needed.inc /media/OE/poky/meta/classes/mirrors.bbclass /media/OE/poky/meta/conf/distro/include/default-providers.inc /media/OE/poky/meta-yocto/conf/abi_version.conf /media/OE/poky/meta/conf/sanity.conf /media/OE/poky/meta/conf/machine/qemux86.conf /media/OE/poky/meta/classes/debian.bbclass /media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers.conf /media/OE/poky/meta/classes/logging.bbclass /media/OE/poky/meta/conf/documentation.conf /media/OE/poky/meta/classes/terminal.bbclass /media/OE/poky/meta-yocto/conf/distro/poky.conf /media/OE/poky/meta/classes/utility-tasks.bbclass /media/OE/poky/meta/conf/distro/include/world-broken.inc /media/OE/poky/meta/conf/layer.conf /media/OE/poky/meta/classes/metadata_scm.bbclass /media/OE/poky/meta/conf/machine/include/ia32/arch-ia32.inc /media/OE/poky/meta/classes/package.bbclass /media/OE/poky/meta/conf/machine/include/tune-i586.inc /media/OE/poky/meta/conf/distro/include/tcmode-default.inc /media/OE/poky/meta/classes/patch.bbclass /media/OE/poky/meta/classes/staging.bbclass /media/OE/poky/meta/classes/devshell.bbclass /media/OE/poky/meta/conf/distro/defaultsetup.conf /media/OE/poky/meta/classes/insane.bbclass /media/OE/poky/meta-yocto/conf/layer.conf /media/OE/poky/meta/classes/image-mklibs.bbclass /media/OE/poky/meta/classes/sanity.bbclass /media/OE/poky/meta/classes/base.bbclass /media/OE/poky/meta/conf/distro/include/default-versions.inc /media/OE/poky/meta/conf/distro/include/default-distrovars.inc /media/OE/poky/meta/classes/sstate.bbclass /media/OE/poky/meta/conf/bitbake.conf /media/OE/poky/meta/classes/license.bbclass /media/OE/poky/meta/classes/buildstats.bbclass /media/OE/poky/meta/conf/distro/include/tclibc-eglibc.inc /media/OE/poky/meta/classes/utils.bbclass /media/OE/poky/meta/classes/prserv.bbclass /media/OE/poky/meta/classes/package_rpm.bbclass
BBINCLUDED="/media/OE/poky/meta-ettus/recipes/hello/build/conf/local.conf /media/OE/poky/meta/classes/image-prelink.bbclass /media/OE/poky/meta/classes/packagedata.bbclass /media/OE/poky/meta/conf/machine/include/qemu.inc /media/OE/poky/meta/conf/distro/include/as-needed.inc /media/OE/poky/meta/classes/mirrors.bbclass /media/OE/poky/meta/conf/distro/include/default-providers.inc /media/OE/poky/meta-yocto/conf/abi_version.conf /media/OE/poky/meta/conf/sanity.conf /media/OE/poky/meta/conf/machine/qemux86.conf /media/OE/poky/meta/classes/debian.bbclass /media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers.conf /media/OE/poky/meta/classes/logging.bbclass /media/OE/poky/meta/conf/documentation.conf /media/OE/poky/meta/classes/terminal.bbclass /media/OE/poky/meta-yocto/conf/distro/poky.conf /media/OE/poky/meta/classes/utility-tasks.bbclass /media/OE/poky/meta/conf/distro/include/world-broken.inc /media/OE/poky/meta/conf/layer.conf /media/OE/poky/meta/classes/metadata_scm.bbclass /media/OE/poky/meta/conf/machine/include/ia32/arch-ia32.inc /media/OE/poky/meta/classes/package.bbclass /media/OE/poky/meta/conf/machine/include/tune-i586.inc /media/OE/poky/meta/conf/distro/include/tcmode-default.inc /media/OE/poky/meta/classes/patch.bbclass /media/OE/poky/meta/classes/staging.bbclass /media/OE/poky/meta/classes/devshell.bbclass /media/OE/poky/meta/conf/distro/defaultsetup.conf /media/OE/poky/meta/classes/insane.bbclass /media/OE/poky/meta-yocto/conf/layer.conf /media/OE/poky/meta/classes/image-mklibs.bbclass /media/OE/poky/meta/classes/sanity.bbclass /media/OE/poky/meta/classes/base.bbclass /media/OE/poky/meta/conf/distro/include/default-versions.inc /media/OE/poky/meta/conf/distro/include/default-distrovars.inc /media/OE/poky/meta/classes/sstate.bbclass /media/OE/poky/meta/conf/bitbake.conf /media/OE/poky/meta/classes/license.bbclass /media/OE/poky/meta/classes/buildstats.bbclass /media/OE/poky/meta/conf/distro/include/tclibc-eglibc.inc /media/OE/poky/meta/classes/utils.bbclass /media/OE/poky/meta/classes/prserv.bbclass /media/OE/poky/meta/classes/package_rpm.bbclass"
# SSTATE_VERSION=2
SSTATE_VERSION="2"
# SDK_NAME=${DISTRO}-${TCLIBC}-${SDK_ARCH}-${TARGET_ARCH}
SDK_NAME="poky-eglibc-x86_64-i586"
# OELAYOUT_ABI=8
OELAYOUT_ABI="8"
# TMPDIR=${TOPDIR}/tmp${TCLIBCAPPEND}
TMPDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp"
# PREFERRED_PROVIDER_opkg-nativesdk=opkg-nativesdk
PREFERRED_PROVIDER_opkg-nativesdk="opkg-nativesdk"
# base_libdir_native=/lib
base_libdir_native="/lib"
# QEMU_OPTIONS_iwmmxt=-cpu pxa270-c5
QEMU_OPTIONS_iwmmxt="-cpu pxa270-c5"
# includedir_nativesdk=${prefix_nativesdk}/include
includedir_nativesdk="/usr/include"
# libexecdir=${exec_prefix}/libexec
export libexecdir="/usr/libexec"
# LINKER_HASH_STYLE_mipsel=sysv
LINKER_HASH_STYLE_mipsel="sysv"
# X86ARCH32=i586
X86ARCH32="i586"
# SOURCE_MIRROR_FETCH=None
# SUMMARY_${PN}-staticdev=${SUMMARY} - Development files (Static Libraries)
SUMMARY_bblayers-staticdev="bblayers version 1.0-r0 - Development files (Static Libraries)"
# IMAGE_PKGTYPE=rpm
IMAGE_PKGTYPE="rpm"
# FILES_${PN}-dbg=${@d.getVar(['DOTDEBUG-dbg', 'DEBUGFILEDIRECTORY-dbg'][d.getVar('PACKAGE_DEBUG_SPLIT_STYLE', True) == 'debug-file-directory'], True)}
FILES_bblayers-dbg="/usr/bin/.debug /usr/sbin/.debug /usr/libexec/.debug /usr/lib/.debug /bin/.debug /sbin/.debug /lib/.debug /usr/lib/bblayers/.debug /usr/lib/matchbox-panel/.debug /usr/src/debug"
# servicedir=${base_prefix}/srv
export servicedir="/srv"
# PREFERRED_PROVIDER_linux-libc-headers-nativesdk=linux-libc-headers-nativesdk
PREFERRED_PROVIDER_linux-libc-headers-nativesdk="linux-libc-headers-nativesdk"
# bindir_native=${prefix_native}/bin
bindir_native="/usr/bin"
# BB_MIN_VERSION=1.15.1
BB_MIN_VERSION="1.15.1"
# BUILD_PREFIX=
# HOME=/home/mmoselhy
export HOME="/home/mmoselhy"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}gcc=gcc-cross
PREFERRED_PROVIDER_virtual/i586-poky-linux-gcc="gcc-cross"
# SDK_OS=${BUILD_OS}
SDK_OS="linux"
# COMBINED_FEATURES=${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "alsa", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "bluetooth", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "ext2", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "vfat", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "irda", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "pcmcia", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "pci", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "usbgadget", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "usbhost", d)} ${@base_both_contain("DISTRO_FEATURES", "MACHINE_FEATURES", "wifi", d)}
COMBINED_FEATURES="alsa bluetooth   irda pcmcia  usbgadget"
# GIT_CONFIG=${GIT_CONFIG_PATH}/gitconfig
GIT_CONFIG="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/etc/gitconfig"
# TUNECONFLICT=None
# PYTHON=${@sys.executable}
PYTHON="/usr/bin/python"
# datadir=${prefix}/share
export datadir="/usr/share"
# KERNEL_CONSOLE=ttyS0
KERNEL_CONSOLE="ttyS0"
# STAGING_ETCDIR_NATIVE=${STAGING_DIR_NATIVE}${sysconfdir_native}
STAGING_ETCDIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/etc"
# BUILD_AS_ARCH=
# HOST_EXEEXT=
# SRCDATE=${DATE}
SRCDATE="20120323"
# PREFERRED_VERSION_eglibc-nativesdk=${EGLIBCVERSION}
PREFERRED_VERSION_eglibc-nativesdk="2.13"
# SEPPUKU_PASS=None
# SUMMARY=${PN} version ${PV}-${PR}
SUMMARY="bblayers version 1.0-r0"
# TARGET_CC_ARCH=${TUNE_CCARGS}
TARGET_CC_ARCH="-m32   -march=i586"
# QEMU_OPTIONS_armv6=-cpu arm1136
QEMU_OPTIONS_armv6="-cpu arm1136"
# HOST_ARCH=${TARGET_ARCH}
HOST_ARCH="i586"
# ENABLE_BINARY_LOCALE_GENERATION=1
ENABLE_BINARY_LOCALE_GENERATION="1"
# TARGET_OS=linux${LIBCEXTENSION}${ABIEXTENSION}
TARGET_OS="linux"
# GPEPHONE_MIRROR=http://gpephone.linuxtogo.org/download/gpephone
GPEPHONE_MIRROR="http://gpephone.linuxtogo.org/download/gpephone"
# GPEPHONE_SVN=svn://projects.linuxtogo.org/svn/gpephone/trunk/source;module=${PN}
GPEPHONE_SVN="svn://projects.linuxtogo.org/svn/gpephone/trunk/source;module=bblayers"
# sbindir_native=${prefix_native}/sbin
sbindir_native="/usr/sbin"
# SOLIBS_darwin8=.*.dylib
SOLIBS_darwin8=".*.dylib"
# ASSUME_PROVIDED=bzip2-native grep-native diffstat-native patch-native perl-native-runtime python-native-runtime subversion-native tar-native virtual/libintl-native 
ASSUME_PROVIDED="bzip2-native grep-native diffstat-native patch-native perl-native-runtime python-native-runtime subversion-native tar-native virtual/libintl-native"
# expansion of SRCPV threw ExpansionError: Failure expanding variable SRCPV, expression was ${@bb.fetch2.get_srcrev(d)} which triggered exception FetchError: Fetcher failure: SRCREV was used yet no valid SCM was found in SRC_URI
# QEMU_OPTIONS=
# LICSSTATEDIR=${WORKDIR}/license-destdir/
LICSSTATEDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/license-destdir/"
# ALL_MULTILIB_PACKAGE_ARCHS=${@all_multilib_tune_values(d, 'PACKAGE_ARCHS')}
ALL_MULTILIB_PACKAGE_ARCHS="all any noarch x86 i386 i486 i586 qemux86"
# LCONF_VERSION=4
LCONF_VERSION="4"
# MLPREFIX=
# CONNECTIVITY_CHECK_URIS=git://git.yoctoproject.org/yocto-firewall-test;protocol=git;rev=HEAD https://eula-downloads.yoctoproject.org/index.php http://bugzilla.yoctoproject.org/report.cgi
CONNECTIVITY_CHECK_URIS="git://git.yoctoproject.org/yocto-firewall-test;protocol=git;rev=HEAD https://eula-downloads.yoctoproject.org/index.php http://bugzilla.yoctoproject.org/report.cgi"
# FETCHCMD_hg=/usr/bin/env hg
FETCHCMD_hg="/usr/bin/env hg"
# TUNEVALID=None
# FILES=
# ABIEXTENSION=${@bb.utils.contains("TUNE_FEATURES", "mx32", "x32", "" ,d)}
# IPK_FEED_URIS=None
# BUILD_CXX=${CCACHE}${BUILD_PREFIX}g++ ${BUILD_CC_ARCH}
export BUILD_CXX="ccache g++"
# FULL_OPTIMIZATION=-O2 -pipe ${DEBUG_FLAGS}
FULL_OPTIMIZATION="-O2 -pipe -g -feliminate-unused-debug-types"
# CPU_FEATURES=
# TARGET_AS_ARCH=${TUNE_ASARGS}
TARGET_AS_ARCH=""
# ASNEEDED_pn-console-tools=
# UPDATECOMMAND_cvs=/usr/bin/env cvs -d${CVSROOT} update -d -P ${CVSCOOPTS}
UPDATECOMMAND_cvs="/usr/bin/env cvs -d${CVSROOT} update -d -P ${CVSCOOPTS}"
# PREFERRED_VERSION_python=2.7.2
PREFERRED_VERSION_python="2.7.2"
# FILES_${PN}=${bindir}/* ${sbindir}/* ${libexecdir}/* ${libdir}/lib*${SOLIBS} ${sysconfdir} ${sharedstatedir} ${localstatedir} ${base_bindir}/* ${base_sbindir}/* ${base_libdir}/*${SOLIBS} ${datadir}/${BPN} ${libdir}/${BPN}/* ${datadir}/pixmaps ${datadir}/applications ${datadir}/idl ${datadir}/omf ${datadir}/sounds ${libdir}/bonobo/servers
FILES_bblayers="/usr/bin/* /usr/sbin/* /usr/libexec/* /usr/lib/lib*.so.* /etc /com /var /bin/* /sbin/* /lib/*.so.* /usr/share/bblayers /usr/lib/bblayers/* /usr/share/pixmaps /usr/share/applications /usr/share/idl /usr/share/omf /usr/share/sounds /usr/lib/bonobo/servers"
# MKTEMPCMD=mktemp -q ${TMPBASE}
MKTEMPCMD="mktemp -q ${TMPBASE}"
# DATE=20120323
DATE="20120323"
# APACHE_MIRROR=http://www.apache.org/dist
APACHE_MIRROR="http://www.apache.org/dist"
# do_rootfs=None
# LD=${HOST_PREFIX}ld${TOOLCHAIN_OPTIONS} ${HOST_LD_ARCH}
export LD="i586-poky-linux-ld --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# HOST_VENDOR=${TARGET_VENDOR}
HOST_VENDOR="-poky"
# PACKAGE_EXTRA_ARCHS_tune-x86-64=x86_64
PACKAGE_EXTRA_ARCHS_tune-x86-64="x86_64"
# PATCHRESOLVE=noop
PATCHRESOLVE="noop"
# SSTATE_SCAN_FILES=*.la *-config *_config
SSTATE_SCAN_FILES="*.la *-config *_config"
# LGPLv2_WHITELIST_GPLv3=libassuan gnutls libtasn1 libidn libgcc gcc-runtime
LGPLv2_WHITELIST_GPLv3="libassuan gnutls libtasn1 libidn libgcc gcc-runtime"
# PREFERRED_PROVIDER_gdk-pixbuf=gdk-pixbuf
PREFERRED_PROVIDER_gdk-pixbuf="gdk-pixbuf"
# SSTATE_MANFILEBASE=${SSTATE_MANIFESTS}/manifest-${SSTATE_MANMACH}-
SSTATE_MANFILEBASE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control/manifest-i586-"
# MACHINE_TASK_PROVIDER=${DEFAULT_TASK_PROVIDER}
MACHINE_TASK_PROVIDER="task-base"
# EXTRA_OEMAKE=-e MAKEFLAGS=
EXTRA_OEMAKE="-e MAKEFLAGS="
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}gcc-initial=gcc-cross-initial
PREFERRED_PROVIDER_virtual/i586-poky-linux-gcc-initial="gcc-cross-initial"
# LDFLAGS=${TARGET_LDFLAGS}
export LDFLAGS="-Wl,-O1 -Wl,--hash-style=gnu -Wl,--as-needed"
# HOST_NONSYSV=None
# bindir=${exec_prefix}/bin
export bindir="/usr/bin"
# FREEBSD_MIRROR=ftp://ftp.freebsd.org/pub/FreeBSD/
FREEBSD_MIRROR="ftp://ftp.freebsd.org/pub/FreeBSD/"
# PREFERRED_VERSION_binutils-cross=${BINUVERSION}
PREFERRED_VERSION_binutils-cross="2.22"
# COLORTERM=gnome-terminal
COLORTERM="gnome-terminal"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}binutils=binutils-cross
PREFERRED_PROVIDER_virtual/i586-poky-linux-binutils="binutils-cross"
# SUMMARY_${PN}-dbg=${SUMMARY} - Debugging files
SUMMARY_bblayers-dbg="bblayers version 1.0-r0 - Debugging files"
# HOST_PREFIX=${TARGET_PREFIX}
HOST_PREFIX="i586-poky-linux-"
# LAYER_CONF_VERSION=4
LAYER_CONF_VERSION="4"
# BUILDSTATS_BASE=${TMPDIR}/buildstats/
BUILDSTATS_BASE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/buildstats/"
# SYSVINIT_ENABLED_GETTYS=None
# DISTRO_EXTRA_RRECOMMENDS=  ${POKY_DEFAULT_EXTRA_RRECOMMENDS}
DISTRO_EXTRA_RRECOMMENDS="kernel-module-af-packet"
# LC_ALL=C
export LC_ALL="C"
# SOLIBSDEV=.so
SOLIBSDEV=".so"
# BUILD_ARCH=${@os.uname()[4]}
BUILD_ARCH="x86_64"
# PKGD=${WORKDIR}/package
PKGD="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/package"
# PKGE=${@['','${PE\x7d'][d.getVar('PE',1) > 0]}
# HOST_SYS=${HOST_ARCH}${HOST_VENDOR}-${HOST_OS}
HOST_SYS="i586-poky-linux"
# MAKE=make
export MAKE="make"
# PKGV=${PV}
PKGV="1.0"
# includedir=${exec_prefix}/include
export includedir="/usr/include"
# PKGR=${PR}${EXTENDPRAUTO}
PKGR="r0"
# TARGET_CPPFLAGS=
# RRECOMMENDS_${PN}-dbg=${PN} (= ${EXTENDPKGV})
RRECOMMENDS_bblayers-dbg="bblayers (= 1.0-r0)"
# PREFERRED_VERSION_eglibc-initial=${EGLIBCVERSION}
PREFERRED_VERSION_eglibc-initial="2.13"
# BBFILE_PATTERN_yocto=^/media/OE/poky/meta-yocto/
BBFILE_PATTERN_yocto="^/media/OE/poky/meta-yocto/"
# PCMCIA_MANAGER=pcmciautils
PCMCIA_MANAGER="pcmciautils"
# PREFERRED_PROVIDER_opkg=opkg
PREFERRED_PROVIDER_opkg="opkg"
# TUNE_ASARGS= ${@bb.utils.contains("TUNE_FEATURES", "mx32", "-x32", "", d)}
TUNE_ASARGS=""
# FILE=/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers.conf
FILE="/media/OE/poky/meta-ettus/recipes/hello/build/conf/bblayers.conf"
# EXTENDPKGEVER=${@['','${PKGE\x7d:'][d.getVar('PKGE',1).strip() != '']}
# libdir_native=${prefix_native}/lib
libdir_native="/usr/lib"
# ASNEEDED_pn-openobex=
# PATCH_GET=0
export PATCH_GET="0"
# PREFERRED_PROVIDER_dbus-glib=dbus-glib
PREFERRED_PROVIDER_dbus-glib="dbus-glib"
# FILES_${PN}-doc=${docdir} ${mandir} ${infodir} ${datadir}/gtk-doc ${datadir}/gnome/help
FILES_bblayers-doc="/usr/share/doc /usr/share/man /usr/share/info /usr/share/gtk-doc /usr/share/gnome/help"
# exec_prefix=/usr
export exec_prefix="/usr"
# bindir_crossscripts=${bindir}/crossscripts
bindir_crossscripts="/usr/bin/crossscripts"
# PRIORITY=optional
PRIORITY="optional"
# PREFERRED_VERSION_binutils=${BINUVERSION}
PREFERRED_VERSION_binutils="2.22"
# PARALLEL_MAKEINST=${PARALLEL_MAKE}
PARALLEL_MAKEINST="${PARALLEL_MAKE}"
# SEPPUKU_QUERY=None
# BB_SETSCENE_VERIFY_FUNCTION=sysroot_checkhashes
BB_SETSCENE_VERIFY_FUNCTION="sysroot_checkhashes"
# SECTION=base
SECTION="base"
# SDK_CC_ARCH=${BUILD_CC_ARCH}
# MAINTAINER=Poky <poky@yoctoproject.org>
MAINTAINER="Poky <poky@yoctoproject.org>"
# SDKPATH=/opt/${DISTRO}/${SDK_VERSION}
SDKPATH="/opt/poky/1.1+snapshot"
# GROUP_locale=None
# BUILD_CC=${CCACHE}${BUILD_PREFIX}gcc ${BUILD_CC_ARCH}
export BUILD_CC="ccache gcc"
# LIBCOVERRIDE=:libc-glibc
LIBCOVERRIDE=":libc-glibc"
# BUILD_LDFLAGS=-L${STAGING_LIBDIR_NATIVE} -L${STAGING_BASE_LIBDIR_NATIVE} -Wl,-rpath-link,${STAGING_LIBDIR_NATIVE} -Wl,-rpath-link,${STAGING_BASE_LIBDIR_NATIVE} -Wl,-rpath,${STAGING_LIBDIR_NATIVE} -Wl,-rpath,${STAGING_BASE_LIBDIR_NATIVE} -Wl,-O1
export BUILD_LDFLAGS="-L/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib -L/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/lib -Wl,-rpath-link,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib -Wl,-rpath-link,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/lib -Wl,-rpath,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib -Wl,-rpath,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/lib -Wl,-O1"
# SSTATE_PKGNAME=${SSTATE_PKGSPEC}${BB_TASKHASH}
SSTATE_PKGNAME="sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH}"
# PACKAGE_ARCH=${TUNE_PKGARCH}
PACKAGE_ARCH="i586"
# SEPPUKU_COMPONENT=None
# STAGING_LIBDIR=${STAGING_DIR_HOST}${libdir}
STAGING_LIBDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib"
# TARGET_ARCH=${TUNE_ARCH}
unset TARGET_ARCH
# FETCHCMD_cvs=/usr/bin/env cvs
FETCHCMD_cvs="/usr/bin/env cvs"
# EXTRA_IMAGE_FEATURES=debug-tweaks
EXTRA_IMAGE_FEATURES="debug-tweaks"
# DESKTOP_SESSION=gnome
DESKTOP_SESSION="gnome"
# AR=${HOST_PREFIX}ar
export AR="i586-poky-linux-ar"
# BBINCLUDELOGS_LINES=None
# LINUXLIBCVERSION=3.1
LINUXLIBCVERSION="3.1"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}gcc-intermediate=gcc-cross-intermediate
PREFERRED_PROVIDER_virtual/i586-poky-linux-gcc-intermediate="gcc-cross-intermediate"
# LIBCEXTENSION=${@['', '-gnu'][(d.getVar('ABIEXTENSION', True) or '') != '']}
# PREFERRED_PROVIDER_libgcc=libgcc
PREFERRED_PROVIDER_libgcc="libgcc"
# GENTOO_MIRROR=http://distfiles.gentoo.org/distfiles
GENTOO_MIRROR="http://distfiles.gentoo.org/distfiles"
# CO_DIR=${DL_DIR}
CO_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads"
# MULTIMACH_TARGET_SYS=${PACKAGE_ARCH}${TARGET_VENDOR}-${TARGET_OS}
MULTIMACH_TARGET_SYS="i586-poky-linux"
# PREFERRED_VERSION_liberation-fonts=1.04
PREFERRED_VERSION_liberation-fonts="1.04"
# CCACHE_DIR=${TMPDIR}/ccache/${MULTIMACH_HOST_SYS}/${PN}
export CCACHE_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/ccache/i586-poky-linux/bblayers"
# QUILTRCFILE=${STAGING_BINDIR_NATIVE}/quiltrc
QUILTRCFILE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/quiltrc"
# DEPLOY_DIR_DEB=${DEPLOY_DIR}/deb
DEPLOY_DIR_DEB="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/deb"
# BBLAYERS= /media/OE/poky/meta /media/OE/poky/meta-yocto 
BBLAYERS="/media/OE/poky/meta /media/OE/poky/meta-yocto"
# SECTION_${PN}-staticdev=devel
SECTION_bblayers-staticdev="devel"
# X86ARCH64=x86_64
X86ARCH64="x86_64"
# BOOTSTRAP_EXTRA_RDEPENDS=
# PREFERRED_VERSION_linux-libc-headers-nativesdk=${LINUXLIBCVERSION}
PREFERRED_VERSION_linux-libc-headers-nativesdk="3.1"
# BUILD_LD=${BUILD_PREFIX}ld ${BUILD_LD_ARCH}
export BUILD_LD="ld"
# TUNE_LDARGS= ${@bb.utils.contains("TUNE_FEATURES", "mx32", "-m elf32_x86_64", "", d)}
TUNE_LDARGS=""
# baselib=${BASELIB}
baselib="lib"
# STAGING_INCDIR=${STAGING_DIR_HOST}${includedir}
STAGING_INCDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/include"
# PREFERRED_PROVIDER_virtual/${SDK_PREFIX}libc-for-gcc-nativesdk=${TCLIBC}-nativesdk
PREFERRED_PROVIDER_virtual/x86_64-pokysdk-linux-libc-for-gcc-nativesdk="eglibc-nativesdk"
# GLIBC_EXTRA_OECONF=--with-tls
GLIBC_EXTRA_OECONF="--with-tls"
# BB_ENV_EXTRAWHITE=PSEUDO_BUILD PSEUDO_DISABLED MACHINE DISTRO TCMODE TCLIBC http_proxy ftp_proxy https_proxy all_proxy ALL_PROXY no_proxy SSH_AGENT_PID SSH_AUTH_SOCK BB_SRCREV_POLICY SDKMACHINE BB_NUMBER_THREADS PARALLEL_MAKE GIT_PROXY_COMMAND GIT_PROXY_IGNORE SOCKS5_PASSWD SOCKS5_USER
BB_ENV_EXTRAWHITE="PSEUDO_BUILD PSEUDO_DISABLED MACHINE DISTRO TCMODE TCLIBC http_proxy ftp_proxy https_proxy all_proxy ALL_PROXY no_proxy SSH_AGENT_PID SSH_AUTH_SOCK BB_SRCREV_POLICY SDKMACHINE BB_NUMBER_THREADS PARALLEL_MAKE GIT_PROXY_COMMAND GIT_PROXY_IGNORE SOCKS5_PASSWD SOCKS5_USER"
# QADEPENDS_virtclass-native=
# PREFERRED_PROVIDER_opkg-native=opkg-native
PREFERRED_PROVIDER_opkg-native="opkg-native"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}g++=gcc-cross
PREFERRED_PROVIDER_virtual/i586-poky-linux-g++="gcc-cross"
# DISPLAY=:0
DISPLAY=":0"
# PREFERRED_VERSION_gcc-crosssdk-intermediate=${SDKGCCVERSION}
PREFERRED_VERSION_gcc-crosssdk-intermediate="4.6%"
# LOG_DIR=${TMPDIR}/log
LOG_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/log"
# XORG_MIRROR=http://xorg.freedesktop.org/releases
XORG_MIRROR="http://xorg.freedesktop.org/releases"
# PATCHDEPENDENCY=${PATCHTOOL}-native:do_populate_sysroot
PATCHDEPENDENCY="quilt-native:do_populate_sysroot"
# PREFERRED_VERSION_binutils-cross-canadian-${TRANSLATED_TARGET_ARCH}=${BINUVERSION}
PREFERRED_VERSION_binutils-cross-canadian-i586="2.22"
# BUILDSDK_CPPFLAGS=-isystem${STAGING_INCDIR}
BUILDSDK_CPPFLAGS="-isystem/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/include"
# EXTRAOPKGCONFIG=poky-feed-config-opkg
EXTRAOPKGCONFIG="poky-feed-config-opkg"
# OEINCLUDELOGS=yes
OEINCLUDELOGS="yes"
# AVAILTUNES= x86 x86-64 x86-64-x32 i586
AVAILTUNES="x86 x86-64 x86-64-x32 i586"
# BB_HASHBASE_WHITELIST=TMPDIR FILE PATH PWD BB_TASKHASH BBPATH DL_DIR SSTATE_DIR THISDIR FILESEXTRAPATHS FILE_DIRNAME HOME LOGNAME SHELL TERM USER FILESPATH STAGING_DIR_HOST STAGING_DIR_TARGET COREBASE PRSERV_HOST PRSERV_PORT PRSERV_DUMPDIR PRSERV_DUMPFILE PRSERV_LOCKDOWN
BB_HASHBASE_WHITELIST="TMPDIR FILE PATH PWD BB_TASKHASH BBPATH DL_DIR SSTATE_DIR THISDIR FILESEXTRAPATHS FILE_DIRNAME HOME LOGNAME SHELL TERM USER FILESPATH STAGING_DIR_HOST STAGING_DIR_TARGET COREBASE PRSERV_HOST PRSERV_PORT PRSERV_DUMPDIR PRSERV_DUMPFILE PRSERV_LOCKDOWN"
# SEPPUKU_AUTOBUILD=None
# E_MIRROR=http://download.enlightenment.org/releases
E_MIRROR="http://download.enlightenment.org/releases"
# PREFERRED_PROVIDER_virtual/gettext=gettext
PREFERRED_PROVIDER_virtual/gettext="gettext"
# FETCHCOMMAND_wget=/usr/bin/env wget -t 5 -nv --passive-ftp --no-check-certificate -P ${DL_DIR} '${URI}'
FETCHCOMMAND_wget="/usr/bin/env wget -t 5 -nv --passive-ftp --no-check-certificate -P /media/OE/poky/meta-ettus/recipes/hello/build/downloads '${URI}'"
# FETCHCMD_svn=/usr/bin/env svn
FETCHCMD_svn="/usr/bin/env svn"
# PACKAGE_EXTRA_ARCHS_tune-i586=${PACKAGE_EXTRA_ARCHS_tune-x86} i386 i486 i586
PACKAGE_EXTRA_ARCHS_tune-i586="x86 i386 i486 i586"
# SDK_AS_ARCH=${BUILD_AS_ARCH}
# GPE_EXTRA_SVN=svn://projects.linuxtogo.org/svn/gpe/trunk/extra;module=${PN}
GPE_EXTRA_SVN="svn://projects.linuxtogo.org/svn/gpe/trunk/extra;module=bblayers"
# oldincludedir=${exec_prefix}/include
export oldincludedir="/usr/include"
# INITRAMFS_FSTYPES=cpio.gz
INITRAMFS_FSTYPES="cpio.gz"
# PREFERRED_PROVIDER_virtual/kernel=linux-yocto
PREFERRED_PROVIDER_virtual/kernel="linux-yocto"
# TUNECONFLICTS=None
# sysconfdir=${base_prefix}/etc
export sysconfdir="/etc"
# PSEUDO_BUILD=1
PSEUDO_BUILD="1"
# CCLD=${CC}
export CCLD="ccache i586-poky-linux-gcc  -m32   -march=i586 --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# TIME=091305
TIME="091305"
# CHECKCOMMAND_wget=/usr/bin/env wget --spider -t 5 --passive-ftp --no-check-certificate -P ${DL_DIR} '${URI}'
CHECKCOMMAND_wget="/usr/bin/env wget --spider -t 5 --passive-ftp --no-check-certificate -P /media/OE/poky/meta-ettus/recipes/hello/build/downloads '${URI}'"
# localstatedir_nativesdk=/var
localstatedir_nativesdk="/var"
# UPDATECOMMAND_svn=/usr/bin/env svn update ${SVNCOOPTS}
UPDATECOMMAND_svn="/usr/bin/env svn update ${SVNCOOPTS}"
# PREFERRED_VERSION_gcc=${GCCVERSION}
PREFERRED_VERSION_gcc="4.6%"
# SELECTED_OPTIMIZATION=${@d.getVar(['FULL_OPTIMIZATION', 'DEBUG_OPTIMIZATION'][d.getVar('DEBUG_BUILD', True) == '1'], True)}
SELECTED_OPTIMIZATION="-O2 -pipe -g -feliminate-unused-debug-types"
# GIT_CONFIG_PATH=${STAGING_DIR_NATIVE}/etc
GIT_CONFIG_PATH="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/etc"
# SEPPUKU_USER=None
# FEED_DEPLOYDIR_BASE_URI=None
# DEBIAN_NAMES=1
DEBIAN_NAMES="1"
# EXTRA_IMAGEDEPENDS= qemu-native qemu-helper-native
EXTRA_IMAGEDEPENDS="qemu-native qemu-helper-native"
# PACKAGE_EXTRA_ARCHS_tune-x86-64-x32=x86_64_x32
PACKAGE_EXTRA_ARCHS_tune-x86-64-x32="x86_64_x32"
# LIMIT_BUILT_LOCALES=POSIX en_US en_GB
LIMIT_BUILT_LOCALES="POSIX en_US en_GB"
# PACKAGEINDEXDEPS= rpm-native:do_populate_sysroot createrepo-native:do_populate_sysroot
PACKAGEINDEXDEPS="rpm-native:do_populate_sysroot createrepo-native:do_populate_sysroot"
# TARGET_CXXFLAGS=${TARGET_CFLAGS} -fpermissive
export TARGET_CXXFLAGS="-O2 -pipe -g -feliminate-unused-debug-types -fpermissive"
# PREFERRED_VERSION_linux-yocto_qemuarm=3.2%
PREFERRED_VERSION_linux-yocto_qemuarm="3.2%"
# DESCRIPTION_${PN}-dbg=${DESCRIPTION}  This package contains ELF symbols and related sources for debugging purposes.
DESCRIPTION_bblayers-dbg="bblayers version 1.0-r0  This package contains ELF symbols and related sources for debugging purposes."
# QA_LOG=None
# LANG=en_US.UTF-8
LANG="en_US.UTF-8"
# PSEUDO_LOCALSTATEDIR=${WORKDIR}/pseudo/
PSEUDO_LOCALSTATEDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/pseudo/"
# BUILD_CCLD=${BUILD_PREFIX}gcc ${BUILD_CC_ARCH}
export BUILD_CCLD="gcc"
# IMAGE_NAME=${IMAGE_BASENAME}-${MACHINE}-${DATETIME}
IMAGE_NAME="bblayers-qemux86-20120323091305"
# DEBUG_FLAGS=-g -feliminate-unused-debug-types
DEBUG_FLAGS="-g -feliminate-unused-debug-types"
# STAGING_LIBDIR_NATIVE=${STAGING_DIR_NATIVE}${libdir_native}
STAGING_LIBDIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib"
# QEMU_TARGETS=arm i386 mips mipsel ppc x86_64
QEMU_TARGETS="arm i386 mips mipsel ppc x86_64"
# SOLIBSDEV_darwin=.dylib
SOLIBSDEV_darwin=".dylib"
# GROUP_packaging=None
# DESCRIPTION=${SUMMARY}
DESCRIPTION="bblayers version 1.0-r0"
# B=${S}
B="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/bblayers-1.0"
# GROUP_fetcher=None
# OVERRIDES=${TARGET_OS}:${TRANSLATED_TARGET_ARCH}:build-${BUILD_OS}:pn-${PN}:${MACHINEOVERRIDES}:${DISTROOVERRIDES}:forcevariable${LIBCOVERRIDE}
OVERRIDES="linux:i586:build-linux:pn-bblayers:qemux86:x86:poky:forcevariable:libc-glibc"
# SDK_NAME_PREFIX=oecore
SDK_NAME_PREFIX="oecore"
# BBPATH=/media/OE/poky/meta-yocto::/media/OE/poky/meta
BBPATH="/media/OE/poky/meta-yocto::/media/OE/poky/meta"
# SSTATE_SCAN_CMD=find ${SSTATE_BUILDDIR} \( -name "${@"\" -o -name \"".join(d.getVar("SSTATE_SCAN_FILES", True).split())}" \) -type f
SSTATE_SCAN_CMD="find ${SSTATE_BUILDDIR} \( -name \"*.la\" -o -name \"*-config\" -o -name \"*_config\" \) -type f"
# TARGET_LD_ARCH=${TUNE_LDARGS}
TARGET_LD_ARCH=""
# SDK_SYS=${SDK_ARCH}${SDK_VENDOR}${@['-' + d.getVar('SDK_OS', True), ''][d.getVar('SDK_OS', True) == ('' or 'custom')]}
SDK_SYS="x86_64-pokysdk-linux"
# RDEPENDS_${PN}-staticdev=${PN}-dev (= ${EXTENDPKGV})
RDEPENDS_bblayers-staticdev="bblayers-dev (= 1.0-r0)"
# base_dep=def base_dep_prepend(d):
#	#
#	# Ideally this will check a flag so we will operate properly in
#	# the case where host == build == target, for now we don't work in
#	# that case though.
#	#
#
#	deps = ""
#	# INHIBIT_DEFAULT_DEPS doesn't apply to the patch command.  Whether or  not
#	# we need that built is the responsibility of the patch function / class, not
#	# the application.
#	if not d.getVar('INHIBIT_DEFAULT_DEPS'):
#		if (d.getVar('HOST_SYS', True) !=
#	     	    d.getVar('BUILD_SYS', True)):
#			deps += " virtual/${TARGET_PREFIX}gcc virtual/${TARGET_PREFIX}compilerlibs virtual/libc "
#	return deps
#
base_dep="def base_dep_prepend(d): \
	# \
	# Ideally this will check a flag so we will operate properly in \
	# the case where host == build == target, for now we don't work in \
	# that case though. \
	# \
 \
	deps = \"\" \
	# INHIBIT_DEFAULT_DEPS doesn't apply to the patch command.  Whether or  not \
	# we need that built is the responsibility of the patch function / class, not \
	# the application. \
	if not d.getVar('INHIBIT_DEFAULT_DEPS'): \
		if (d.getVar('HOST_SYS', True) != \
	     	    d.getVar('BUILD_SYS', True)): \
			deps += \" virtual/i586-poky-linux-gcc virtual/i586-poky-linux-compilerlibs virtual/libc \" \
	return deps"
# EGLIBCVERSION=2.13
EGLIBCVERSION="2.13"
# RPMCONF_HOST_BASE=${DEPLOY_DIR_RPM}/solvedb-sdk
RPMCONF_HOST_BASE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb-sdk"
# FETCHCMD_wget=/usr/bin/env wget -t 5 -nv --no-check-certificate
FETCHCMD_wget="/usr/bin/env wget -t 5 -nv --no-check-certificate"
# HOST_LD_ARCH=${TARGET_LD_ARCH}
HOST_LD_ARCH=""
# BUILD_OPTIMIZATION=-O2 -pipe
BUILD_OPTIMIZATION="-O2 -pipe"
# GROUP_dependencies=None
# BUILD_F77=${CCACHE}${BUILD_PREFIX}g77 ${BUILD_CC_ARCH}
export BUILD_F77="ccache g77"
# EXCLUDE_FROM_WORLD_pn-eds-tools=1
EXCLUDE_FROM_WORLD_pn-eds-tools="1"
# PREFERRED_VERSION_libgcc-nativesdk=${SDKGCCVERSION}
PREFERRED_VERSION_libgcc-nativesdk="4.6%"
# BB_STRICT_CHECKSUM=1
BB_STRICT_CHECKSUM="1"
# PACKAGEINDEXES= package_update_index_rpm; createrepo ${DEPLOY_DIR_RPM};
PACKAGEINDEXES="package_update_index_rpm; createrepo /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm;"
# BPN=${@base_prune_suffix(d.getVar('PN', True), d.getVar('SPECIAL_PKGSUFFIX', True).split(), d)}
BPN="bblayers"
# RDEPENDS=
# ASNEEDED_pn-dialer=
# PATH=${STAGING_BINDIR_TOOLCHAIN}:${STAGING_BINDIR_CROSS}:${STAGING_DIR_NATIVE}${sbindir_native}:${STAGING_BINDIR_NATIVE}:${STAGING_DIR_NATIVE}${base_sbindir_native}:${STAGING_DIR_NATIVE}/${base_bindir_native}:/media/OE/poky/bitbake/bin/:/media/OE/poky/scripts:/media/OE/poky/bitbake/bin/:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/mmoselhy/.local/bin:/home/mmoselhy/bin:/media/OE/poky/scripts
export PATH="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin/crossscripts:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/sbin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/sbin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux//bin:/media/OE/poky/bitbake/bin/:/media/OE/poky/scripts:/media/OE/poky/bitbake/bin/:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/mmoselhy/.local/bin:/home/mmoselhy/bin:/media/OE/poky/scripts"
# PACKAGES=${PN}-dbg ${PN}-staticdev ${PN} ${PN}-doc ${PN}-dev ${PN}-locale
PACKAGES="bblayers-dbg bblayers-staticdev bblayers bblayers-doc bblayers-dev bblayers-locale"
# EXCLUDE_FROM_WORLD_pn-clutter-box2d=1
EXCLUDE_FROM_WORLD_pn-clutter-box2d="1"
# DESCRIPTION_${PN}-staticdev=${DESCRIPTION}  This package contains static libraries for software development.
DESCRIPTION_bblayers-staticdev="bblayers version 1.0-r0  This package contains static libraries for software development."
# TARGET_CFLAGS=${TARGET_CPPFLAGS} ${SELECTED_OPTIMIZATION}
export TARGET_CFLAGS="-O2 -pipe -g -feliminate-unused-debug-types"
# base_bindir=${base_prefix}/bin
export base_bindir="/bin"
# BUILD_CPP=${BUILD_PREFIX}cpp ${BUILD_CC_ARCH}
export BUILD_CPP="cpp"
# HOMEPAGE=unknown
HOMEPAGE="unknown"
# SANITY_VERSION=1
SANITY_VERSION="1"
# BZRDIR=${CO_DIR}/bzr
BZRDIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads/bzr"
# EXTENDPRAUTO=${@['.${PRAUTO\x7d',''][d.getVar('PRAUTO',1) is None]}
# LINKER_HASH_STYLE_mips=sysv
LINKER_HASH_STYLE_mips="sysv"
# PREFERRED_VERSION_gcc-cross=${GCCVERSION}
PREFERRED_VERSION_gcc-cross="4.6%"
# SANITY_REQUIRED_UTILITIES=patch diffstat texi2html makeinfo svn bzip2 tar gzip gawk chrpath wget cpio
SANITY_REQUIRED_UTILITIES="patch diffstat texi2html makeinfo svn bzip2 tar gzip gawk chrpath wget cpio"
# ASNEEDED_pn-rpm=
# BASE_LIB_tune-x86-64=lib64
BASE_LIB_tune-x86-64="lib64"
# PKGWRITEDIRRPM=${WORKDIR}/deploy-rpms
PKGWRITEDIRRPM="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/deploy-rpms"
# BBFILE_PRIORITY_normal=5
BBFILE_PRIORITY_normal="5"
# MACHINE=qemux86
unset MACHINE
# INHERIT= ${PACKAGE_CLASSES} ${USER_CLASSES} ${INHERIT_INSANE} ${INHERIT_DISTRO} sanity
INHERIT="package_rpm buildstats image-mklibs image-prelink insane debian devshell sstate license sanity"
# FILE_DIRNAME=${@os.path.dirname(d.getVar('FILE'))}
FILE_DIRNAME="/media/OE/poky/meta-ettus/recipes/hello/build/conf"
# GITDIR=${CO_DIR}/git2
GITDIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads/git2"
# RESUMECOMMAND_wget=/usr/bin/env wget -c -t 5 -nv --passive-ftp --no-check-certificate -P ${DL_DIR} '${URI}'
RESUMECOMMAND_wget="/usr/bin/env wget -c -t 5 -nv --passive-ftp --no-check-certificate -P /media/OE/poky/meta-ettus/recipes/hello/build/downloads '${URI}'"
# EXCLUDE_FROM_WORLD_pn-gobject-introspection=1
EXCLUDE_FROM_WORLD_pn-gobject-introspection="1"
# MACHINEOVERRIDES=${MACHINE}${@bb.utils.contains("TUNE_FEATURES", "m32", ":x86", "" ,d)}
MACHINEOVERRIDES="qemux86:x86"
# FILES_${PN}-staticdev=${libdir}/*.a ${base_libdir}/*.a ${libdir}/${BPN}/*.a
FILES_bblayers-staticdev="/usr/lib/*.a /lib/*.a /usr/lib/bblayers/*.a"
# prefix_native=/usr
prefix_native="/usr"
# PREFERRED_PROVIDER_virtual/xserver-xf86=xserver-xorg
PREFERRED_PROVIDER_virtual/xserver-xf86="xserver-xorg"
# GPE_MIRROR=http://gpe.linuxtogo.org/download/source
GPE_MIRROR="http://gpe.linuxtogo.org/download/source"
# SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/1423,unix/unix:/tmp/.ICE-unix/1423
SESSION_MANAGER="local/unix:@/tmp/.ICE-unix/1423,unix/unix:/tmp/.ICE-unix/1423"
# SECTION_${PN}-dev=devel
SECTION_bblayers-dev="devel"
# base_sbindir_native=/sbin
base_sbindir_native="/sbin"
# SOURCE_MIRROR_URL=None
# sbindir=${exec_prefix}/sbin
export sbindir="/usr/sbin"
# CFLAGS=${TARGET_CFLAGS}
export CFLAGS="-O2 -pipe -g -feliminate-unused-debug-types"
# BUILD_AR=${BUILD_PREFIX}ar
export BUILD_AR="ar"
# BUILD_AS=${BUILD_PREFIX}as ${BUILD_AS_ARCH}
export BUILD_AS="as"
# HANDHELDS_CVS=cvs://anoncvs:anoncvs@anoncvs.handhelds.org/cvs
HANDHELDS_CVS="cvs://anoncvs:anoncvs@anoncvs.handhelds.org/cvs"
# sharedstatedir=${base_prefix}/com
export sharedstatedir="/com"
# STAGING_BASE_LIBDIR_NATIVE=${STAGING_DIR_NATIVE}${base_libdir_native}
STAGING_BASE_LIBDIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/lib"
# COMMERCIAL_AUDIO_PLUGINS=
# SSTATE_MANFILEPREFIX=${SSTATE_MANFILEBASE}${PN}
SSTATE_MANFILEPREFIX="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control/manifest-i586-bblayers"
# SDK_PREFIX=${SDK_SYS}-
SDK_PREFIX="x86_64-pokysdk-linux-"
# DEBIAN_MIRROR=ftp://ftp.debian.org/debian/pool
DEBIAN_MIRROR="ftp://ftp.debian.org/debian/pool"
# PREFERRED_PROVIDER_virtual/libc=eglibc
PREFERRED_PROVIDER_virtual/libc="eglibc"
# DEVFILE=${BUILDSTATS_BASE}/.device
DEVFILE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/buildstats//.device"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}libc-for-gcc=${TCLIBC}
PREFERRED_PROVIDER_virtual/i586-poky-linux-libc-for-gcc="eglibc"
# DEFAULT_TASK_PROVIDER=task-base
DEFAULT_TASK_PROVIDER="task-base"
# BOOTSTRAP_EXTRA_RRECOMMENDS=
# F77=${CCACHE}${HOST_PREFIX}g77 ${HOST_CC_ARCH}${TOOLCHAIN_OPTIONS}
export F77="ccache i586-poky-linux-g77  -m32   -march=i586 --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# TOPDIR=/media/OE/poky/meta-ettus/recipes/hello/build
TOPDIR="/media/OE/poky/meta-ettus/recipes/hello/build"
# PREFERRED_VERSION_linux-yocto_qemuppc=3.2%
PREFERRED_VERSION_linux-yocto_qemuppc="3.2%"
# WARN_QA=ldflags useless-rpaths rpaths unsafe-references-in-binaries unsafe-references-in-scripts staticdev
WARN_QA="ldflags useless-rpaths rpaths unsafe-references-in-binaries unsafe-references-in-scripts staticdev"
# KERNEL_IMAGETYPE=bzImage
KERNEL_IMAGETYPE="bzImage"
# VIRTUAL-RUNTIME_apm=apm
VIRTUAL-RUNTIME_apm="apm"
# QEMUIMAGETESTS=/media/OE/poky/scripts/qemuimage-tests
QEMUIMAGETESTS="/media/OE/poky/scripts/qemuimage-tests"
# IMAGE_LINGUAS=en-us en-gb
IMAGE_LINGUAS="en-us en-gb"
# DEPLOY_DIR_IMAGE=${DEPLOY_DIR}/images
DEPLOY_DIR_IMAGE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/images"
# SUMMARY_${PN}-dev=${SUMMARY} - Development files
SUMMARY_bblayers-dev="bblayers version 1.0-r0 - Development files"
# PREFERRED_PROVIDER_virtual/libc-nativesdk=eglibc-nativesdk
PREFERRED_PROVIDER_virtual/libc-nativesdk="eglibc-nativesdk"
# ALLOWED_FLAGS=-O -mcpu -march -pipe
ALLOWED_FLAGS="-O -mcpu -march -pipe"
# ASNEEDED_pn-minimo=
# VIRTUAL-RUNTIME_update-alternatives=update-alternatives-cworth
VIRTUAL-RUNTIME_update-alternatives="update-alternatives-cworth"
# PREFERRED_PROVIDER_virtual/libiconv-nativesdk=eglibc-nativesdk
PREFERRED_PROVIDER_virtual/libiconv-nativesdk="eglibc-nativesdk"
# PACKAGE_DEPENDS= rpm-native file-native pax-utils-native ${QADEPENDS}
PACKAGE_DEPENDS="rpm-native file-native pax-utils-native prelink-native"
# PREFERRED_VERSION_linux-libc-headers=${LINUXLIBCVERSION}
PREFERRED_VERSION_linux-libc-headers="3.1"
# SOURCEFORGE_MIRROR=http://downloads.sourceforge.net
SOURCEFORGE_MIRROR="http://downloads.sourceforge.net"
# DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-KF7AY2432s,guid=819b6bb53f5221bf98349e7d00000029
DBUS_SESSION_BUS_ADDRESS="unix:abstract=/tmp/dbus-KF7AY2432s,guid=819b6bb53f5221bf98349e7d00000029"
# OBJDUMP=${HOST_PREFIX}objdump
export OBJDUMP="i586-poky-linux-objdump"
# INHERIT_DISTRO=debian devshell sstate license
INHERIT_DISTRO="debian devshell sstate license"
# DEFAULTTUNE=i586
DEFAULTTUNE="i586"
# IMAGE_BASENAME=${PN}
IMAGE_BASENAME="bblayers"
# PATCHTOOL=quilt
PATCHTOOL="quilt"
# STAGING_EXECPREFIXDIR=${STAGING_DIR_HOST}${exec_prefix}
STAGING_EXECPREFIXDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr"
# SYSROOT_DESTDIR=${WORKDIR}/sysroot-destdir/
SYSROOT_DESTDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/sysroot-destdir/"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}libc-initial=${TCLIBC}-initial
PREFERRED_PROVIDER_virtual/i586-poky-linux-libc-initial="eglibc-initial"
# UCLIBCVERSION=0.9.33
UCLIBCVERSION="0.9.33"
# BUILD_CFLAGS=${BUILD_CPPFLAGS} ${BUILD_OPTIMIZATION}
export BUILD_CFLAGS="-isystem/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/include -O2 -pipe"
# PACKAGELOCK=${STAGING_DIR}/package-output.lock
PACKAGELOCK="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/package-output.lock"
# PREFERRED_VERSION_elfutils=0.148
PREFERRED_VERSION_elfutils="0.148"
# SPECIAL_PKGSUFFIX=-native -cross -initial -intermediate -nativesdk -crosssdk -cross-canadian
SPECIAL_PKGSUFFIX="-native -cross -initial -intermediate -nativesdk -crosssdk -cross-canadian"
# BUILD_EXEEXT=
# ASSUME_SHLIBS=None
# OLDEST_KERNEL=2.6.16
OLDEST_KERNEL="2.6.16"
# PKGDATA_DIR=${TMPDIR}/pkgdata/${MULTIMACH_TARGET_SYS}
PKGDATA_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/pkgdata/i586-poky-linux"
# PREFERRED_VERSION_python-native=2.7.2
PREFERRED_VERSION_python-native="2.7.2"
# base_libdir=${base_prefix}/${baselib}
export base_libdir="/lib"
# SECTION_${PN}-doc=doc
SECTION_bblayers-doc="doc"
# PR=${@bb.parse.BBHandler.vars_from_file(d.getVar('FILE'),d)[2] or 'r0'}
PR="r0"
# PV=${@bb.parse.BBHandler.vars_from_file(d.getVar('FILE'),d)[1] or '1.0'}
PV="1.0"
# XAUTHORITY=/var/run/gdm/auth-for-mmoselhy-1sF7v9/database
XAUTHORITY="/var/run/gdm/auth-for-mmoselhy-1sF7v9/database"
# AUTHOR=None
# sysconfdir_native=/etc
sysconfdir_native="/etc"
# BUILDSDK_LDFLAGS=-L${STAGING_LIBDIR} -Wl,-rpath-link,${STAGING_LIBDIR} -Wl,-rpath,${libdir} -Wl,-O1 -L${STAGING_DIR_HOST}${base_libdir} -Wl,-rpath-link,${STAGING_DIR_HOST}${base_libdir} -Wl,-rpath,${base_libdir} -Wl,-O1
BUILDSDK_LDFLAGS="-L/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib -Wl,-rpath-link,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib -Wl,-rpath,/usr/lib -Wl,-O1 -L/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/lib -Wl,-rpath-link,/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/lib -Wl,-rpath,/lib -Wl,-O1"
# PKGDEST=${WORKDIR}/packages-split
PKGDEST="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/packages-split"
# BASELIB=lib
BASELIB="lib"
# PF=${PN}-${EXTENDPE}${PV}-${PR}
PF="bblayers-1.0-r0"
# STAGING_BINDIR_NATIVE=${STAGING_DIR_NATIVE}${bindir_native}
STAGING_BINDIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin"
# GPG_AGENT_INFO=/tmp/keyring-X2vmYv/gpg:0:1
GPG_AGENT_INFO="/tmp/keyring-X2vmYv/gpg:0:1"
# PN=${@bb.parse.BBHandler.vars_from_file(d.getVar('FILE'),d)[0] or 'defaultpkgname'}
PN="bblayers"
# POKY_DEFAULT_EXTRA_RDEPENDS=task-core-boot
POKY_DEFAULT_EXTRA_RDEPENDS="task-core-boot"
# FAKEROOTNOENV=PSEUDO_UNLOAD=1
FAKEROOTNOENV="PSEUDO_UNLOAD=1"
# PACKAGEVARS=FILES RDEPENDS RRECOMMENDS SUMMARY DESCRIPTION RSUGGESTS RPROVIDES RCONFLICTS PKG ALLOW_EMPTY pkg_postinst pkg_postrm INITSCRIPT_NAME INITSCRIPT_PARAMS DEBIAN_NOAUTONAME
PACKAGEVARS="FILES RDEPENDS RRECOMMENDS SUMMARY DESCRIPTION RSUGGESTS RPROVIDES RCONFLICTS PKG ALLOW_EMPTY pkg_postinst pkg_postrm INITSCRIPT_NAME INITSCRIPT_PARAMS DEBIAN_NOAUTONAME"
# FILES_${PN}-dev=${includedir} ${libdir}/lib*${SOLIBSDEV} ${libdir}/*.la ${libdir}/*.o ${libdir}/pkgconfig ${datadir}/pkgconfig ${datadir}/aclocal ${base_libdir}/*.o
FILES_bblayers-dev="/usr/include /usr/lib/lib*.so /usr/lib/*.la /usr/lib/*.o /usr/lib/pkgconfig /usr/share/pkgconfig /usr/share/aclocal /lib/*.o"
# DISTRO_VERSION=1.1+snapshot-${DATE}
DISTRO_VERSION="1.1+snapshot-20120323"
# SDK_LD_ARCH=${BUILD_LD_ARCH}
# S=${WORKDIR}/${BP}
S="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/bblayers-1.0"
# IMAGE_LINK_NAME=${IMAGE_BASENAME}-${MACHINE}
IMAGE_LINK_NAME="bblayers-qemux86"
# USER_CLASSES=buildstats image-mklibs image-prelink
USER_CLASSES="buildstats image-mklibs image-prelink"
# DEPLOY_DIR_TAR=${DEPLOY_DIR}/tar
DEPLOY_DIR_TAR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/tar"
# MKTEMPDIRCMD=mktemp -d -q ${TMPBASE}
MKTEMPDIRCMD="mktemp -d -q ${TMPBASE}"
# STAGING_KERNEL_DIR=${STAGING_DIR_HOST}/kernel
STAGING_KERNEL_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/kernel"
# BB_HASHCHECK_FUNCTION=sstate_checkhashes
BB_HASHCHECK_FUNCTION="sstate_checkhashes"
# SEPPUKU_LOGIN=None
# SEPPUKU_PRODUCT=None
# ADOBE_MIRROR=http://fpdownload.macromedia.com/get/flashplayer/current/
ADOBE_MIRROR="http://fpdownload.macromedia.com/get/flashplayer/current/"
# SOLIBS=.so.*
SOLIBS=".so.*"
# PROVIDES=${P} ${PF} ${PN} 
PROVIDES="bblayers-1.0 bblayers-1.0-r0 bblayers"
# PKG_CONFIG_DIR=${STAGING_DIR_HOST}/${libdir}/pkgconfig
export PKG_CONFIG_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86//usr/lib/pkgconfig"
# PYTHON_BASEVERSION=2.7
PYTHON_BASEVERSION="2.7"
# PACKAGE_PREPROCESS_FUNCS=
# IMAGE_PREPROCESS_COMMAND= mklibs_optimize_image;  prelink_image; 
IMAGE_PREPROCESS_COMMAND="mklibs_optimize_image;  prelink_image;"
# DEBIANRDEP=do_package
DEBIANRDEP="do_package"
# do_package_write_tar=None
# DISTRO_FEATURES=alsa argp bluetooth ext2 irda largefile pcmcia usbgadget usbhost wifi xattr nfs zeroconf pci 3g x11 ${DISTRO_FEATURES_LIBC} largefile opengl${@oe.utils.distro_features_backfill(d)}
DISTRO_FEATURES="alsa argp bluetooth ext2 irda largefile pcmcia usbgadget usbhost wifi xattr nfs zeroconf pci 3g x11 ipv4 ipv6 libc-backtrace libc-big-macros libc-bsd libc-cxx-tests libc-catgets libc-charsets libc-crypt 					libc-crypt-ufc libc-db-aliases libc-envz libc-fcvt libc-fmtmsg libc-fstab libc-ftraverse 					libc-getlogin libc-idn libc-inet-anl libc-libm libc-libm-big libc-locales libc-locale-code 					libc-memusage libc-nis libc-nsswitch libc-rcmd libc-rtld-debug libc-spawn libc-streams libc-sunrpc 					libc-utmp libc-utmpx libc-wordexp libc-posix-clang-wchar libc-posix-regexp libc-posix-regexp-glibc 					libc-posix-wchar-io largefile opengl pulseaudio"
# TARGET_SYS=${TARGET_ARCH}${TARGET_VENDOR}${@['-' + d.getVar('TARGET_OS', True), ''][d.getVar('TARGET_OS', True) == ('' or 'custom')]}
TARGET_SYS="i586-poky-linux"
# PREFERRED_PROVIDER_virtual/libc-locale=eglibc-locale
PREFERRED_PROVIDER_virtual/libc-locale="eglibc-locale"
# PKG_CONFIG_DISABLE_UNINSTALLED=yes
export PKG_CONFIG_DISABLE_UNINSTALLED="yes"
# RESUMECOMMAND=ERROR, this must be a BitBake bug
RESUMECOMMAND="ERROR, this must be a BitBake bug"
# DESCRIPTION_${PN}-dev=${DESCRIPTION}  This package contains symbolic links, header files, and related items necessary for software development.
DESCRIPTION_bblayers-dev="bblayers version 1.0-r0  This package contains symbolic links, header files, and related items necessary for software development."
# PACKAGERDEPTASK=do_package_write
PACKAGERDEPTASK="do_package_write"
# LINKER_HASH_STYLE_mips64el=sysv
LINKER_HASH_STYLE_mips64el="sysv"
# infodir=${datadir}/info
export infodir="/usr/share/info"
# SANITY_ABIFILE=${TMPDIR}/abi_version
SANITY_ABIFILE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/abi_version"
# libdir=${exec_prefix}/${baselib}
export libdir="/usr/lib"
# SEPPUKU_NEWREPORT=None
# DISTROOVERRIDES=${DISTRO}
DISTROOVERRIDES="poky"
# TUNE_FEATURES_tune-x86-64=m64
TUNE_FEATURES_tune-x86-64="m64"
# ALLOW_EMPTY_${PN}-dev=1
ALLOW_EMPTY_bblayers-dev="1"
# COMMERCIAL_QT=
# base_prefix=
# ASNEEDED_pn-xserver-kdrive-xomap=
# LINKER_HASH_STYLE=gnu
LINKER_HASH_STYLE="gnu"
# METADATA_BRANCH=${@base_detect_branch(d)}
METADATA_BRANCH="master"
# PREFERRED_VERSION_gcc-crosssdk-initial=${SDKGCCVERSION}
PREFERRED_VERSION_gcc-crosssdk-initial="4.6%"
# CC=${CCACHE}${HOST_PREFIX}gcc ${HOST_CC_ARCH}${TOOLCHAIN_OPTIONS}
export CC="ccache i586-poky-linux-gcc  -m32   -march=i586 --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# BB_HASHCONFIG_WHITELIST=${BB_HASHBASE_WHITELIST} DATE TIME SESSION_MANAGER DBUS_SESSION_BUS_ADDRESS SSH_AGENT_PID XDG_SESSION_COOKIE SSH_AUTH_SOCK
BB_HASHCONFIG_WHITELIST="TMPDIR FILE PATH PWD BB_TASKHASH BBPATH DL_DIR SSTATE_DIR THISDIR FILESEXTRAPATHS FILE_DIRNAME HOME LOGNAME SHELL TERM USER FILESPATH STAGING_DIR_HOST STAGING_DIR_TARGET COREBASE PRSERV_HOST PRSERV_PORT PRSERV_DUMPDIR PRSERV_DUMPFILE PRSERV_LOCKDOWN DATE TIME SESSION_MANAGER DBUS_SESSION_BUS_ADDRESS SSH_AGENT_PID XDG_SESSION_COOKIE SSH_AUTH_SOCK"
# THISDIR=${@os.path.dirname(d.getVar('FILE', True))}
THISDIR="/media/OE/poky/meta-ettus/recipes/hello/build/conf"
# PREFERRED_PROVIDER_virtual/${SDK_PREFIX}libc-initial-nativesdk=${TCLIBC}-initial-nativesdk
PREFERRED_PROVIDER_virtual/x86_64-pokysdk-linux-libc-initial-nativesdk="eglibc-initial-nativesdk"
# HGDIR=${CO_DIR}/hg
HGDIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads/hg"
# PACKAGE_EXTRA_ARCHS=${PACKAGE_EXTRA_ARCHS_tune-${DEFAULTTUNE}}
PACKAGE_EXTRA_ARCHS="x86 i386 i486 i586"
# SDKGCCVERSION=4.6%
SDKGCCVERSION="4.6%"
# MULTILIB_VARIANTS=
# PREMIRRORS=bzr://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n cvs://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n git://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n hg://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n osc://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n p4://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n svk://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n svn://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n
PREMIRRORS="bzr://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n cvs://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n git://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n hg://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n osc://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n p4://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n svk://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n svn://.*/.*   http://downloads.yoctoproject.org/mirror/sources/ \n"
# BUILD_OS=${@os.uname()[0].lower()}
BUILD_OS="linux"
# PSEUDO_DISABLED=1
export PSEUDO_DISABLED="1"
# IMAGE_FSTYPES=tar.bz2 ext3
IMAGE_FSTYPES="tar.bz2 ext3"
# PACKAGE_CLASSES=package_rpm
PACKAGE_CLASSES="package_rpm"
# BASE_LIB_tune-i586=lib
BASE_LIB_tune-i586="lib"
# STAGING_LOADER_DIR=${STAGING_DIR_HOST}/loader
STAGING_LOADER_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/loader"
# SSTATE_PKG=${SSTATE_DIR}/${SSTATE_PKGNAME}
SSTATE_PKG="/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH}"
# TOOLCHAIN_OPTIONS= --sysroot=${STAGING_DIR_TARGET}
TOOLCHAIN_OPTIONS="--sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# LIBC_DEPENDENCIES=libsegfault 		     eglibc     		     eglibc-dbg     		     eglibc-dev     		     eglibc-utils     		     eglibc-thread-db     		     eglibc-localedata-i18n     		     eglibc-gconv-ibm850     		     eglibc-gconv-cp1252     		     eglibc-gconv-iso8859-1     		     eglibc-gconv-iso8859-15     		     locale-base-en-us     		     locale-base-en-gb 
LIBC_DEPENDENCIES="libsegfault 		     eglibc     		     eglibc-dbg     		     eglibc-dev     		     eglibc-utils     		     eglibc-thread-db     		     eglibc-localedata-i18n     		     eglibc-gconv-ibm850     		     eglibc-gconv-cp1252     		     eglibc-gconv-iso8859-1     		     eglibc-gconv-iso8859-15     		     locale-base-en-us     		     locale-base-en-gb"
# DISTRO_EXTRA_RDEPENDS=  ${POKY_DEFAULT_EXTRA_RDEPENDS} ${POKYQEMUDEPS}
DISTRO_EXTRA_RDEPENDS="task-core-boot qemu-config"
# LOGNAME=mmoselhy
export LOGNAME="mmoselhy"
# OE_TERMINAL=auto
OE_TERMINAL="auto"
# PREFERRED_PROVIDER_linux-libc-headers=linux-libc-headers
PREFERRED_PROVIDER_linux-libc-headers="linux-libc-headers"
# ASNEEDED_pn-pulseaudio=
# DL_DIR=${TOPDIR}/downloads
DL_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/downloads"
# OE_TERMINAL_EXPORTS=XAUTHORITY SHELL DBUS_SESSION_BUS_ADDRESS DISPLAY EXTRA_OEMAKE
OE_TERMINAL_EXPORTS="XAUTHORITY SHELL DBUS_SESSION_BUS_ADDRESS DISPLAY EXTRA_OEMAKE"
# CACHE=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/cache/default-eglibc/qemux86
CACHE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/cache/default-eglibc/qemux86"
# PREFERRED_PROVIDER_virtual/libx11=libx11-trim
PREFERRED_PROVIDER_virtual/libx11="libx11-trim"
# TARGET_PREFIX=${TARGET_SYS}-
TARGET_PREFIX="i586-poky-linux-"
# ASNEEDED_pn-distcc=
# MACHINE_FEATURES=apm alsa pcmcia bluetooth irda usbgadget screen x86
MACHINE_FEATURES="apm alsa pcmcia bluetooth irda usbgadget screen x86"
# STAGING_BINDIR_TOOLCHAIN=${STAGING_DIR_NATIVE}${bindir_native}/${TUNE_PKGARCH}${TARGET_VENDOR}-${TARGET_OS}
STAGING_BINDIR_TOOLCHAIN="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux"
# TARGET_LDFLAGS=-Wl,-O1 ${TARGET_LINK_HASH_STYLE} ${ASNEEDED}
export TARGET_LDFLAGS="-Wl,-O1 -Wl,--hash-style=gnu -Wl,--as-needed"
# HOST_OS=${TARGET_OS}
HOST_OS="linux"
# TERM=xterm
export TERM="xterm"
# MULTIMACH_HOST_SYS=${PACKAGE_ARCH}${HOST_VENDOR}-${HOST_OS}
MULTIMACH_HOST_SYS="i586-poky-linux"
# PREFERRED_PROVIDER_virtual/update-alternatives=update-alternatives-cworth
PREFERRED_PROVIDER_virtual/update-alternatives="update-alternatives-cworth"
# TARGET_FPU=
# DOTDEBUG-dbg=${bindir}/.debug ${sbindir}/.debug ${libexecdir}/.debug ${libdir}/.debug ${base_bindir}/.debug ${base_sbindir}/.debug ${base_libdir}/.debug ${libdir}/${BPN}/.debug ${libdir}/matchbox-panel/.debug /usr/src/debug
DOTDEBUG-dbg="/usr/bin/.debug /usr/sbin/.debug /usr/libexec/.debug /usr/lib/.debug /bin/.debug /sbin/.debug /lib/.debug /usr/lib/bblayers/.debug /usr/lib/matchbox-panel/.debug /usr/src/debug"
# STAGING_DIR_NATIVE=${STAGING_DIR}/${BUILD_SYS}
STAGING_DIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux"
# PACKAGE_ARCHS=all any noarch ${PACKAGE_EXTRA_ARCHS} ${MACHINE_ARCH}
PACKAGE_ARCHS="all any noarch x86 i386 i486 i586 qemux86"
# GNU_MIRROR=ftp://ftp.gnu.org/gnu
GNU_MIRROR="ftp://ftp.gnu.org/gnu"
# DEPLOY_DIR=${TMPDIR}/deploy
DEPLOY_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy"
# ASNEEDED_pn-pciutils=
# ROOTFS_POSTINSTALL_COMMAND= license_create_manifest; 
ROOTFS_POSTINSTALL_COMMAND="license_create_manifest;"
# MACHINE_EXTRA_RDEPENDS=
# EXTRA_OECONF=
# MULTI_PROVIDER_WHITELIST=virtual/libintl virtual/libintl-native virtual/libintl-nativesdk virtual/xserver virtual/update-alternatives-native virtual/update-alternatives
MULTI_PROVIDER_WHITELIST="virtual/libintl virtual/libintl-native virtual/libintl-nativesdk virtual/xserver virtual/update-alternatives-native virtual/update-alternatives"
# SHLIBSWORKDIR=${WORKDIR}/shlibs
SHLIBSWORKDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/shlibs"
# ASNEEDED_pn-puzzles=
# SIGGEN_EXCLUDERECIPES_ABISAFE=  sysvinit-inittab shadow-securetty opkg-config-base netbase formfactor xserver-xf86-config pointercal base-files keymaps 
SIGGEN_EXCLUDERECIPES_ABISAFE="sysvinit-inittab shadow-securetty opkg-config-base netbase formfactor xserver-xf86-config pointercal base-files keymaps"
# MACHINE_ESSENTIAL_EXTRA_RDEPENDS= v86d
MACHINE_ESSENTIAL_EXTRA_RDEPENDS="v86d"
# STAMP=${TMPDIR}/stamps/${MULTIMACH_TARGET_SYS}/${PF}
STAMP="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/stamps/i586-poky-linux/bblayers-1.0-r0"
# PRAUTOINX=${PF}
PRAUTOINX="bblayers-1.0-r0"
# BBINCLUDELOGS=yes
BBINCLUDELOGS="yes"
# PREFERRED_PROVIDER_virtual/libintl=eglibc
PREFERRED_PROVIDER_virtual/libintl="eglibc"
# BUILD_LD_ARCH=
# BB_DEFAULT_TASK=build
BB_DEFAULT_TASK="build"
# STAGING_DATADIR_NATIVE=${STAGING_DIR_NATIVE}${datadir_native}
STAGING_DATADIR_NATIVE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/share"
# RPMDEPS=${STAGING_LIBDIR_NATIVE}/rpm/bin/rpmdeps-oecore --macros ${STAGING_LIBDIR_NATIVE}/rpm/macros --define '_rpmfc_magic_path ${STAGING_DIR_NATIVE}${datadir_native}/misc/magic.mgc' --rpmpopt ${STAGING_LIBDIR_NATIVE}/rpm/rpmpopt
RPMDEPS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/bin/rpmdeps-oecore --macros /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/macros --define '_rpmfc_magic_path /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/share/misc/magic.mgc' --rpmpopt /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/rpmpopt"
# QA_LOGFILE=${TMPDIR}/qa.log
QA_LOGFILE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/qa.log"
# XDG_SESSION_COOKIE=11c3271c5b66ca2e9ed0560c0000000b-1332479281.412676-1103961216
XDG_SESSION_COOKIE="11c3271c5b66ca2e9ed0560c0000000b-1332479281.412676-1103961216"
# SRCREV=INVALID
SRCREV="INVALID"
# base_libdir_nativesdk=/lib
base_libdir_nativesdk="/lib"
# BASE_LIB_tune-x86=lib
BASE_LIB_tune-x86="lib"
# PACKAGEFUNCS=package_get_auto_pr                 perform_packagecopy                 ${PACKAGE_PREPROCESS_FUNCS} 		package_do_split_locales 		split_and_strip_files 		fixup_perms 		populate_packages 		package_do_filedeps 		package_do_shlibs 		package_do_pkgconfig 		read_shlibdeps 		package_depchains 		emit_pkgdata  do_package_qa 
PACKAGEFUNCS="package_get_auto_pr                 perform_packagecopy                  		package_do_split_locales 		split_and_strip_files 		fixup_perms 		populate_packages 		package_do_filedeps 		package_do_shlibs 		package_do_pkgconfig 		read_shlibdeps 		package_depchains 		emit_pkgdata  do_package_qa"
# PWD=/media/OE/poky/meta-ettus/recipes/hello/build
export PWD="/media/OE/poky/meta-ettus/recipes/hello/build"
# GCCVERSION=4.6%
GCCVERSION="4.6%"
# BASELIB_powerpc64=lib64
BASELIB_powerpc64="lib64"
# ERROR_QA=dev-so debug-deps dev-deps debug-files arch la2 pkgconfig la perms
ERROR_QA="dev-so debug-deps dev-deps debug-files arch la2 pkgconfig la perms"
# TUNE_FEATURES_tune-i586=${TUNE_FEATURES_tune-x86} i586
TUNE_FEATURES_tune-i586="m32 i586"
# GPE_SVN=svn://projects.linuxtogo.org/svn/gpe/trunk/base;module=${PN}
GPE_SVN="svn://projects.linuxtogo.org/svn/gpe/trunk/base;module=bblayers"
# EXTENDPKGV=${EXTENDPKGEVER}${PKGV}-${PKGR}
EXTENDPKGV="1.0-r0"
# CPPFLAGS=${TARGET_CPPFLAGS}
# PREFERRED_VERSION_gzip-native=1.4
PREFERRED_VERSION_gzip-native="1.4"
# docdir=${datadir}/doc
export docdir="/usr/share/doc"
# QAPATHTEST=None
# SSTATETASKS= do_populate_sysroot do_package do_package_write_rpm do_populate_lic
SSTATETASKS="do_populate_sysroot do_package do_package_write_rpm do_populate_lic"
# SOLIBS_darwin=.*.dylib
SOLIBS_darwin=".*.dylib"
# SSTATE_MANMACH=${SSTATE_PKGARCH}
SSTATE_MANMACH="i586"
# PREFERRED_PROVIDER_virtual/db=db
PREFERRED_PROVIDER_virtual/db="db"
# BP=${BPN}-${PV}
BP="bblayers-1.0"
# BBFILE_PATTERN_normal=^/media/OE/poky/meta/
BBFILE_PATTERN_normal="^/media/OE/poky/meta/"
# XLIBS_MIRROR=http://xlibs.freedesktop.org/release
XLIBS_MIRROR="http://xlibs.freedesktop.org/release"
# SDK_ARCH=${BUILD_ARCH}
SDK_ARCH="x86_64"
# SHELL=/bin/bash
export SHELL="/bin/bash"
# PREFERRED_PROVIDER_virtual/update-alternatives-native=opkg-native
PREFERRED_PROVIDER_virtual/update-alternatives-native="opkg-native"
# DEBUGFILEDIRECTORY-dbg=/usr/lib/debug /usr/src/debug
DEBUGFILEDIRECTORY-dbg="/usr/lib/debug /usr/src/debug"
# PREFERRED_VERSION_uclibc=${UCLIBCVERSION}
PREFERRED_VERSION_uclibc="0.9.33"
# DEPCHAIN_POST=-dev -dbg
DEPCHAIN_POST="-dev -dbg"
# PREFERRED_PROVIDER_xf86-video-intel=xf86-video-intel
PREFERRED_PROVIDER_xf86-video-intel="xf86-video-intel"
# SHLIBSDIR=${STAGING_DIR_HOST}/shlibs
SHLIBSDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/shlibs"
# BB_GENERATE_MIRROR_TARBALLS=0
BB_GENERATE_MIRROR_TARBALLS="0"
# GLIBC_ADDONS=nptl
GLIBC_ADDONS="nptl"
# SSTATE_DIR=${TOPDIR}/sstate-cache
SSTATE_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache"
# D=${WORKDIR}/image
D="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/image"
# TCMODE=default
TCMODE="default"
# IMAGE_ROOTFS_SIZE=65536
IMAGE_ROOTFS_SIZE="65536"
# DISTRO=poky
unset DISTRO
# RANLIB=${HOST_PREFIX}ranlib
export RANLIB="i586-poky-linux-ranlib"
# LOCALE_SECTION=
# RPMBUILD=rpmbuild
RPMBUILD="rpmbuild"
# LICENSE_DIRECTORY=${DEPLOY_DIR}/licenses
LICENSE_DIRECTORY="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses"
# T=${WORKDIR}/temp
T="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp"
# RDEPENDS_kernel-base=
# TUNE_FEATURES_tune-x86-64-x32=mx32
TUNE_FEATURES_tune-x86-64-x32="mx32"
# base_sbindir=${base_prefix}/sbin
export base_sbindir="/sbin"
# SYSROOT_LOCK=${STAGING_DIR}/staging.lock
SYSROOT_LOCK="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/staging.lock"
# RPM=rpm
RPM="rpm"
# ASNEEDED_pn-icu=
# LINKER_HASH_STYLE_mips64=sysv
LINKER_HASH_STYLE_mips64="sysv"
# COMMERCIAL_VIDEO_PLUGINS=
# STAGING_DIR_HOST=${STAGING_DIR}/${MACHINE}
STAGING_DIR_HOST="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# FETCHCOMMAND=ERROR, this must be a BitBake bug
FETCHCOMMAND="ERROR, this must be a BitBake bug"
# MACHINE_ARCH=${@[d.getVar('TUNE_PKGARCH', True), d.getVar('MACHINE', True)][bool(d.getVar('MACHINE', True))].replace('-', '_')}
MACHINE_ARCH="qemux86"
# BINUVERSION=2.22
BINUVERSION="2.22"
# datadir_native=${prefix_native}/share
datadir_native="/usr/share"
# PREFERRED_PROVIDER_virtual/libgl=mesa-dri
PREFERRED_PROVIDER_virtual/libgl="mesa-dri"
# SDKPATHNATIVE=${SDKPATH}/sysroots/${SDK_SYS}
SDKPATHNATIVE="/opt/poky/1.1+snapshot/sysroots/x86_64-pokysdk-linux"
# PREFERRED_PROVIDER_matchbox-panel=matchbox-panel-2
PREFERRED_PROVIDER_matchbox-panel="matchbox-panel-2"
# PREFERRED_VERSION_eglibc-initial-nativesdk=${EGLIBCVERSION}
PREFERRED_VERSION_eglibc-initial-nativesdk="2.13"
# PREFERRED_PROVIDER_virtual/libiconv=eglibc
PREFERRED_PROVIDER_virtual/libiconv="eglibc"
# PKG_CONFIG_LIBDIR=${PKG_CONFIG_DIR}
export PKG_CONFIG_LIBDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86//usr/lib/pkgconfig"
# PREFERRED_VERSION_binutils-crosssdk=${BINUVERSION}
PREFERRED_VERSION_binutils-crosssdk="2.22"
# PREFERRED_VERSION_uclibc-initial=${UCLIBCVERSION}
PREFERRED_VERSION_uclibc-initial="0.9.33"
# BUILD_CC_ARCH=
# DESCRIPTION_${PN}-doc=${DESCRIPTION}  This package contains documentation.
DESCRIPTION_bblayers-doc="bblayers version 1.0-r0  This package contains documentation."
# PKG_CONFIG_SYSROOT_DIR=${STAGING_DIR_HOST}
export PKG_CONFIG_SYSROOT_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# CXX=${CCACHE}${HOST_PREFIX}g++ ${HOST_CC_ARCH}${TOOLCHAIN_OPTIONS}
export CXX="ccache i586-poky-linux-g++  -m32   -march=i586 --sysroot=/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# SDK_VERSION=1.1+snapshot
SDK_VERSION="1.1+snapshot"
# BUILD_VENDOR=
# SSTATE_MANIFESTS=${TMPDIR}/sstate-control
SSTATE_MANIFESTS="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control"
# DEPCHAIN_PRE=
# SDK_VENDOR=-pokysdk
SDK_VENDOR="-pokysdk"
# GNOME_GIT=git://git.gnome.org
GNOME_GIT="git://git.gnome.org"
# RPROVIDES=
# PREFERRED_VERSION_gcc-runtime-nativesdk=${SDKGCCVERSION}
PREFERRED_VERSION_gcc-runtime-nativesdk="4.6%"
# PREFERRED_VERSION=None
# ASNEEDED=-Wl,--as-needed
ASNEEDED="-Wl,--as-needed"
# ALLOW_EMPTY_${PN}-dbg=1
ALLOW_EMPTY_bblayers-dbg="1"
# PKG_CONFIG_PATH=${PKG_CONFIG_DIR}:${STAGING_DATADIR}/pkgconfig
export PKG_CONFIG_PATH="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86//usr/lib/pkgconfig:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/share/pkgconfig"
# PREFERRED_PROVIDER_gzip-native=pigz-native
PREFERRED_PROVIDER_gzip-native="pigz-native"
# PREFERRED_PROVIDER_gdb=gdb
PREFERRED_PROVIDER_gdb="gdb"
# _=/media/OE/poky/bitbake/bin/bitbake
_="/media/OE/poky/bitbake/bin/bitbake"
# PACKAGE_EXTRA_ARCHS_tune-x86=x86
PACKAGE_EXTRA_ARCHS_tune-x86="x86"
# TCLIBC=eglibc
TCLIBC="eglibc"
# PREFERRED_PROVIDER_virtual/xserver=xserver-xorg
PREFERRED_PROVIDER_virtual/xserver="xserver-xorg"
# PKGDESTWORK=${WORKDIR}/pkgdata
PKGDESTWORK="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/pkgdata"
# SPDXLICENSEMAP=None
# CONF_VERSION=1
CONF_VERSION="1"
# PREFERRED_VERSION_linux-yocto=3.2%
PREFERRED_VERSION_linux-yocto="3.2%"
# STAGING_DIR_TARGET=${STAGING_DIR}/${MACHINE}
STAGING_DIR_TARGET="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86"
# IMAGE_ROOTFS_EXTRA_SPACE=0
IMAGE_ROOTFS_EXTRA_SPACE="0"
# FREEDESKTOP_CVS=cvs://anoncvs:anoncvs@anoncvs.freedesktop.org/cvs
FREEDESKTOP_CVS="cvs://anoncvs:anoncvs@anoncvs.freedesktop.org/cvs"
# HOST_AS_ARCH=${TARGET_AS_ARCH}
HOST_AS_ARCH=""
# BUILD_CPPFLAGS=-isystem${STAGING_INCDIR_NATIVE}
export BUILD_CPPFLAGS="-isystem/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/include"
# DEBUG_OPTIMIZATION=-O -fno-omit-frame-pointer ${DEBUG_FLAGS} -pipe
DEBUG_OPTIMIZATION="-O -fno-omit-frame-pointer -g -feliminate-unused-debug-types -pipe"
# RPMCONF_TARGET_BASE=${DEPLOY_DIR_RPM}/solvedb
RPMCONF_TARGET_BASE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb"
# IMAGE_OVERHEAD_FACTOR=1.3
IMAGE_OVERHEAD_FACTOR="1.3"
# SITE_CONF_VERSION=1
SITE_CONF_VERSION="1"
# TUNE_FEATURES=${TUNE_FEATURES_tune-${DEFAULTTUNE}}
TUNE_FEATURES="m32 i586"
# BUILD_NM=${BUILD_PREFIX}nm
export BUILD_NM="nm"
# CXXFLAGS=${TARGET_CXXFLAGS} -fvisibility-inlines-hidden
export CXXFLAGS="-O2 -pipe -g -feliminate-unused-debug-types -fpermissive -fvisibility-inlines-hidden"
# RDEPENDS_${PN}-dev=${PN} (= ${EXTENDPKGV})
RDEPENDS_bblayers-dev="bblayers (= 1.0-r0)"
# COMPATIBLE_MACHINE=None
# TARGET_VENDOR=-poky
TARGET_VENDOR="-poky"
# PREFERRED_VERSION_linux-yocto_qemux86-64=3.2%
PREFERRED_VERSION_linux-yocto_qemux86-64="3.2%"
# NM=${HOST_PREFIX}nm
export NM="i586-poky-linux-nm"
# SEPPUKU_ADDCOMMENT=None
# POKYQEMUDEPS=${@base_contains("INCOMPATIBLE_LICENSE", "GPLv3", "", "qemu-config",d)}
POKYQEMUDEPS="qemu-config"
# OE_IMPORTS= os sys time oe.path oe.utils oe.data oe.packagegroup oe.sstatesig
OE_IMPORTS="os sys time oe.path oe.utils oe.data oe.packagegroup oe.sstatesig"
# POKY_DEFAULT_EXTRA_RRECOMMENDS=kernel-module-af-packet
POKY_DEFAULT_EXTRA_RRECOMMENDS="kernel-module-af-packet"
# PREFERRED_VERSION_gcc-crosssdk=${SDKGCCVERSION}
PREFERRED_VERSION_gcc-crosssdk="4.6%"
# FILES_${PN}-locale=${datadir}/locale
FILES_bblayers-locale="/usr/share/locale"
# COMMON_LICENSE_DIR=${COREBASE}/meta/files/common-licenses
COMMON_LICENSE_DIR="/media/OE/poky/meta/files/common-licenses"
# PREFERRED_PROVIDER_virtual/fakeroot-native=pseudo-native
PREFERRED_PROVIDER_virtual/fakeroot-native="pseudo-native"
# TARGET_LINK_HASH_STYLE=${@['-Wl,--hash-style=gnu',''][d.getVar('LINKER_HASH_STYLE', True) != 'gnu']}
TARGET_LINK_HASH_STYLE="-Wl,--hash-style=gnu"
# DISTRO_FEATURES_BACKFILL=pulseaudio
DISTRO_FEATURES_BACKFILL="pulseaudio"
# HOSTTOOLS_WHITELIST_GPLv3=
# SERIAL_CONSOLE=115200 ttyS0
SERIAL_CONSOLE="115200 ttyS0"
# DISTRO_FEATURES_LIBC=ipv4 ipv6 libc-backtrace libc-big-macros libc-bsd libc-cxx-tests libc-catgets libc-charsets libc-crypt 					libc-crypt-ufc libc-db-aliases libc-envz libc-fcvt libc-fmtmsg libc-fstab libc-ftraverse 					libc-getlogin libc-idn libc-inet-anl libc-libm libc-libm-big libc-locales libc-locale-code 					libc-memusage libc-nis libc-nsswitch libc-rcmd libc-rtld-debug libc-spawn libc-streams libc-sunrpc 					libc-utmp libc-utmpx libc-wordexp libc-posix-clang-wchar libc-posix-regexp libc-posix-regexp-glibc 					libc-posix-wchar-io
DISTRO_FEATURES_LIBC="ipv4 ipv6 libc-backtrace libc-big-macros libc-bsd libc-cxx-tests libc-catgets libc-charsets libc-crypt 					libc-crypt-ufc libc-db-aliases libc-envz libc-fcvt libc-fmtmsg libc-fstab libc-ftraverse 					libc-getlogin libc-idn libc-inet-anl libc-libm libc-libm-big libc-locales libc-locale-code 					libc-memusage libc-nis libc-nsswitch libc-rcmd libc-rtld-debug libc-spawn libc-streams libc-sunrpc 					libc-utmp libc-utmpx libc-wordexp libc-posix-clang-wchar libc-posix-regexp libc-posix-regexp-glibc 					libc-posix-wchar-io"
# TRANSLATED_TARGET_ARCH=${@d.getVar('TARGET_ARCH', True).replace("_", "-")}
TRANSLATED_TARGET_ARCH="i586"
# BUILDSDK_CFLAGS=${BUILDSDK_CPPFLAGS} ${BUILD_OPTIMIZATION}
BUILDSDK_CFLAGS="-isystem/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/include -O2 -pipe"
# TUNE_PKGARCH=${@bb.utils.contains("TUNE_FEATURES", "i586", "i586", TUNE_PKGARCH_TMP, d)}${@bb.utils.contains("TUNE_FEATURES", "mx32", "_x32", "", d)}
TUNE_PKGARCH="i586"
# PRINC=0
PRINC="0"
# PREFERRED_PROVIDER_virtual/${TARGET_PREFIX}compilerlibs=gcc-runtime
PREFERRED_PROVIDER_virtual/i586-poky-linux-compilerlibs="gcc-runtime"
# CPU_FEATURES_arm=vfp
CPU_FEATURES_arm="vfp"
# TUNE_CCARGS= ${@bb.utils.contains("TUNE_FEATURES", "m32", "-m32", "", d)} ${@bb.utils.contains("TUNE_FEATURES", "mx32", "-mx32", "", d)} ${@bb.utils.contains("TUNE_FEATURES", "m64", "-m64", "", d)} ${@bb.utils.contains("TUNE_FEATURES", "i586", "-march=i586", "", d)}
TUNE_CCARGS="-m32   -march=i586"
# GNOME_KEYRING_PID=1418
GNOME_KEYRING_PID="1418"
# BB_HASHFILENAME=${SSTATE_PKGNAME}
BB_HASHFILENAME="sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH}"
# FETCHCMD_bzr=/usr/bin/env bzr
FETCHCMD_bzr="/usr/bin/env bzr"
# METADATA_REVISION=${@base_detect_revision(d)}
METADATA_REVISION="224ff370b4636cdd33c47c1e6341ef43a67e0227"
# BUILD_SYS=${BUILD_ARCH}${BUILD_VENDOR}-${BUILD_OS}
BUILD_SYS="x86_64-linux"
# BBFILE_PRIORITY_yocto=5
BBFILE_PRIORITY_yocto="5"
# BUILD_STRIP=${BUILD_PREFIX}strip
export BUILD_STRIP="strip"
# libdir_nativesdk=${prefix_nativesdk}/lib
libdir_nativesdk="/usr/lib"
# QEMU_OPTIONS_armv7a=-cpu cortex-a8
QEMU_OPTIONS_armv7a="-cpu cortex-a8"
# TCLIBCAPPEND=
# STAGING_DIR=${TMPDIR}/sysroots
STAGING_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots"
# PREFERRED_VERSION_gcc-cross-canadian-${TRANSLATED_TARGET_ARCH}=${GCCVERSION}
PREFERRED_VERSION_gcc-cross-canadian-i586="4.6%"
# MACHINE_ESSENTIAL_EXTRA_RRECOMMENDS=
# PREFERRED_VERSION_eglibc=${EGLIBCVERSION}
PREFERRED_VERSION_eglibc="2.13"
# BB_SIGNATURE_HANDLER=OEBasicHash
BB_SIGNATURE_HANDLER="OEBasicHash"
# LOCALE_UTF8_ONLY=0
LOCALE_UTF8_ONLY="0"
# PREFERRED_VERSION_linux-yocto_qemumips=3.2%
PREFERRED_VERSION_linux-yocto_qemumips="3.2%"
# VIRTUAL-RUNTIME_alsa-state=alsa-state
VIRTUAL-RUNTIME_alsa-state="alsa-state"
# PREFERRED_PROVIDER_virtual/db-native=db-native
PREFERRED_PROVIDER_virtual/db-native="db-native"
# LICENSE=INVALID
LICENSE="INVALID"
# prefix_nativesdk=/usr
prefix_nativesdk="/usr"
# COREBASE=/media/OE/poky
COREBASE="/media/OE/poky"
# GNOME_MIRROR=http://ftp.gnome.org/pub/GNOME/sources
GNOME_MIRROR="http://ftp.gnome.org/pub/GNOME/sources"
# PREFERRED_VERSION_libgcc=${GCCVERSION}
PREFERRED_VERSION_libgcc="4.6%"
# PACKAGES_DYNAMIC=${PN}-locale-*
PACKAGES_DYNAMIC="bblayers-locale-*"
# SSTATE_PKGSPEC=sstate-${PN}-${PACKAGE_ARCH}${TARGET_VENDOR}-${TARGET_OS}-${PV}-${PR}-${SSTATE_PKGARCH}-${SSTATE_VERSION}-
SSTATE_PKGSPEC="sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-"
# LOCALCONF_VERSION=1
LOCALCONF_VERSION="1"
# COMPATIBLE_HOST=None
# PREFERRED_PROVIDER_console-tools=kbd
PREFERRED_PROVIDER_console-tools="kbd"
# SSTATEPREINSTFUNCS=
# DEPLOY_DIR_IPK=${DEPLOY_DIR}/ipk
DEPLOY_DIR_IPK="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/ipk"
# SSH_AUTH_SOCK=/tmp/keyring-X2vmYv/ssh
SSH_AUTH_SOCK="/tmp/keyring-X2vmYv/ssh"
# STAGING_FIRMWARE_DIR=${STAGING_DIR_HOST}/firmware
STAGING_FIRMWARE_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/firmware"
# BBFILES= /media/OE/poky/meta/recipes-*/*/*.bb /media/OE/poky/meta-yocto/recipes-*/*/*.bb /media/OE/poky/meta-yocto/recipes-*/*/*.bbappend
BBFILES="/media/OE/poky/meta/recipes-*/*/*.bb /media/OE/poky/meta-yocto/recipes-*/*/*.bb /media/OE/poky/meta-yocto/recipes-*/*/*.bbappend"
# AS=${HOST_PREFIX}as ${HOST_AS_ARCH}
export AS="i586-poky-linux-as"
# BUILD_RANLIB=${BUILD_PREFIX}ranlib
export BUILD_RANLIB="ranlib"
# SSTATE_PKGARCH=${PACKAGE_ARCH}
SSTATE_PKGARCH="i586"
# PREFERRED_VERSION_gcc-runtime=${GCCVERSION}
PREFERRED_VERSION_gcc-runtime="4.6%"
# BNFILE=${BUILDSTATS_BASE}/.buildname
BNFILE="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/buildstats//.buildname"
# AUTOREV=${@bb.fetch2.get_autorev(d)}
AUTOREV="AUTOINC"
# WORKDIR=${TMPDIR}/work/${MULTIMACH_TARGET_SYS}/${PF}
WORKDIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0"
# bindir_nativesdk=${prefix_nativesdk}/bin
bindir_nativesdk="/usr/bin"
# do_package_write_ipk=None
# FETCHCOMMAND_svn=/usr/bin/env svn co ${SVNCOOPTS} ${SVNROOT} ${SVNMODULE}
FETCHCOMMAND_svn="/usr/bin/env svn co ${SVNCOOPTS} ${SVNROOT} ${SVNMODULE}"
# MIRRORS=ftp://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n http://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n https://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n  ${DEBIAN_MIRROR}/main	http://snapshot.debian.net/archive/pool \n ${DEBIAN_MIRROR}	ftp://ftp.de.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.au.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.cl.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.hr.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.fi.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.hk.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.hu.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.ie.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.it.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.jp.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.no.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.pl.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.ro.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.si.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.es.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.se.debian.org/debian/pool \n ${DEBIAN_MIRROR}	ftp://ftp.tr.debian.org/debian/pool \n ${GNU_MIRROR}	ftp://mirrors.kernel.org/gnu \n ${KERNELORG_MIRROR}	http://www.kernel.org/pub \n ${KERNELORG_MIRROR}	ftp://ftp.us.kernel.org/pub \n ${KERNELORG_MIRROR}	ftp://ftp.uk.kernel.org/pub \n ${KERNELORG_MIRROR}	ftp://ftp.hk.kernel.org/pub \n ${KERNELORG_MIRROR}	ftp://ftp.au.kernel.org/pub \n ${KERNELORG_MIRROR}	ftp://ftp.jp.kernel.org/pub \n ftp://ftp.gnupg.org/gcrypt/     ftp://ftp.franken.de/pub/crypt/mirror/ftp.gnupg.org/gcrypt/ \n ftp://ftp.gnupg.org/gcrypt/     ftp://ftp.surfnet.nl/pub/security/gnupg/ \n ftp://ftp.gnupg.org/gcrypt/     http://gulus.USherbrooke.ca/pub/appl/GnuPG/ \n ftp://dante.ctan.org/tex-archive ftp://ftp.fu-berlin.de/tex/CTAN \n ftp://dante.ctan.org/tex-archive http://sunsite.sut.ac.jp/pub/archives/ctan/ \n ftp://dante.ctan.org/tex-archive http://ctan.unsw.edu.au/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.gnutls.org/pub/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.gnupg.org/gcrypt/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls http://www.mirrors.wiretapped.net/security/network-security/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.mirrors.wiretapped.net/pub/security/network-security/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls http://josefsson.org/gnutls/releases/ \n http://ftp.info-zip.org/pub/infozip/src/ http://mirror.switch.ch/ftp/mirror/infozip/src/ \n http://ftp.info-zip.org/pub/infozip/src/ ftp://sunsite.icm.edu.pl/pub/unix/archiving/info-zip/src/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.cerias.purdue.edu/pub/tools/unix/sysutils/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tau.ac.il/pub/unix/admin/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.cert.dfn.de/pub/tools/admin/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.fu-berlin.de/pub/unix/tools/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.kaizo.org/pub/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tu-darmstadt.de/pub/sysadmin/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tux.org/pub/sites/vic.cc.purdue.edu/tools/unix/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://gd.tuwien.ac.at/utils/admin-tools/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://sunsite.ualberta.ca/pub/Mirror/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://the.wiretapped.net/pub/security/host-security/lsof/ \n http://www.apache.org/dist  http://archive.apache.org/dist \n cvs://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n svn://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n git://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n hg://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n bzr://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n svk://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n p4://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n osc://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n https?$://.*/.* http://downloads.yoctoproject.org/mirror/sources/ \n ftp://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n cvs://.*/.*     http://sources.openembedded.org/ \n svn://.*/.*     http://sources.openembedded.org/ \n git://.*/.*     http://sources.openembedded.org/ \n hg://.*/.*      http://sources.openembedded.org/ \n bzr://.*/.*     http://sources.openembedded.org/ \n svk://.*/.*     http://sources.openembedded.org/ \n p4://.*/.*      http://sources.openembedded.org/ \n osc://.*/.*     http://sources.openembedded.org/ \n https?$://.*/.* http://sources.openembedded.org/ \n ftp://.*/.*     http://sources.openembedded.org/ \n 
MIRRORS="ftp://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n http://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n https://.*/.*    http://downloads.yoctoproject.org/mirror/sources/ \n  ftp://ftp.debian.org/debian/pool/main	http://snapshot.debian.net/archive/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.de.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.au.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.cl.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.hr.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.fi.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.hk.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.hu.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.ie.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.it.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.jp.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.no.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.pl.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.ro.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.si.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.es.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.se.debian.org/debian/pool \n ftp://ftp.debian.org/debian/pool	ftp://ftp.tr.debian.org/debian/pool \n ftp://ftp.gnu.org/gnu	ftp://mirrors.kernel.org/gnu \n http://kernel.org/pub	http://www.kernel.org/pub \n http://kernel.org/pub	ftp://ftp.us.kernel.org/pub \n http://kernel.org/pub	ftp://ftp.uk.kernel.org/pub \n http://kernel.org/pub	ftp://ftp.hk.kernel.org/pub \n http://kernel.org/pub	ftp://ftp.au.kernel.org/pub \n http://kernel.org/pub	ftp://ftp.jp.kernel.org/pub \n ftp://ftp.gnupg.org/gcrypt/     ftp://ftp.franken.de/pub/crypt/mirror/ftp.gnupg.org/gcrypt/ \n ftp://ftp.gnupg.org/gcrypt/     ftp://ftp.surfnet.nl/pub/security/gnupg/ \n ftp://ftp.gnupg.org/gcrypt/     http://gulus.USherbrooke.ca/pub/appl/GnuPG/ \n ftp://dante.ctan.org/tex-archive ftp://ftp.fu-berlin.de/tex/CTAN \n ftp://dante.ctan.org/tex-archive http://sunsite.sut.ac.jp/pub/archives/ctan/ \n ftp://dante.ctan.org/tex-archive http://ctan.unsw.edu.au/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.gnutls.org/pub/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.gnupg.org/gcrypt/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls http://www.mirrors.wiretapped.net/security/network-security/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls ftp://ftp.mirrors.wiretapped.net/pub/security/network-security/gnutls/ \n ftp://ftp.gnutls.org/pub/gnutls http://josefsson.org/gnutls/releases/ \n http://ftp.info-zip.org/pub/infozip/src/ http://mirror.switch.ch/ftp/mirror/infozip/src/ \n http://ftp.info-zip.org/pub/infozip/src/ ftp://sunsite.icm.edu.pl/pub/unix/archiving/info-zip/src/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.cerias.purdue.edu/pub/tools/unix/sysutils/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tau.ac.il/pub/unix/admin/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.cert.dfn.de/pub/tools/admin/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.fu-berlin.de/pub/unix/tools/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.kaizo.org/pub/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tu-darmstadt.de/pub/sysadmin/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://ftp.tux.org/pub/sites/vic.cc.purdue.edu/tools/unix/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://gd.tuwien.ac.at/utils/admin-tools/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://sunsite.ualberta.ca/pub/Mirror/lsof/ \n ftp://lsof.itap.purdue.edu/pub/tools/unix/lsof/  ftp://the.wiretapped.net/pub/security/host-security/lsof/ \n http://www.apache.org/dist  http://archive.apache.org/dist \n cvs://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n svn://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n git://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n hg://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n bzr://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n svk://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n p4://.*/.*      http://downloads.yoctoproject.org/mirror/sources/ \n osc://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n https?$://.*/.* http://downloads.yoctoproject.org/mirror/sources/ \n ftp://.*/.*     http://downloads.yoctoproject.org/mirror/sources/ \n cvs://.*/.*     http://sources.openembedded.org/ \n svn://.*/.*     http://sources.openembedded.org/ \n git://.*/.*     http://sources.openembedded.org/ \n hg://.*/.*      http://sources.openembedded.org/ \n bzr://.*/.*     http://sources.openembedded.org/ \n svk://.*/.*     http://sources.openembedded.org/ \n p4://.*/.*      http://sources.openembedded.org/ \n osc://.*/.*     http://sources.openembedded.org/ \n https?$://.*/.* http://sources.openembedded.org/ \n ftp://.*/.*     http://sources.openembedded.org/ \n"
# DEPLOY_DIR_RPM=${DEPLOY_DIR}/rpm
DEPLOY_DIR_RPM="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm"
# PREFERRED_VERSION_eglibc-locale=${EGLIBCVERSION}
PREFERRED_VERSION_eglibc-locale="2.13"
# DISTRO_NAME=Yocto (Built by Poky 6.0)
DISTRO_NAME="Yocto (Built by Poky 6.0)"
# PERSISTENT_DIR=${TMPDIR}/cache
PERSISTENT_DIR="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/cache"
# CLEANFUNCS= sstate_cleanall
CLEANFUNCS="sstate_cleanall"
# AUTO_LIBNAME_PKGS=${PACKAGES}
AUTO_LIBNAME_PKGS="bblayers-dbg bblayers-staticdev bblayers bblayers-doc bblayers-dev bblayers-locale"
# NO32LIBS=1
NO32LIBS="1"
# SEPPUKU_ATTACHMENT=None
do_fetchall() {
	:

}

die() {
	bbfatal "$*"

}

base_do_install() {
	:

}

do_compile() {
	base_do_compile

}

resolve_package_rpm() {
	local conffile="$1"
	shift
	local pkg_name=""
	for solve in `cat ${conffile}`; do
		pkg_name=$(rpm -D "_dbpath $solve" -D "__dbi_txn create nofsync" -q --yaml $@ | grep -i 'Packageorigin' | cut -d : -f 2)
		if [ -n "$pkg_name" ]; then
			break;
		fi
	done
	echo $pkg_name

}

prelink_image() {
#	export PSEUDO_DEBUG=4
#	/bin/env | /bin/grep PSEUDO
#	echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH"
#	echo "LD_PRELOAD=$LD_PRELOAD"

	pre_prelink_size=`du -ks /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs | awk '{size = $1 ; print size }'`
	echo "Size before prelinking $pre_prelink_size."

	# We need a prelink conf on the filesystem, add one if it's missing
	if [ ! -e /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/etc/prelink.conf ]; then
		cp /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/etc/prelink.conf \
			/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/etc/prelink.conf
		dummy_prelink_conf=true;
	else
		dummy_prelink_conf=false;
	fi

	# prelink!
	/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/sbin/prelink --root /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs -amR -N -c /etc/prelink.conf

	# Remove the prelink.conf if we had to add it.
	if [ "$dummy_prelink_conf" = "true" ]; then
		rm -f /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/etc/prelink.conf
	fi

	pre_prelink_size=`du -ks /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs | awk '{size = $1 ; print size }'`
	echo "Size after prelinking $pre_prelink_size."

}

package_install_internal_rpm() {

	local target_rootfs="${INSTALL_ROOTFS_RPM}"
	local platform="${INSTALL_PLATFORM_RPM}"
	local platform_extra="${INSTALL_PLATFORM_EXTRA_RPM}"
	local confbase="${INSTALL_CONFBASE_RPM}"
	local package_to_install="${INSTALL_PACKAGES_RPM}"
	local package_attemptonly="${INSTALL_PACKAGES_ATTEMPTONLY_RPM}"
	local package_linguas="${INSTALL_PACKAGES_LINGUAS_RPM}"
	local providename="${INSTALL_PROVIDENAME_RPM}"
	local task="${INSTALL_TASK_RPM}"

	# Setup base system configuration
	mkdir -p ${target_rootfs}/etc/rpm/
	echo "${platform}-poky-linux" > ${target_rootfs}/etc/rpm/platform
	if [ ! -z "$platform_extra" ]; then
		for pt in $platform_extra ; do
			case $pt in
				noarch | any | all)
					os="`echo linux | sed "s,-.*,,"`.*"
					;;
				*)
					os="linux"
					;;
			esac
			echo "$pt-.*-$os" >> ${target_rootfs}/etc/rpm/platform
		done
	fi

	# Tell RPM that the "/" directory exist and is available
	mkdir -p ${target_rootfs}/etc/rpm/sysinfo
	echo "/" >${target_rootfs}/etc/rpm/sysinfo/Dirnames
	if [ ! -z "$providename" ]; then
		cat /dev/null > ${target_rootfs}/etc/rpm/sysinfo/Providename
		for provide in $providename ; do
			echo $provide >> ${target_rootfs}/etc/rpm/sysinfo/Providename
		done
	fi

	# Setup manifest of packages to install...
	mkdir -p ${target_rootfs}/install
	echo "# Install manifest" > ${target_rootfs}/install/install.manifest

	# Uclibc builds don't provide this stuff...
	if [ xlinux = "xlinux" ] || [ xlinux = "xlinux-gnueabi" ] ; then
		if [ ! -z "${package_linguas}" ]; then
			for pkg in ${package_linguas}; do
				echo "Processing $pkg..."

				archvar=base_archs
				manifest=install.manifest
				ml_prefix=`echo ${pkg} | cut -d'-' -f1`
				ml_pkg=$pkg
				for i in ${MULTILIB_PREFIX_LIST} ; do
					if [ ${ml_prefix} = ${i} ]; then
						ml_pkg=$(echo ${pkg} | sed "s,^${ml_prefix}-\(.*\),\1,")
						archvar=ml_archs
						manifest=install_multilib.manifest
						break
					fi
				done

				pkg_name=$(resolve_package_rpm ${confbase}-${archvar}.conf ${ml_pkg})
				if [ -z "$pkg_name" ]; then
					echo "Unable to find package $pkg ($ml_pkg)!"
					exit 1
				fi
				echo $pkg_name >> ${target_rootfs}/install/${manifest}
			done
		fi
	fi
	if [ ! -z "${package_to_install}" ]; then
		for pkg in ${package_to_install} ; do
			echo "Processing $pkg..."

			archvar=base_archs
			manifest=install.manifest
			ml_prefix=`echo ${pkg} | cut -d'-' -f1`
			ml_pkg=$pkg
			for i in ${MULTILIB_PREFIX_LIST} ; do
				if [ ${ml_prefix} = ${i} ]; then
					ml_pkg=$(echo ${pkg} | sed "s,^${ml_prefix}-\(.*\),\1,")
					archvar=ml_archs
					manifest=install_multilib.manifest
					break
				fi
			done

			pkg_name=$(resolve_package_rpm ${confbase}-${archvar}.conf ${ml_pkg})
			if [ -z "$pkg_name" ]; then
				echo "Unable to find package $pkg ($ml_pkg)!"
				exit 1
			fi
			echo $pkg_name >> ${target_rootfs}/install/${manifest}
		done
	fi

	# Normal package installation

	# Generate an install solution by doing a --justdb install, then recreate it with
	# an actual package install!
	rpm --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
		--predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
		-D "_dbpath ${target_rootfs}/install" -D "`cat ${confbase}-base_archs.macro`" \
		-D "__dbi_txn create nofsync" \
		-U --justdb --noscripts --notriggers --noparentdirs --nolinktos --ignoresize \
		${target_rootfs}/install/install.manifest

	if [ ! -z "${package_attemptonly}" ]; then
		echo "Adding attempt only packages..."
		for pkg in ${package_attemptonly} ; do
			echo "Processing $pkg..."
			archvar=base_archs
			ml_prefix=`echo ${pkg} | cut -d'-' -f1`
			ml_pkg=$pkg
			for i in ${MULTILIB_PREFIX_LIST} ; do
				if [ ${ml_prefix} = ${i} ]; then
					ml_pkg=$(echo ${pkg} | sed "s,^${ml_prefix}-\(.*\),\1,")
					archvar=ml_archs
					break
				fi
			done

			pkg_name=$(resolve_package_rpm ${confbase}-${archvar}.conf ${ml_pkg})
			if [ -z "$pkg_name" ]; then
				echo "Note: Unable to find package $pkg ($ml_pkg) -- PACKAGE_INSTALL_ATTEMPTONLY"
				continue
			fi
			echo "Attempting $pkg_name..." >> "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/log.do_${task}_attemptonly.${PID}"
			rpm --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
				--predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
				-D "_dbpath ${target_rootfs}/install" -D "`cat ${confbase}.macro`" \
				-D "__dbi_txn create nofsync private" \
				-U --justdb --noscripts --notriggers --noparentdirs --nolinktos --ignoresize \
			$pkg_name >> "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/log.do_${task}_attemptonly.${PID}" || true
		done
	fi

	#### Note: 'Recommends' is an arbitrary tag that means _SUGGESTS_ in OE-core..
	# Add any recommended packages to the image
	# RPM does not solve for recommended packages because they are optional...
	# So we query them and tree them like the ATTEMPTONLY packages above...
	# Change the loop to "1" to run this code...
	loop=0
	if [ $loop -eq 1 ]; then
	 echo "Processing recommended packages..."
	 cat /dev/null >  ${target_rootfs}/install/recommend.list
	 while [ $loop -eq 1 ]; do
		# Dump the full set of recommends...
		rpm --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
			--predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
			-D "_dbpath ${target_rootfs}/install" -D "`cat ${confbase}.macro`" \
			-D "__dbi_txn create nofsync private" \
			-qa --qf "[%{RECOMMENDS}\n]" | sort -u > ${target_rootfs}/install/recommend
		# Did we add more to the list?
		grep -v -x -F -f ${target_rootfs}/install/recommend.list ${target_rootfs}/install/recommend > ${target_rootfs}/install/recommend.new || true
		# We don't want to loop unless there is a change to the list!
		loop=0
		cat ${target_rootfs}/install/recommend.new | \
		 while read pkg ; do
			# Ohh there was a new one, we'll need to loop again...
			loop=1
			echo "Processing $pkg..."
			found=0
			for archvar in base_archs ml_archs ; do
				pkg_name=$(resolve_package_rpm ${confbase}-${archvar}.conf ${pkg})
				if [ -n "$pkg_name" ]; then
					found=1
					break
				fi
			done

			if [ $found -eq 0 ]; then
				echo "Note: Unable to find package $pkg -- suggests"
				echo "Unable to find package $pkg." >> "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/log.do_${task}_recommend.${PID}"
				continue
			fi
			echo "Attempting $pkg_name..." >> "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/log.do_{task}_recommend.${PID}"
			rpm --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
				--predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
				-D "_dbpath ${target_rootfs}/install" -D "`cat ${confbase}.macro`" \
				-D "__dbi_txn create nofsync private" \
				-U --justdb --noscripts --notriggers --noparentdirs --nolinktos --ignoresize \
				$pkg_name >> "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/log.do_${task}_recommend.${PID}" 2>&1 || true
		done
		cat ${target_rootfs}/install/recommend.list ${target_rootfs}/install/recommend.new | sort -u > ${target_rootfs}/install/recommend.new.list
		mv -f ${target_rootfs}/install/recommend.new.list ${target_rootfs}/install/recommend.list
		rm ${target_rootfs}/install/recommend ${target_rootfs}/install/recommend.new
	 done
	fi

	# Now that we have a solution, pull out a list of what to install...
	echo "Manifest: ${target_rootfs}/install/install.manifest"
	rpm -D "_dbpath ${target_rootfs}/install" -qa --yaml \
		-D "__dbi_txn create nofsync private" \
		| grep -i 'Packageorigin' | cut -d : -f 2 > ${target_rootfs}/install/install_solution.manifest

	touch ${target_rootfs}/install/install_multilib_solution.manifest

	if [ -e "${target_rootfs}/install/install_multilib.manifest" ]; then
		# multilib package installation

		# Generate an install solution by doing a --justdb install, then recreate it with
		# an actual package install!
		rpm --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
			--predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
			-D "_dbpath ${target_rootfs}/install" -D "`cat ${confbase}-ml_archs.macro`" \
			-D "__dbi_txn create nofsync" \
			-U --justdb --noscripts --notriggers --noparentdirs --nolinktos --ignoresize \
			${target_rootfs}/install/install_multilib.manifest

		# Now that we have a solution, pull out a list of what to install...
		echo "Manifest: ${target_rootfs}/install/install_multilib.manifest"
		rpm -D "_dbpath ${target_rootfs}/install" -qa --yaml \
			-D "__dbi_txn create nofsync private" \
			| grep -i 'Packageorigin' | cut -d : -f 2 > ${target_rootfs}/install/install_multilib_solution.manifest

	fi

	cat ${target_rootfs}/install/install_solution.manifest > ${target_rootfs}/install/total_solution.manifest
	cat ${target_rootfs}/install/install_multilib_solution.manifest >> ${target_rootfs}/install/total_solution.manifest

	# Construct install scriptlet wrapper
	cat << EOF > /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/scriptlet_wrapper
#!/bin/bash

export PATH="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin/crossscripts:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/sbin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/sbin:/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux//bin:/media/OE/poky/bitbake/bin/:/media/OE/poky/scripts:/media/OE/poky/bitbake/bin/:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/mmoselhy/.local/bin:/home/mmoselhy/bin:/media/OE/poky/scripts"
export D="${target_rootfs}"
export OFFLINE_ROOT="\$D"
export IPKG_OFFLINE_ROOT="\$D"
export OPKG_OFFLINE_ROOT="\$D"

\$2 \$1/\$3 \$4
if [ \$? -ne 0 ]; then
  mkdir -p \$1/etc/rpm-postinsts
  num=100
  while [ -e \$1/etc/rpm-postinsts/\${num} ]; do num=\$((num + 1)); done
  echo "#!\$2" > \$1/etc/rpm-postinsts/\${num}
  echo "# Arg: \$4" >> \$1/etc/rpm-postinsts/\${num}
  cat \$1/\$3 >> \$1/etc/rpm-postinsts/\${num}
  chmod +x \$1/etc/rpm-postinsts/\${num}
fi
EOF

	chmod 0755 /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/scriptlet_wrapper

    rpm_update_pkg


}

bbdebug() {
	USAGE='Usage: bbdebug [123] "message"'
	if [ $# -lt 2 ]; then
		bbfatal "$USAGE"
	fi

	# Strip off the debug level and ensure it is an integer
	DBGLVL=$1; shift
	if ! [[ "$DBGLVL" =~ ^[0-9]+ ]]; then
		bbfatal "$USAGE"
	fi

	# All debug output is printed to the logs
	echo "DEBUG: $*"

}

base_do_package() {
	:

}

do_configure() {
	base_do_configure

}

package_generate_rpm_conf() {
	# Update target packages
	package_generate_rpm_conf_common "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb" base_archs ml_archs

	# Update SDK packages
	package_generate_rpm_conf_common "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb-sdk" base_archs

}

oe_soinstall() {
	# Purpose: Install shared library file and
	#          create the necessary links
	# Example:
	#
	# oe_
	#
	#bbnote installing shared library $1 to $2
	#
	libname=`basename $1`
	install -m 755 $1 $2/$libname
	sonamelink=`i586-poky-linux-readelf -d $1 |grep 'Library soname:' |sed -e 's/.*\[\(.*\)\].*/\1/'`
	solink=`echo $libname | sed -e 's/\.so\..*/.so/'`
	ln -sf $libname $2/$sonamelink
	ln -sf $libname $2/$solink

}

oe_machinstall() {
	# Purpose: Install machine dependent files, if available
	#          If not available, check if there is a default
	#          If no default, just touch the destination
	# Example:
	#                $1  $2   $3         $4
	# oe_machinstall -m 0644 fstab /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/image/etc/fstab
	#
	# TODO: Check argument number?
	#
	filename=`basename $3`
	dirname=`dirname $3`

	for o in `echo linux:i586:build-linux:pn-bblayers:qemux86:x86:poky:forcevariable:libc-glibc | tr ':' ' '`; do
		if [ -e $dirname/$o/$filename ]; then
			bbnote $dirname/$o/$filename present, installing to $4
			install $1 $2 $dirname/$o/$filename $4
			return
		fi
	done
#	bbnote overrides specific file NOT present, trying default=$3...
	if [ -e $3 ]; then
		bbnote $3 present, installing to $4
		install $1 $2 $3 $4
	else
		bbnote $3 NOT present, touching empty $4
		touch $4
	fi

}

base_do_compile() {
	if [ -e Makefile -o -e makefile ]; then
		oe_runmake || die "make failed"
	else
		bbnote "nothing to compile"
	fi

}

bbfatal() {
	echo "ERROR: $*"
	exit 1

}

do_package_write() {
	:

}

sysroot_stage_dir() {
	src="$1"
	dest="$2"
	# if the src doesn't exist don't do anything
	if [ ! -d "$src" ]; then
		 return
	fi

	# We only want to stage the contents of $src if it's non-empty so first rmdir $src
	# then if it still exists (rmdir on non-empty dir fails) we can copy its contents
	rmdir "$src" 2> /dev/null || true
	# However we always want to stage a $src itself, even if it's empty
	mkdir -p "$dest"
	if [ -d "$src" ]; then
		tar -cf - -C "$src" -ps . | tar -xf - -C "$dest"
	fi

}

do_buildall() {
	:

}

create_cmdline_wrapper() {
   # Create a wrapper script
   #
   # These are useful to work around relocation issues, by setting environment
   # variables which point to paths in the filesystem.
   #
   # Usage: create_wrapper FILENAME [[VAR=VALUE]..]

   cmd=$1
   shift

   # run echo via env to test syntactic validity of the variable arguments
   echo "Generating wrapper script for $cmd"

   mv $cmd $cmd.real
   cmdname=`basename $cmd`.real
   cat <<END >$cmd
#!/bin/sh
realpath=\`readlink -fn \$0\`
exec \`dirname \$realpath\`/$cmdname $@ "\$@"
END
   chmod +x $cmd

}

oe_libinstall() {
	# Purpose: Install a library, in all its forms
	# Example
	#
	# oe_libinstall libltdl /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib/
	# oe_libinstall -C src/libblah libblah /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/image//usr/lib/
	dir=""
	libtool=""
	silent=""
	require_static=""
	require_shared=""
	staging_install=""
	while [ "$#" -gt 0 ]; do
		case "$1" in
		-C)
			shift
			dir="$1"
			;;
		-s)
			silent=1
			;;
		-a)
			require_static=1
			;;
		-so)
			require_shared=1
			;;
		-*)
			bbfatal "oe_libinstall: unknown option: $1"
			;;
		*)
			break;
			;;
		esac
		shift
	done

	libname="$1"
	shift
	destpath="$1"
	if [ -z "$destpath" ]; then
		bbfatal "oe_libinstall: no destination path specified"
	fi
	if echo "$destpath/" | egrep '^/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib/' >/dev/null
	then
		staging_install=1
	fi

	__runcmd () {
		if [ -z "$silent" ]; then
			echo >&2 "oe_libinstall: $*"
		fi
		$*
	}

	if [ -z "$dir" ]; then
		dir=`pwd`
	fi

	dotlai=$libname.lai

	# Sanity check that the libname.lai is unique
	number_of_files=`(cd $dir; find . -name "$dotlai") | wc -l`
	if [ $number_of_files -gt 1 ]; then
		bbfatal "oe_libinstall: $dotlai is not unique in $dir"
	fi


	dir=$dir`(cd $dir;find . -name "$dotlai") | sed "s/^\.//;s/\/$dotlai\$//;q"`
	olddir=`pwd`
	__runcmd cd $dir

	lafile=$libname.la

	# If such file doesn't exist, try to cut version suffix
	if [ ! -f "$lafile" ]; then
		libname1=`echo "$libname" | sed 's/-[0-9.]*$//'`
		lafile1=$libname.la
		if [ -f "$lafile1" ]; then
			libname=$libname1
			lafile=$lafile1
		fi
	fi

	if [ -f "$lafile" ]; then
		# libtool archive
		eval `cat $lafile|grep "^library_names="`
		libtool=1
	else
		library_names="$libname.so* $libname.dll.a $libname.*.dylib"
	fi

	__runcmd install -d $destpath/
	dota=$libname.a
	if [ -f "$dota" -o -n "$require_static" ]; then
		rm -f $destpath/$dota
		__runcmd install -m 0644 $dota $destpath/
	fi
	if [ -f "$dotlai" -a -n "$libtool" ]; then
		rm -f $destpath/$libname.la
		__runcmd install -m 0644 $dotlai $destpath/$libname.la
	fi

	for name in $library_names; do
		files=`eval echo $name`
		for f in $files; do
			if [ ! -e "$f" ]; then
				if [ -n "$libtool" ]; then
					bbfatal "oe_libinstall: $dir/$f not found."
				fi
			elif [ -L "$f" ]; then
				__runcmd cp -P "$f" $destpath/
			elif [ ! -L "$f" ]; then
				libfile="$f"
				rm -f $destpath/$libfile
				__runcmd install -m 0755 $libfile $destpath/
			fi
		done
	done

	if [ -z "$libfile" ]; then
		if  [ -n "$require_shared" ]; then
			bbfatal "oe_libinstall: unable to locate shared library"
		fi
	elif [ -z "$libtool" ]; then
		# special case hack for non-libtool .so.#.#.# links
		baselibfile=`basename "$libfile"`
		if (echo $baselibfile | grep -qE '^lib.*\.so\.[0-9.]*$'); then
			sonamelink=`i586-poky-linux-readelf -d $libfile |grep 'Library soname:' |sed -e 's/.*\[\(.*\)\].*/\1/'`
			solink=`echo $baselibfile | sed -e 's/\.so\..*/.so/'`
			if [ -n "$sonamelink" -a x"$baselibfile" != x"$sonamelink" ]; then
				__runcmd ln -sf $baselibfile $destpath/$sonamelink
			fi
			__runcmd ln -sf $baselibfile $destpath/$solink
		fi
	fi

	__runcmd cd "$olddir"

}

package_update_index_rpm_common() {
	rpmconf_base="$1"
	shift

	for archvar in "$@"; do
		eval archs=\${${archvar}}
		packagedirs=""
		for arch in $archs; do
			packagedirs="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/$arch $packagedirs"
			rm -rf /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/$arch/solvedb
		done

		cat /dev/null > ${rpmconf_base}-${archvar}.conf
		for pkgdir in $packagedirs; do
			if [ -e $pkgdir/ ]; then
				echo "Generating solve db for $pkgdir..."
				echo $pkgdir/solvedb >> ${rpmconf_base}-${archvar}.conf
				if [ -d $pkgdir/solvedb ]; then
					# We've already processed this and it's a duplicate
					continue
				fi
				mkdir -p $pkgdir/solvedb
				echo "# Dynamically generated solve manifest" >> $pkgdir/solvedb/manifest
				find $pkgdir -maxdepth 1 -type f >> $pkgdir/solvedb/manifest
				rpm -i --replacepkgs --replacefiles --oldpackage \
					-D "_dbpath $pkgdir/solvedb" --justdb \
					--noaid --nodeps --noorder --noscripts --notriggers --noparentdirs --nolinktos --stats \
					--ignoresize --nosignature --nodigest \
					-D "__dbi_txn create nofsync" \
					$pkgdir/solvedb/manifest
			fi
		done
	done

}

bbwarn() {
	echo "WARNING: $*"

}

base_do_configure() {
	:

}

rpm_common_comand() {

    local target_rootfs="${INSTALL_ROOTFS_RPM}"

    rpm --root ${target_rootfs} \
        --predefine "_rpmds_sysinfo_path ${target_rootfs}/etc/rpm/sysinfo" \
        --predefine "_rpmrc_platform_path ${target_rootfs}/etc/rpm/platform" \
        -D "_var /var" \
        -D "_dbpath ${rpmlibdir}" \
        --noparentdirs --nolinktos \
        -D "__dbi_txn create nofsync private" \
        -D "_cross_scriptlet_wrapper /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/scriptlet_wrapper" $@

}

bbnote() {
	echo "NOTE: $*"

}

do_install() {
	base_do_install

}

rpm_update_pkg() {

    local target_rootfs="${INSTALL_ROOTFS_RPM}"

    # Save the rpm's build time for incremental image generation, and the file
    # would be moved to /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp
    rm -f ${target_rootfs}/install/total_solution_bt.manifest
    for i in `cat ${target_rootfs}/install/total_solution.manifest`; do
        # Use "rpm" rather than "rpm" here, since we don't need the
        # '--dbpath' option
        echo "$i `rpm -qp --qf '%{BUILDTIME}\n' $i`" >> \
            ${target_rootfs}/install/total_solution_bt.manifest
    done

    # Only install the different pkgs if incremental image generation is set
    if [ "${INC_RPM_IMAGE_GEN}" = "1" -a -f /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/total_solution_bt.manifest -a \
        "rpm" = "rpm" ]; then
        cur_list="${target_rootfs}/install/total_solution_bt.manifest"
        pre_list="/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/temp/total_solution_bt.manifest"
        sort -u $cur_list -o $cur_list
        sort -u $pre_list -o $pre_list
        comm -1 -3 $cur_list $pre_list | sed 's#.*/\(.*\)\.rpm .*#\1#' > \
            ${target_rootfs}/install/remove.manifest
        comm -2 -3 $cur_list $pre_list | awk '{print $1}' > \
            ${target_rootfs}/install/incremental.manifest

        # Attempt to remove unwanted pkgs, the scripts(pre, post, etc.) has not
        # been run by now, so don't have to run them(preun, postun, etc.) when
        # erase the pkg
        if [ -s ${target_rootfs}/install/remove.manifest ]; then
            rpm_common_comand --noscripts --nodeps \
                -e `cat ${target_rootfs}/install/remove.manifest`
        fi

        # Attempt to install the incremental pkgs
        rpm_common_comand --nodeps --replacefiles --replacepkgs \
            -Uvh ${target_rootfs}/install/incremental.manifest
    else
        # Attempt to install
        rpm_common_comand --replacepkgs \
            -Uhv ${target_rootfs}/install/total_solution.manifest
    fi

}

sysroot_stage_dirs() {
	from="$1"
	to="$2"

	sysroot_stage_dir $from/usr/include $to/usr/include
	if [ "x86_64-linux" = "i586-poky-linux" ]; then
		sysroot_stage_dir $from/usr/bin $to/usr/bin
		sysroot_stage_dir $from/usr/sbin $to/usr/sbin
		sysroot_stage_dir $from/bin $to/bin
		sysroot_stage_dir $from/sbin $to/sbin
		sysroot_stage_dir $from/usr/libexec $to/usr/libexec
		sysroot_stage_dir $from/etc $to/etc
		sysroot_stage_dir $from/var $to/var
	fi
	if [ -d $from/usr/lib ]
	then
		sysroot_stage_libdir $from//usr/lib $to/usr/lib
	fi
	if [ -d $from/lib ]
	then
		sysroot_stage_libdir $from/lib $to/lib
	fi
	sysroot_stage_dir $from/usr/share $to/usr/share

}

sstate_create_package() {
	cd ${SSTATE_BUILDDIR}
	# Need to handle empty directories
	if [ "$(ls -A)" ]; then
		tar -czf /media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH} *
	else
		tar -cz --file=/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH} --files-from=/dev/null
	fi

	cd /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0
	rm -rf ${SSTATE_BUILDDIR}

}

bbplain() {
	echo "$*"

}

ldconfig_postinst_fragment() {
if [ x"$D" = "x" ]; then
	[ -x /sbin/ldconfig ] && /sbin/ldconfig
fi

}

do_checkuriall() {
	:

}

packagedstaging_fastpath() {
	:

}

rpm_log_check() {
       target="$1"
       lf_path="$2"

       lf_txt="`cat $lf_path`"
       for keyword_die in "Cannot find package" "exit 1" ERR Fail
       do
               if (echo "$lf_txt" | grep -v log_check | grep "$keyword_die") >/dev/null 2>&1
               then
                       echo "log_check: There were error messages in the logfile"
                       echo -e "log_check: Matched keyword: [$keyword_die]\n"
                       echo "$lf_txt" | grep -v log_check | grep -C 5 -i "$keyword_die"
                       echo ""
                       do_exit=1
               fi
       done
       test "$do_exit" = 1 && exit 1
       true

}

do_build() {
	:

}

sstate_unpack_package() {
	mkdir -p ${SSTATE_INSTDIR}
	cd ${SSTATE_INSTDIR}
	tar -xvzf /media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/sstate-bblayers-i586-poky-linux-1.0-r0-i586-2-${BB_TASKHASH}

}

package_update_index_rpm() {
	if [ ! -z "${DEPLOY_KEEP_PACKAGES}" ]; then
		return
	fi

	# Update target packages
	base_archs="all any noarch x86 i386 i486 i586 qemux86"
	ml_archs="${MULTILIB_PACKAGE_ARCHS}"
	package_update_index_rpm_common "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb" base_archs ml_archs

	# Update SDK packages
	base_archs="all any noarch x86_64-nativesdk"
	package_update_index_rpm_common "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/rpm/solvedb-sdk" base_archs

}

sysroot_stage_all() {
	sysroot_stage_dirs /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/image /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/sysroot-destdir/

}

license_create_manifest() {
    mkdir -p /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305
    # Get list of installed packages
    list_installed_packages | grep -v "locale" |sort > /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/package.manifest
    INSTALLED_PKGS=`cat /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/package.manifest`
    # list of installed packages is broken for deb
    for pkg in ${INSTALLED_PKGS}; do
        # not the best way to do this but licenses are not arch dependant iirc
        files=`find /media/OE/poky/meta-ettus/recipes/hello/build/tmp/pkgdata/*/runtime -name ${pkg}| head -1`
        for filename in $files; do
            pkged_pn="$(sed -n 's/^PN: //p' ${filename})"
            pkged_lic="$(sed -n '/^LICENSE: /{ s/^LICENSE: //; s/[+|&()*]/ /g; s/  */ /g; p }' ${filename})"
            # check to see if the package name exists in the manifest. if so, bail.
            if ! grep -q "PACKAGE NAME: ${pkg}" ${filename}; then
                # exclude local recipes
                if [ ! "${pkged_pn}" = "*locale*" ]; then
                    echo "PACKAGE NAME:" ${pkg} >> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                    echo "RECIPE NAME:" ${pkged_pn} >> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                    echo "LICENSE: " >> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                    for lic in ${pkged_lic}; do
                        if [ -e "/media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/${pkged_pn}/generic_${lic}" ]; then
                            echo ${lic}|sed s'/generic_//'g >> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                        else
                            echo "WARNING: The license listed, " ${lic} " was not in the licenses collected for " ${pkged_pn}>> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                        fi
                    done
                    echo "" >> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest
                fi
            fi
        done
    done

    # Two options here:
    # - Just copy the manifest
    # - Copy the manifest and the license directories
    # With both options set we see a .5 M increase in core-image-minimal
    if [ -n "${COPY_LIC_MANIFEST}" ]; then
        mkdir -p /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/
        cp /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/bblayers-qemux86-20120323091305/license.manifest /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/license.manifest
        if [ -n "${COPY_LIC_DIRS}" ]; then
            for pkg in ${INSTALLED_PKGS}; do
                mkdir -p /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/${pkg}
                for lic in `ls /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/${pkg}`; do
                    # Really don't need to copy the generics as they're
                    # represented in the manifest and in the actual pkg licenses
                    # Doing so would make your image quite a bit larger
                    if [[ "${lic}" != "generic_"* ]]; then
                        cp /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/${pkg}/${lic} /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/${pkg}/${lic}
                    elif [[ "${lic}" == "generic_"* ]]; then
                        if [ ! -f /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/${lic} ]; then
                            cp /media/OE/poky/meta-ettus/recipes/hello/build/tmp/deploy/licenses/${pkg}/${lic} /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/
                        fi
                        ln -s ../${lic} /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs/usr/share/common-licenses/${pkg}/${lic}
                    fi
                done
            done
        fi
    fi


}

mklibs_optimize_image() {
	for img in ${MKLIBS_OPTIMIZED_IMAGES}
	do
		if [ "${img}" = "bblayers" ] || [ "${img}" = "all" ]
		then
			mklibs_optimize_image_doit
			break
		fi
	done

}

oe_runmake() {
	if [ x"$MAKE" = x ]; then MAKE=make; fi
	bbnote make -e MAKEFLAGS= "$@"
	make -e MAKEFLAGS= "$@" || die "oe_runmake failed"

}

create_wrapper() {
   # Create a wrapper script
   #
   # These are useful to work around relocation issues, by setting environment
   # variables which point to paths in the filesystem.
   #
   # Usage: create_wrapper FILENAME [[VAR=VALUE]..]

   cmd=$1
   shift

   # run echo via env to test syntactic validity of the variable arguments
   env $@ echo "Generating wrapper script for $cmd"

   mv $cmd $cmd.real
   cmdname=`basename $cmd`.real
   cat <<END >$cmd
#!/bin/sh
realpath=\`readlink -fn \$0\`
exec env $@ \`dirname \$realpath\`/$cmdname "\$@"
END
   chmod +x $cmd

}

bberror() {
	echo "ERROR: $*"

}

mklibs_optimize_image_doit() {
	rm -rf /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs
	mkdir -p /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/dest
	cd /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs
	du -bs > /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/du.before.mklibs.txt
	for i in `find .`; do file $i; done \
		| grep ELF \
		| grep "LSB executable" \
		| grep "dynamically linked" \
		| sed "s/:.*//" \
		| sed "s+^\./++" \
		> /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/executables.list

	case i586 in
		powerpc | mips | microblaze )
			dynamic_loader="/lib/ld.so.1"
			;;
		powerpc64)
			dynamic_loader="/lib/ld64.so.1"
			;;
		x86_64)
			dynamic_loader="/lib/ld-linux-x86-64.so.2"
			;;
		i586 )
			dynamic_loader="/lib/ld-linux.so.2"
			;;
		arm )
			dynamic_loader="/lib/ld-linux.so.3"
			;;
		* )
			dynamic_loader="/unknown_dynamic_linker"
			;;
	esac

	mklibs -v \
		--ldlib ${dynamic_loader} \
		--sysroot /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86 \
		--root /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs \
		--target `echo i586-poky-linux- | sed 's/-$//' ` \
		-d /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/dest \
		`cat /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/executables.list`

	cd /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/dest
	for i in *
	do
		cp $i `find /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs -name $i`
	done

	cd /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/rootfs
	du -bs > /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/du.after.mklibs.txt

	echo rootfs size before mklibs optimization: `cat /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/du.before.mklibs.txt`
	echo rootfs size after mklibs optimization: `cat /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/mklibs/du.after.mklibs.txt`

}

package_generate_rpm_conf_common() {
	rpmconf_base="$1"
	shift

	printf "_solve_dbpath " > ${rpmconf_base}.macro
	o_colon="false"

	for archvar in "$@"; do
		printf "_solve_dbpath " > ${rpmconf_base}-${archvar}.macro
		colon="false"
		for each in `cat ${rpmconf_base}-${archvar}.conf` ; do
			if [ "$o_colon" = "true" ]; then
				printf ":" >> ${rpmconf_base}.macro
			fi
			if [ "$colon" = "true" ]; then
				printf ":" >> ${rpmconf_base}-${archvar}.macro
			fi
			printf "%s" $each >> ${rpmconf_base}.macro
			o_colon="true"
			printf "%s" $each >> ${rpmconf_base}-${archvar}.macro
			colon="true"
		done
		printf "\n" >> ${rpmconf_base}-${archvar}.macro
	done
	printf "\n" >> ${rpmconf_base}.macro

}

sysroot_stage_libdir() {
	src="$1"
	dest="$2"

	sysroot_stage_dir $src $dest

}



python check_sanity_tmpdir_change () {
def check_sanity_tmpdir_change(tmpdir, data):
    # Sanity checks to be done when the value of TMPDIR changes

    # Check that TMPDIR isn't on a filesystem with limited filename length (eg. eCryptFS)
    testmsg = check_create_long_filename(tmpdir, "TMPDIR")
    # Check that we can fetch from various network transports
    testmsg = testmsg + check_connectivity(data)
    return testmsg
}


python do_devshell () {
    oe_terminal(d.getVar('SHELL', True), 'OpenEmbedded Developer Shell', d)
}


python oe_import_eh () {
    if isinstance(e, bb.event.ConfigParsed):
	oe_import(e.data)
}


python do_listtasks () {
	import sys
	# emit variables and shell functions
	#bb.data.emit_env(sys.__stdout__, d)
	# emit the metadata which isnt valid shell
	for e in d.keys():
		if d.getVarFlag(e, 'task'):
			bb.plain("%s" % e)
}


python package_qa_clean_path () {
def package_qa_clean_path(path,d):
    """ Remove the common prefix from the path. In this case it is the TMPDIR"""
    return path.replace(d.getVar('TMPDIR',True),"")
}


python gen_packagevar () {
def gen_packagevar(d):
    ret = []
    pkgs = (d.getVar("PACKAGES", True) or "").split()
    vars = (d.getVar("PACKAGEVARS", True) or "").split()
    for p in pkgs:
        for v in vars:
            ret.append(v + "_" + p)
    return " ".join(ret)
}


python do_cleansstate () {
        sstate_clean_cachefiles(d)
}


python package_rpm_fn () {
	d.setVar('PKGFN', d.getVar('PKG'))
}


python machine_paths () {
def machine_paths(d):
    """List any existing machine specific filespath directories"""
    machine = d.getVar("MACHINE", True)
    filespathpkg = d.getVar("FILESPATHPKG", True).split(":")
    for basepath in d.getVar("FILESPATHBASE", True).split(":"):
        for pkgpath in filespathpkg:
            machinepath = os.path.join(basepath, pkgpath, machine)
            if os.path.isdir(machinepath):
                yield machinepath
}


python run_buildstats () {
    import bb.build
    import bb.event
    import bb.data
    import time, subprocess, platform

    if isinstance(e, bb.event.BuildStarted):
        ########################################################################
        # at first pass make the buildstats heriarchy and then
        # set the buildname
        ########################################################################
        try:
            bb.mkdirhier(e.data.getVar('BUILDSTATS_BASE', True))
        except:
            pass
        set_bn(e)
        bn = get_bn(e)
        set_device(e)
        device = get_device(e)

        bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
        try:
            bb.mkdirhier(bsdir)
        except:
            pass
        if device != "NoLogicalDevice":
            set_diskdata("__diskdata_build", device, e.data)
        set_timedata("__timedata_build", e.data)
        build_time = os.path.join(bsdir, "build_stats")
        # write start of build into build_time
        file = open(build_time,"a")
        host_info = platform.uname()
        file.write("Host Info: ")
        for x in host_info:
            if x:
                file.write(x + " ")
        file.write("\n")
        file.write("Build Started: %0.2f \n" % time.time())
        file.close()

    elif isinstance(e, bb.event.BuildCompleted):
        bn = get_bn(e)
        device = get_device(e)
        bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
        taskdir = os.path.join(bsdir, e.data.expand("bblayers-1.0-r0"))
        build_time = os.path.join(bsdir, "build_stats")
        file = open(build_time, "a")
        ########################################################################
        # Write build statistics for the build
        ########################################################################
        timedata = get_timedata("__timedata_build", e.data)
        if timedata:
            time, cpu = timedata
            # write end of build and cpu used into build_time
            file = open(build_time, "a")
            file.write("Elapsed time: %0.2f seconds \n" % (time))
            if cpu:
                file.write("CPU usage: %0.1f%% \n" % cpu)
        if device != "NoLogicalDevice":
            diskio = get_diskdata("__diskdata_build", device, e.data)
            if diskio:
                for key in sorted(diskio.iterkeys()):
                    file.write(key + ": " + diskio[key] + "\n")
        file.close()

    if isinstance(e, bb.build.TaskStarted):
        bn = get_bn(e)
        device = get_device(e)
        bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
        taskdir = os.path.join(bsdir, e.data.expand("bblayers-1.0-r0"))
        if device != "NoLogicalDevice":
            set_diskdata("__diskdata_task", device, e.data)
        set_timedata("__timedata_task", e.data)
        try:
            bb.mkdirhier(taskdir)
        except:
            pass
        # write into the task event file the name and start time
        file = open(os.path.join(taskdir, e.task), "a")
        file.write("Event: %s \n" % bb.event.getName(e))
        file.write("Started: %0.2f \n" % time.time())
        file.close()

    elif isinstance(e, bb.build.TaskSucceeded):
        bn = get_bn(e)
        device = get_device(e)
        bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
        taskdir = os.path.join(bsdir, e.data.expand("bblayers-1.0-r0"))
        write_task_data("passed", os.path.join(taskdir, e.task), device, e)
        if e.task == "do_rootfs":
            bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
            bs=os.path.join(bsdir, "build_stats")
            file = open(bs,"a")
            rootfs = e.data.getVar('IMAGE_ROOTFS', True)
            rootfs_size = subprocess.Popen(["du", "-sh", rootfs], stdout=subprocess.PIPE).stdout.read()
            file.write("Uncompressed Rootfs size: %s" % rootfs_size)
            file.close()

    elif isinstance(e, bb.build.TaskFailed):
        bn = get_bn(e)
        device = get_device(e)
        bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
        taskdir = os.path.join(bsdir, e.data.expand("bblayers-1.0-r0"))
        write_task_data("failed", os.path.join(taskdir, e.task), device, e)
        ########################################################################
        # Lets make things easier and tell people where the build failed in
        # build_status. We do this here because BuildCompleted triggers no
        # matter what the status of the build actually is
        ########################################################################
        build_status = os.path.join(bsdir, "build_stats")
        file = open(build_status,"a")
        file.write(e.data.expand("Failed at: bblayers-1.0-r0 at task: %s \n" % e.task))
        file.close()

}


python splitfile2 () {
def splitfile2(debugsrcdir, d):
    # Function to split a single file, called from split_and_strip_files below
    #
    # The debug src information processed in the splitfile2 is further procecessed
    # and copied to the destination here.

    import commands, stat

    sourcefile = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/debugsources.list")
    if debugsrcdir and os.path.isfile(sourcefile):
       dvar = d.getVar('PKGD', True)
       pathprefix = "export PATH=%s; " % d.getVar('PATH', True)
       strip = d.getVar("STRIP", True)
       objcopy = d.getVar("OBJCOPY", True)
       debugedit = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/bin/debugedit")
       workdir = d.getVar("WORKDIR", True)
       workparentdir = os.path.dirname(workdir)
       workbasedir = os.path.basename(workdir)

       nosuchdir = []
       basepath = dvar
       for p in debugsrcdir.split("/"):
           basepath = basepath + "/" + p
           if not os.path.exists(basepath):
               nosuchdir.append(basepath)
       bb.mkdirhier(basepath)

       processdebugsrc =  "LC_ALL=C ; sort -z -u '%s' | egrep -v -z '(<internal>|<built-in>)$' | "
       # We need to ignore files that are not actually ours
       # we do this by only paying attention to items from this package
       processdebugsrc += "fgrep -z '%s' | "
       processdebugsrc += "(cd '%s' ; cpio -pd0mL --no-preserve-owner '%s%s' 2>/dev/null)"

       os.system(processdebugsrc % (sourcefile, workbasedir, workparentdir, dvar, debugsrcdir))

       # The copy by cpio may have resulted in some empty directories!  Remove these
       for root, dirs, files in os.walk("%s%s" % (dvar, debugsrcdir)):
          for d in dirs:
              dir = os.path.join(root, d)
              #bb.note("rmdir -p %s" % dir)
              os.system("rmdir -p %s 2>/dev/null" % dir)

       # Also remove debugsrcdir if its empty
       for p in nosuchdir[::-1]:
           if os.path.exists(p) and not os.listdir(p):
               os.rmdir(p)
}


python incompatible_license () {
def incompatible_license(d,dont_want_license):
    """
    This function checks if a package has only incompatible licenses. It also take into consideration 'or'
    operand.
    """
    import re
    import oe.license
    from fnmatch import fnmatchcase as fnmatch

    dont_want_licenses = []
    dont_want_licenses.append(d.getVar('INCOMPATIBLE_LICENSE', True))
    if d.getVarFlag('SPDXLICENSEMAP', dont_want_license):
	dont_want_licenses.append(d.getVarFlag('SPDXLICENSEMAP', dont_want_license))

    def include_license(license):
	if any(fnmatch(license, pattern) for pattern in dont_want_licenses):
	    return False
	else:
	    spdx_license = d.getVarFlag('SPDXLICENSEMAP', license)
	    if spdx_license and any(fnmatch(spdx_license, pattern) for pattern in dont_want_licenses):
		return False
	    else:
		return True

    def choose_licenses(a, b):
        if all(include_license(lic) for lic in a):
		return a
        else:
		return b

    """
    If you want to exlude license named generically 'X', we surely want to exlude 'X+' as well.
    In consequence, we will exclude the '+' character from LICENSE in case INCOMPATIBLE_LICENSE
    is not a 'X+' license.
    """
    if not re.search(r'[+]',dont_want_license):
	licenses=oe.license.flattened_licenses(re.sub(r'[+]', '', d.getVar('LICENSE', True)), choose_licenses)
    else:
	licenses=oe.license.flattened_licenses(d.getVar('LICENSE', True), choose_licenses)

    for onelicense in licenses:
	if not include_license(onelicense):
		return True
    return False

}


python base_version_less_or_equal () {
def base_version_less_or_equal(variable, checkvalue, truevalue, falsevalue, d):
    return oe.utils.version_less_or_equal(variable, checkvalue, truevalue, falsevalue, d)
}


python do_package_setscene () {
	sstate_setscene(d)
}


python base_dep_prepend () {
None}


python get_cputime () {
def get_cputime():
    fields = open("/proc/stat", "r").readline().rstrip().split()[1:]
    return sum(int(field) for field in fields)
}


python fixup_perms () {
	import os, pwd, grp

	# init using a string with the same format as a line as documented in
	# the fs-perms.txt file
	# <path> <mode> <uid> <gid> <walk> <fmode> <fuid> <fgid>
	# <path> link <link target>
	#
	# __str__ can be used to print out an entry in the input format
	#
	# if fs_perms_entry.path is None:
	#	an error occured
	# if fs_perms_entry.link, you can retrieve:
	#	fs_perms_entry.path = path
	#	fs_perms_entry.link = target of link
	# if not fs_perms_entry.link, you can retrieve:
	#	fs_perms_entry.path = path
	#	fs_perms_entry.mode = expected dir mode or None
	#	fs_perms_entry.uid = expected uid or -1
	#	fs_perms_entry.gid = expected gid or -1
	#	fs_perms_entry.walk = 'true' or something else
	#	fs_perms_entry.fmode = expected file mode or None
	#	fs_perms_entry.fuid = expected file uid or -1
	#	fs_perms_entry_fgid = expected file gid or -1
	class fs_perms_entry():
		def __init__(self, line):
			lsplit = line.split()
			if len(lsplit) == 3 and lsplit[1].lower() == "link":
				self._setlink(lsplit[0], lsplit[2])
			elif len(lsplit) == 8:
				self._setdir(lsplit[0], lsplit[1], lsplit[2], lsplit[3], lsplit[4], lsplit[5], lsplit[6], lsplit[7])
			else:
				bb.error("Fixup Perms: invalid config line %s" % line)
				self.path = None
				self.link = None

		def _setdir(self, path, mode, uid, gid, walk, fmode, fuid, fgid):
			self.path = os.path.normpath(path)
			self.link = None
			self.mode = self._procmode(mode)
			self.uid  = self._procuid(uid)
			self.gid  = self._procgid(gid)
			self.walk = walk.lower()
			self.fmode = self._procmode(fmode)
			self.fuid = self._procuid(fuid)
			self.fgid = self._procgid(fgid)

		def _setlink(self, path, link):
			self.path = os.path.normpath(path)
			self.link = link

		def _procmode(self, mode):
			if not mode or (mode and mode == "-"):
				return None
			else:
				return int(mode,8)

		# Note uid/gid -1 has special significance in os.lchown
		def _procuid(self, uid):
			if uid is None or uid == "-":
				return -1
			elif uid.isdigit():
				return int(uid)
			else:
				return pwd.getpwnam(uid).pw_uid

		def _procgid(self, gid):
			if gid is None or gid == "-":
				return -1
			elif gid.isdigit():
				return int(gid)
			else:
				return grp.getgrnam(gid).gr_gid

		# Use for debugging the entries
		def __str__(self):
			if self.link:
				return "%s link %s" % (self.path, self.link)
			else:
				mode = "-"
				if self.mode:
					mode = "0%o" % self.mode
				fmode = "-"
				if self.fmode:
					fmode = "0%o" % self.fmode
				uid = self._mapugid(self.uid)
				gid = self._mapugid(self.gid)
				fuid = self._mapugid(self.fuid)
				fgid = self._mapugid(self.fgid)
				return "%s %s %s %s %s %s %s %s" % (self.path, mode, uid, gid, self.walk, fmode, fuid, fgid)

		def _mapugid(self, id):
			if id is None or id == -1:
				return "-"
			else:
				return "%d" % id

	# Fix the permission, owner and group of path
	def fix_perms(path, mode, uid, gid, dir):
		if mode and not os.path.islink(path):
			#bb.note("Fixup Perms: chmod 0%o %s" % (mode, dir))
			os.chmod(path, mode)
		# -1 is a special value that means don't change the uid/gid
		# if they are BOTH -1, don't bother to lchown
		if not (uid == -1 and gid == -1):
			#bb.note("Fixup Perms: lchown %d:%d %s" % (uid, gid, dir))
			os.lchown(path, uid, gid)

	# Return a list of configuration files based on either the default
	# files/fs-perms.txt or the contents of FILESYSTEM_PERMS_TABLES
	# paths are resolved via BBPATH
	def get_fs_perms_list(d):
		str = ""
		fs_perms_tables = d.getVar('FILESYSTEM_PERMS_TABLES', True)
		if not fs_perms_tables:
			fs_perms_tables = 'files/fs-perms.txt'
		for conf_file in fs_perms_tables.split():
			str += " %s" % bb.which(d.getVar('BBPATH', True), conf_file)
		return str



	dvar = d.getVar('PKGD', True)

	fs_perms_table = {}

	# By default all of the standard directories specified in
	# bitbake.conf will get 0755 root:root.
	target_path_vars = [	'base_prefix',
				'prefix',
				'exec_prefix',
				'base_bindir',
				'base_sbindir',
				'base_libdir',
				'datadir',
				'sysconfdir',
				'servicedir',
				'sharedstatedir',
				'localstatedir',
				'infodir',
				'mandir',
				'docdir',
				'bindir',
				'sbindir',
				'libexecdir',
				'libdir',
				'includedir',
				'oldincludedir' ]

	for path in target_path_vars:
		dir = d.getVar(path, True) or ""
		if dir == "":
			continue
		fs_perms_table[dir] = fs_perms_entry(bb.data.expand("%s 0755 root root false - - -" % (dir), d))

	# Now we actually load from the configuration files
	for conf in get_fs_perms_list(d).split():
		if os.path.exists(conf):
			f = open(conf)
			for line in f:
				if line.startswith('#'):
					continue
				lsplit = line.split()
				if len(lsplit) == 0:
					continue
				if len(lsplit) != 8 and not (len(lsplit) == 3 and lsplit[1].lower() == "link"):
					bb.error("Fixup perms: %s invalid line: %s" % (conf, line))
					continue
				entry = fs_perms_entry(d.expand(line))
				if entry and entry.path:
					fs_perms_table[entry.path] = entry
			f.close()

	# Debug -- list out in-memory table
	#for dir in fs_perms_table:
	#	bb.note("Fixup Perms: %s: %s" % (dir, str(fs_perms_table[dir])))

	# We process links first, so we can go back and fixup directory ownership
	# for any newly created directories
	for dir in fs_perms_table:
		if not fs_perms_table[dir].link:
			continue

		origin = dvar + dir
		if not (os.path.exists(origin) and os.path.isdir(origin) and not os.path.islink(origin)):
			continue

		link = fs_perms_table[dir].link
		if link[0] == "/":
			target = dvar + link
			ptarget = link
		else:
			target = os.path.join(os.path.dirname(origin), link)
			ptarget = os.path.join(os.path.dirname(dir), link)
		if os.path.exists(target):
			bb.error("Fixup Perms: Unable to correct directory link, target already exists: %s -> %s" % (dir, ptarget))
			continue

		# Create path to move directory to, move it, and then setup the symlink
		bb.mkdirhier(os.path.dirname(target))
		#bb.note("Fixup Perms: Rename %s -> %s" % (dir, ptarget))
		os.rename(origin, target)
		#bb.note("Fixup Perms: Link %s -> %s" % (dir, link))
		os.symlink(link, origin)

	for dir in fs_perms_table:
		if fs_perms_table[dir].link:
			continue

		origin = dvar + dir
		if not (os.path.exists(origin) and os.path.isdir(origin)):
			continue

		fix_perms(origin, fs_perms_table[dir].mode, fs_perms_table[dir].uid, fs_perms_table[dir].gid, dir)

		if fs_perms_table[dir].walk == 'true':
			for root, dirs, files in os.walk(origin):
				for dr in dirs:
					each_dir = os.path.join(root, dr)
					fix_perms(each_dir, fs_perms_table[dir].mode, fs_perms_table[dir].uid, fs_perms_table[dir].gid, dir)
				for f in files:
					each_file = os.path.join(root, f)
					fix_perms(each_file, fs_perms_table[dir].fmode, fs_perms_table[dir].fuid, fs_perms_table[dir].fgid, dir)
}


python base_do_patch () {
	bb.build.exec_func('patch_do_patch', d)
}


python legitimize_package_name () {
def legitimize_package_name(s):
	"""
	Make sure package names are legitimate strings
	"""
	import re

	def fixutf(m):
		cp = m.group(1)
		if cp:
			return ('\u%s' % cp).decode('unicode_escape').encode('utf-8')

	# Handle unicode codepoints encoded as <U0123>, as in glibc locale files.
	s = re.sub('<U([0-9A-Fa-f]{1,4})>', fixutf, s)

	# Remaining package name validity fixes
	return s.lower().replace('_', '-').replace('@', '+').replace(',', '+').replace('/', '-')
}


python base_get_metadata_monotone_branch () {
def base_get_metadata_monotone_branch(path, d):
	monotone_branch = "<unknown>"
	try:
		monotone_branch = file( "%s/_MTN/options" % path ).read().strip()
		if monotone_branch.startswith( "database" ):
			monotone_branch_words = monotone_branch.split()
			monotone_branch = monotone_branch_words[ monotone_branch_words.index( "branch" )+1][1:-1]
	except:
		pass
	return monotone_branch
}


python sstate_hardcode_path () {
def sstate_hardcode_path(d):
	# Need to remove hardcoded paths and fix these when we install the
	# staging packages.

	staging = d.getVar('STAGING_DIR', True)
	staging_target = d.getVar('STAGING_DIR_TARGET', True)
	staging_host = d.getVar('STAGING_DIR_HOST', True)
	sstate_builddir = d.getVar('SSTATE_BUILDDIR', True)

	if bb.data.inherits_class('native', d) or bb.data.inherits_class('nativesdk', d) or bb.data.inherits_class('crosssdk', d) or bb.data.inherits_class('cross-canadian', d):
		sstate_sed_cmd = "sed -i -e 's:%s:FIXMESTAGINGDIR:g'" % (staging)
	elif bb.data.inherits_class('cross', d):
		sstate_sed_cmd = "sed -i -e 's:%s:FIXMESTAGINGDIRTARGET:g; s:%s:FIXMESTAGINGDIR:g'" % (staging_target, staging)
	else:
		sstate_sed_cmd = "sed -i -e 's:%s:FIXMESTAGINGDIRHOST:g'" % (staging_host)

	sstate_scan_cmd = d.getVar('SSTATE_SCAN_CMD', True)
	sstate_filelist_cmd = "tee %sfixmepath" % (sstate_builddir)

	# fixmepath file needs relative paths, drop sstate_builddir prefix
	sstate_filelist_relative_cmd = "sed -i -e 's:^%s::g' %sfixmepath" % (sstate_builddir, sstate_builddir)

	sstate_hardcode_cmd = "%s | %s | xargs %s" % (sstate_scan_cmd, sstate_filelist_cmd, sstate_sed_cmd)

	print "Removing hardcoded paths from sstate package: '%s'" % (sstate_hardcode_cmd)
	os.system(sstate_hardcode_cmd)
	print "Replacing absolute paths in fixmepath file: '%s'" % (sstate_filelist_relative_cmd)
	os.system(sstate_filelist_relative_cmd)
}


python check_create_long_filename () {
def check_create_long_filename(filepath, pathname):
    testfile = os.path.join(filepath, ''.join([`num`[-1] for num in xrange(1,200)]))
    try:
        if not os.path.exists(filepath):
            bb.utils.mkdirhier(filepath)
        f = file(testfile, "w")
        f.close()
        os.remove(testfile)
    except IOError as (errno, strerror):
        if errno == 36: # ENAMETOOLONG
            return "Failed to create a file with a long name in %s. Please use a filesystem that does not unreasonably limit filename length.\n" % pathname
        else:
            return "Failed to create a file in %s: %s" % (pathname, strerror)
    return ""
}


python oe_system () {
def oe_system(d, cmd, **kwargs):
    """ Popen based version of os.system. """
    if not "shell" in kwargs:
        kwargs["shell"] = True
    return oe_popen(d, cmd, **kwargs).wait()
}


python do_populate_lic_setscene () {
	sstate_setscene(d)
}


python runtime_mapping_rename () {
def runtime_mapping_rename (varname, d):
	#bb.note("%s before: %s" % (varname, d.getVar(varname, True)))

	new_depends = []
	deps = bb.utils.explode_dep_versions(d.getVar(varname, True) or "")
	for depend in deps:
		# Have to be careful with any version component of the depend
		new_depend = get_package_mapping(depend, d)
		if deps[depend]:
			new_depends.append("%s (%s)" % (new_depend, deps[depend]))
		else:
			new_depends.append(new_depend)

	d.setVar(varname, " ".join(new_depends) or None)

	#bb.note("%s after: %s" % (varname, d.getVar(varname, True)))
}


python split_and_strip_files () {
	import commands, stat, errno

	dvar = d.getVar('PKGD', True)
	pn = d.getVar('PN', True)

	# We default to '.debug' style
	if d.getVar('PACKAGE_DEBUG_SPLIT_STYLE', True) == 'debug-file-directory':
		# Single debug-file-directory style debug info
		debugappend = ".debug"
		debugdir = ""
		debuglibdir = "/usr/lib/debug"
		debugsrcdir = "/usr/src/debug"
	else:
		# Original OE-core, a.k.a. ".debug", style debug info
		debugappend = ""
		debugdir = "/.debug"
		debuglibdir = ""
		debugsrcdir = "/usr/src/debug"

	os.chdir(dvar)

	# Return type (bits):
	# 0 - not elf
	# 1 - ELF
	# 2 - stripped
	# 4 - executable
	# 8 - shared library
	def isELF(path):
		type = 0
		pathprefix = "export PATH=%s; " % d.getVar('PATH', True)
		ret, result = commands.getstatusoutput("%sfile '%s'" % (pathprefix, path))

		if ret:
			bb.error("split_and_strip_files: 'file %s' failed" % path)
			return type

		# Not stripped
		if "ELF" in result:
			type |= 1
			if "not stripped" not in result:
				type |= 2
			if "executable" in result:
				type |= 4
			if "shared" in result:
				type |= 8
		return type


	#
	# First lets figure out all of the files we may have to process ... do this only once!
	#
	file_list = {}
	file_links = {}
	if (d.getVar('INHIBIT_PACKAGE_DEBUG_SPLIT', True) != '1') and \
	   (d.getVar('INHIBIT_PACKAGE_STRIP', True) != '1'):
		for root, dirs, files in os.walk(dvar):
			for f in files:
				file = os.path.join(root, f)
				# Only process files (and symlinks)... Skip files that are obviously debug files
				if not (debugappend != "" and file.endswith(debugappend)) and \
				   not (debugdir != "" and debugdir in os.path.dirname(file[len(dvar):])) and \
				   os.path.isfile(file):
					try:
						s = os.stat(file)
					except OSError, (err, strerror):
						if err != errno.ENOENT:
							raise
						# Skip broken symlinks
						continue
					# Is the item excutable?  Then we need to process it.
					if (s[stat.ST_MODE] & stat.S_IXUSR) or \
					   (s[stat.ST_MODE] & stat.S_IXGRP) or \
					   (s[stat.ST_MODE] & stat.S_IXOTH):
						# If it's a symlink, and points to an ELF file, we capture the readlink target
						if os.path.islink(file):
							target = os.readlink(file)
							if not os.path.isabs(target):
								ltarget = os.path.join(os.path.dirname(file), target)
							else:
								ltarget = target

							if isELF(ltarget):
								#bb.note("Sym: %s (%d)" % (ltarget, isELF(ltarget)))
								file_list[file] = "sym: " + target
							continue
						# It's a file (or hardlink), not a link
						# ...but is it ELF, and is it already stripped?
						elf_file = isELF(file)
						if elf_file & 1:
							# Check if it's a hard link to something else
							if s.st_nlink > 1:
								file_reference = "%d_%d" % (s.st_dev, s.st_ino)
								# Hard link to something else
								file_list[file] = "hard: " + file_reference
								continue

							file_list[file] = "ELF: %d" % elf_file


	#
	# First lets process debug splitting
	#
	if (d.getVar('INHIBIT_PACKAGE_DEBUG_SPLIT', True) != '1'):
		for file in file_list:
			src = file[len(dvar):]
			dest = debuglibdir + os.path.dirname(src) + debugdir + "/" + os.path.basename(src) + debugappend
			fpath = dvar + dest
			# Preserve symlinks in debug area...
			if file_list[file].startswith("sym: "):
				ltarget = file_list[file][5:]
				lpath = os.path.dirname(ltarget)
				lbase = os.path.basename(ltarget)
				ftarget = ""
				if lpath and lpath != ".":
					ftarget += lpath + debugdir + "/"
				ftarget += lbase + debugappend
				if lpath.startswith(".."):
					ftarget = os.path.join("..", ftarget)
				bb.mkdirhier(os.path.dirname(fpath))
				#bb.note("Symlink %s -> %s" % (fpath, ftarget))
				os.symlink(ftarget, fpath)
				continue

			# Preserve hard links in debug area...
			file_reference = ""
			if file_list[file].startswith("hard: "):
				file_reference = file_list[file][6:]
				if file_reference not in file_links:
					# If this is a new file, add it as a reference, and
					# update it's type, so we can fall through and split
					file_list[file] = "ELF: %d" % (isELF(file))
				else:
					target = file_links[file_reference][len(dvar):]
					ftarget = dvar + debuglibdir + os.path.dirname(target) + debugdir + "/" + os.path.basename(target) + debugappend
					bb.mkdirhier(os.path.dirname(fpath))
					#bb.note("Link %s -> %s" % (fpath, ftarget))
					os.link(ftarget, fpath)
					continue

			# It's ELF...
			if file_list[file].startswith("ELF: "):
				elf_file = int(file_list[file][5:])
				if elf_file & 2:
					bb.warn("File '%s' from %s was already stripped, this will prevent future debugging!" % (src, pn))
					continue

				# Split the file...
				bb.mkdirhier(os.path.dirname(fpath))
				#bb.note("Split %s -> %s" % (file, fpath))
				# Only store off the hard link reference if we successfully split!
				if splitfile(file, fpath, debugsrcdir, d) == 0 and file_reference != "":
					file_links[file_reference] = file

		# The above may have generated dangling symlinks, remove them!
		# Dangling symlinks are a result of something NOT being split, such as a stripped binary.
		# This should be a rare occurance, but we want to clean up anyway.
		for file in file_list:
			if file_list[file].startswith("sym: "):
				src = file[len(dvar):]
				dest = debuglibdir + os.path.dirname(src) + debugdir + "/" + os.path.basename(src) + debugappend
				fpath = dvar + dest
				try:
					s = os.stat(fpath)
				except OSError, (err, strerror):
					if err != errno.ENOENT:
						raise
					#bb.note("Remove dangling link %s -> %s" % (fpath, os.readlink(fpath)))
					os.unlink(fpath)
					# This could leave an empty debug directory laying around
					# take care of the obvious case...
					os.system("rmdir %s 2>/dev/null" % os.path.dirname(fpath))

		# Process the debugsrcdir if requested...
		# This copies and places the referenced sources for later debugging...
		splitfile2(debugsrcdir, d)
	#
	# End of debug splitting
	#

	#
	# Now lets go back over things and strip them
	#
	if (d.getVar('INHIBIT_PACKAGE_STRIP', True) != '1'):
		for file in file_list:
			if file_list[file].startswith("ELF: "):
				elf_file = int(file_list[file][5:])
				#bb.note("Strip %s" % file)
				runstrip(file, elf_file, d)
	#
	# End of strip
	#
}


python patch_do_patch () {
	import oe.patch

	patchsetmap = {
		"patch": oe.patch.PatchTree,
		"quilt": oe.patch.QuiltTree,
		"git": oe.patch.GitApplyTree,
	}

	cls = patchsetmap[d.getVar('PATCHTOOL', True) or 'quilt']

	resolvermap = {
		"noop": oe.patch.NOOPResolver,
		"user": oe.patch.UserResolver,
	}

	rcls = resolvermap[d.getVar('PATCHRESOLVE', True) or 'user']

	classes = {}

	s = d.getVar('S', True)

	path = os.getenv('PATH')
	os.putenv('PATH', d.getVar('PATH', True))

	for patch in src_patches(d):
		_, _, local, _, _, parm = bb.decodeurl(patch)

		if "patchdir" in parm:
			patchdir = parm["patchdir"]
			if not os.path.isabs(patchdir):
				patchdir = os.path.join(s, patchdir)
		else:
			patchdir = s

		if not patchdir in classes:
			patchset = cls(patchdir, d)
			resolver = rcls(patchset, oe_terminal)
			classes[patchdir] = (patchset, resolver)
			patchset.Clean()
		else:
			patchset, resolver = classes[patchdir]

		bb.note("Applying patch '%s' (%s)" % (parm['patchname'], oe.path.format_display(local, d)))
		try:
			patchset.Import({"file":local, "strippath": parm['striplevel']}, True)
		except Exception as exc:
			bb.fatal(str(exc))
		try:
			resolver.Resolve()
		except bb.BBHandledException as e:
			bb.fatal(str(e))
}


python oe_popen () {
def oe_popen(d, cmd, **kwargs):
    import oe.process
    kwargs["env"] = oe_popen_env(d)
    return oe.process.Popen(cmd, **kwargs)
}


python pstaging_fetch () {
def pstaging_fetch(sstatepkg, d):
    import bb.fetch2

    # Only try and fetch if the user has configured a mirror
    mirrors = d.getVar('SSTATE_MIRRORS', True)
    if not mirrors:
        return

    # Copy the data object and override DL_DIR and SRC_URI
    localdata = bb.data.createCopy(d)
    bb.data.update_data(localdata)

    dldir = localdata.expand("/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache")
    srcuri = "file://" + os.path.basename(sstatepkg)

    bb.mkdirhier(dldir)

    localdata.setVar('DL_DIR', dldir)
    localdata.setVar('PREMIRRORS', mirrors)
    localdata.setVar('SRC_URI', srcuri)

    # Try a fetch from the sstate mirror, if it fails just return and
    # we will build the package
    try:
        fetcher = bb.fetch2.Fetch([srcuri], localdata, cache=False)
        fetcher.download()

        # Need to optimise this, if using file:// urls, the fetcher just changes the local path
        # For now work around by symlinking
        localpath = bb.data.expand(fetcher.localpath(srcuri), localdata)
        if localpath != sstatepkg and os.path.exists(localpath) and not os.path.exists(sstatepkg):
            os.symlink(localpath, sstatepkg)

    except bb.fetch2.BBFetchException:
        pass
}


python pkgarch_mapping () {
def pkgarch_mapping(d):
    # Compatibility mappings of TUNE_PKGARCH (opt in)
    if d.getVar("PKGARCHCOMPAT_ARMV7A", True):
        if d.getVar("TUNE_PKGARCH", True) == "armv7a-vfp-neon":
            d.setVar("TUNE_PKGARCH", "armv7a")
}


python explode_deps () {
def explode_deps(s):
	return bb.utils.explode_deps(s)
}


python package_qa_check_dev () {
def package_qa_check_dev(path, name, d, elf, messages):
    """
    Check for ".so" library symlinks in non-dev packages
    """

    if not name.endswith("-dev") and not name.endswith("-dbg") and not name.endswith("-nativesdk") and path.endswith(".so") and os.path.islink(path):
        messages.append("non -dev/-dbg/-nativesdk package contains symlink .so: %s path '%s'" % \
                 (name, package_qa_clean_path(path,d)))
}


python package_qa_check_rpath () {
def package_qa_check_rpath(file,name, d, elf, messages):
    """
    Check for dangerous RPATHs
    """
    if not elf:
        return

    scanelf = os.path.join(d.getVar('STAGING_BINDIR_NATIVE',True),'scanelf')
    bad_dirs = [d.getVar('TMPDIR', True) + "/work", d.getVar('STAGING_DIR_TARGET', True)]
    bad_dir_test = d.getVar('TMPDIR', True)
    if not os.path.exists(scanelf):
        bb.fatal("Can not check RPATH, scanelf (part of pax-utils-native) not found")

    if not bad_dirs[0] in d.getVar('WORKDIR', True):
        bb.fatal("This class assumed that WORKDIR is /media/OE/poky/meta-ettus/recipes/hello/build/tmp/work... Not doing any check")

    output = os.popen("%s -B -F%%r#F '%s'" % (scanelf,file))
    txt    = output.readline().split()
    for line in txt:
        for dir in bad_dirs:
            if dir in line:
                messages.append("package %s contains bad RPATH %s in file %s" % (name, line, file))
}


python package_qa_check_unsafe_references_in_scripts () {
def package_qa_check_unsafe_references_in_scripts(path, name, d, elf, messages):
	"""
	Warn if scripts in base_[bindir|sbindir|libdir] reference files under exec_prefix
	"""
	if unsafe_references_skippable(path, name, d):
		return

	if not elf:
		import stat
		pn = d.getVar('PN', True)

		# Ensure we're checking an executable script
		statinfo = os.stat(path)
		if bool(statinfo.st_mode & stat.S_IXUSR):
			# grep shell scripts for possible references to /exec_prefix/
			exec_prefix = d.getVar('exec_prefix', True)
			statement = "grep -e '%s/' %s > /dev/null" % (exec_prefix, path)
			if os.system(statement) == 0:
				error_msg = pn + ": Found a reference to %s/ in %s" % (exec_prefix, path)
				package_qa_handle_error("unsafe-references-in-scripts", error_msg, d)
				error_msg = "Shell scripts in base_bindir and base_sbindir should not reference anything in exec_prefix"
				package_qa_handle_error("unsafe-references-in-scripts", error_msg, d)
}


python base_get_metadata_git_branch () {
def base_get_metadata_git_branch(path, d):
	branch = os.popen('cd %s; git branch 2>&1 | grep "^* " | tr -d "* "' % path).read()

	if len(branch) != 0:
		return branch
	return "<unknown>"
}


python check_sanity_eventhandler () {
    if bb.event.getName(e) == "ConfigParsed" and e.data.getVar("BB_WORKERCONTEXT", True) != "1":
        check_sanity(e)

    return
}


python perform_packagecopy () {
	dest = d.getVar('D', True)
	dvar = d.getVar('PKGD', True)

	bb.mkdirhier(dvar)

	# Start by package population by taking a copy of the installed
	# files to operate on
	os.system('rm -rf %s/*' % (dvar))
	# Preserve sparse files and hard links
	os.system('tar -cf - -C %s -ps . | tar -xf - -C %s' % (dest, dvar))
}


python sstate_task_postfunc () {
    shared_state = sstate_state_fromvars(d)
    sstate_install(shared_state, d)
    for intercept in shared_state['interceptfuncs']:
        bb.build.exec_func(intercept, d)
    sstate_package(shared_state, d)
}


python base_detect_branch () {
def base_detect_branch(d):
	path = base_get_scmbasepath(d)

	scms = [base_get_metadata_git_branch]

	for scm in scms:
		rev = scm(path, d)
		if rev <> "<unknown>":
			return rev.strip()

	return "<unknown>"
}


python do_checkuri () {
	src_uri = (d.getVar('SRC_URI', True) or "").split()
	if len(src_uri) == 0:
		return

	localdata = bb.data.createCopy(d)
	bb.data.update_data(localdata)

        try:
            fetcher = bb.fetch2.Fetch(src_uri, localdata)
            fetcher.checkstatus()
        except bb.fetch2.BBFetchException, e:
            raise bb.build.FuncFailed(e)
}


python is_machine_specific () {
def is_machine_specific(d):
    """Determine whether the current recipe is machine specific"""
    machinepaths = set(machine_paths(d))
    srcuri = d.getVar("SRC_URI", True).split()
    for url in srcuri:
        fetcher = bb.fetch2.Fetch([srcuri], d)
        if url.startswith("file://"):
            if any(fetcher.localpath(url).startswith(mp + "/") for mp in machinepaths):
                return True
}


python sysroot_checkhashes () {
def sysroot_checkhashes(covered, tasknames, fnids, fns, d):
    problems = set()
    configurefnids = set()
    for task in xrange(len(tasknames)):
        if tasknames[task] == "do_configure" and task not in covered:
            configurefnids.add(fnids[task])
    for task in covered:
        if tasknames[task] == "do_populate_sysroot" and fnids[task] in configurefnids:
            problems.add(task)
    return problems
}


python package_qa_write_error () {
def package_qa_write_error(error, d):
    logfile = d.getVar('QA_LOGFILE', True)
    if logfile:
        p = d.getVar('P', True)
        f = file( logfile, "a+")
        print >> f, "%s: %s" % (p, error)
        f.close()
}


python write_specfile () {
	import textwrap
	import oe.packagedata

	# We need a simple way to remove the MLPREFIX from the package name,
	# and dependency information...
	def strip_multilib(name, d):
		multilibs = d.getVar('MULTILIBS', True) or ""
		for ext in multilibs.split():
			eext = ext.split(':')
			if len(eext) > 1 and eext[0] == 'multilib' and name and name.find(eext[1] + '-') >= 0:
				name = "".join(name.split(eext[1] + '-'))
		return name

#		ml = d.getVar("MLPREFIX", True)
#		if ml and name and len(ml) != 0 and name.find(ml) == 0:
#			return ml.join(name.split(ml, 1)[1:])
#		return name

	# In RPM, dependencies are of the format: pkg <>= Epoch:Version-Release
	# This format is similar to OE, however there are restrictions on the
	# characters that can be in a field.  In the Version field, "-"
	# characters are not allowed.  "-" is allowed in the Release field.
	#
	# We translate the "-" in the version to a "+", by loading the PKGV
	# from the dependent recipe, replacing the - with a +, and then using
	# that value to do a replace inside of this recipe's dependencies.
	# This preserves the "-" separator between the version and release, as
	# well as any "-" characters inside of the release field.
	#
	# All of this has to happen BEFORE the mapping_rename_hook as
	# after renaming we cannot look up the dependencies in the packagedata
	# store.
	def translate_vers(varname, d):
		depends = d.getVar(varname, True)
		if depends:
			depends_dict = bb.utils.explode_dep_versions(depends)
			newdeps_dict = {}
			for dep in depends_dict:
				ver = depends_dict[dep]
				if dep and ver:
					if '-' in ver:
						subd = oe.packagedata.read_subpkgdata_dict(dep, d)
						if 'PKGV' in subd:
							pv = subd['PKGV']
							reppv = pv.replace('-', '+')
							ver = ver.replace(pv, reppv)
				newdeps_dict[dep] = ver
			depends = bb.utils.join_deps(newdeps_dict)
			d.setVar(varname, depends.strip())

	# We need to change the style the dependency from BB to RPM
	# This needs to happen AFTER the mapping_rename_hook
	def print_deps(variable, tag, array, d):
		depends = variable
		if depends:
			depends_dict = bb.utils.explode_dep_versions(depends)
			for dep in depends_dict:
				ver = depends_dict[dep]
				if dep and ver:
					ver = ver.replace('(', '')
					ver = ver.replace(')', '')
					array.append("%s: %s %s" % (tag, dep, ver))
				else:
					array.append("%s: %s" % (tag, dep))

	def walk_files(walkpath, target, conffiles):
		import os
		for rootpath, dirs, files in os.walk(walkpath):
			path = rootpath.replace(walkpath, "")
			for dir in dirs:
				# All packages own the directories their files are in...
				target.append('%dir "' + path + '/' + dir + '"')
			for file in files:
				if conffiles.count(path + '/' + file):
					target.append('%config "' + path + '/' + file + '"')
				else:
					target.append('"' + path + '/' + file + '"')

	# Prevent the prerm/postrm scripts from being run during an upgrade
	def wrap_uninstall(scriptvar):
		scr = scriptvar.strip()
		if scr.startswith("#!"):
			pos = scr.find("\n") + 1
		else:
			pos = 0
		scr = scr[:pos] + 'if [ "$1" = "0" ] ; then\n' + scr[pos:] + '\nfi'
		return scr

	packages = d.getVar('PACKAGES', True)
	if not packages or packages == '':
		bb.debug(1, "No packages; nothing to do")
		return

	pkgdest = d.getVar('PKGDEST', True)
	if not pkgdest:
		bb.fatal("No PKGDEST")
		return

	outspecfile = d.getVar('OUTSPECFILE', True)
	if not outspecfile:
		bb.fatal("No OUTSPECFILE")
		return

	# Construct the SPEC file...
	srcname    = strip_multilib(d.getVar('PN', True), d)
	srcsummary = (d.getVar('SUMMARY', True) or d.getVar('DESCRIPTION', True) or ".")
	srcversion = d.getVar('PKGV', True).replace('-', '+')
	srcrelease = d.getVar('PKGR', True)
	srcepoch   = (d.getVar('PKGE', True) or "")
	srclicense = d.getVar('LICENSE', True)
	srcsection = d.getVar('SECTION', True)
	srcmaintainer  = d.getVar('MAINTAINER', True)
	srchomepage    = d.getVar('HOMEPAGE', True)
	srcdescription = d.getVar('DESCRIPTION', True) or "."

	srcdepends     = strip_multilib(d.getVar('DEPENDS', True), d)
	srcrdepends    = []
	srcrrecommends = []
	srcrsuggests   = []
	srcrprovides   = []
	srcrreplaces   = []
	srcrconflicts  = []
	srcrobsoletes  = []

	srcpreinst  = []
	srcpostinst = []
	srcprerm    = []
	srcpostrm   = []

	spec_preamble_top = []
	spec_preamble_bottom = []

	spec_scriptlets_top = []
	spec_scriptlets_bottom = []

	spec_files_top = []
	spec_files_bottom = []

	for pkg in packages.split():
		localdata = bb.data.createCopy(d)

		root = "%s/%s" % (pkgdest, pkg)

		lf = bb.utils.lockfile(root + ".lock")

		localdata.setVar('ROOT', '')
		localdata.setVar('ROOT_%s' % pkg, root)
		pkgname = localdata.getVar('PKG_%s' % pkg, True)
		if not pkgname:
			pkgname = pkg
		localdata.setVar('PKG', pkgname)

		localdata.setVar('OVERRIDES', pkg)

		bb.data.update_data(localdata)

		conffiles = (localdata.getVar('CONFFILES', True) or "").split()

		splitname    = strip_multilib(pkgname, d)

		splitsummary = (localdata.getVar('SUMMARY', True) or localdata.getVar('DESCRIPTION', True) or ".")
		splitversion = (localdata.getVar('PKGV', True) or "").replace('-', '+')
		splitrelease = (localdata.getVar('PKGR', True) or "")
		splitepoch   = (localdata.getVar('PKGE', True) or "")
		splitlicense = (localdata.getVar('LICENSE', True) or "")
		splitsection = (localdata.getVar('SECTION', True) or "")
		splitdescription = (localdata.getVar('DESCRIPTION', True) or ".")

		translate_vers('RDEPENDS', localdata)
		translate_vers('RRECOMMENDS', localdata)
		translate_vers('RSUGGESTS', localdata)
		translate_vers('RPROVIDES', localdata)
		translate_vers('RREPLACES', localdata)
		translate_vers('RCONFLICTS', localdata)

		# Map the dependencies into their final form
		bb.build.exec_func("mapping_rename_hook", localdata)

		splitrdepends    = strip_multilib(localdata.getVar('RDEPENDS', True), d) or ""
		splitrrecommends = strip_multilib(localdata.getVar('RRECOMMENDS', True), d) or ""
		splitrsuggests   = strip_multilib(localdata.getVar('RSUGGESTS', True), d) or ""
		splitrprovides   = strip_multilib(localdata.getVar('RPROVIDES', True), d) or ""
		splitrreplaces   = strip_multilib(localdata.getVar('RREPLACES', True), d) or ""
		splitrconflicts  = strip_multilib(localdata.getVar('RCONFLICTS', True), d) or ""
		splitrobsoletes  = []

		# For now we need to manually supplement RPROVIDES with any update-alternatives links
		if pkg == d.getVar("PN", True):
			splitrprovides = splitrprovides + " " + (d.getVar('ALTERNATIVE_LINK', True) or '') + " " + (d.getVar('ALTERNATIVE_LINKS', True) or '')

		# Gather special src/first package data
		if srcname == splitname:
			srcrdepends    = splitrdepends
			srcrrecommends = splitrrecommends
			srcrsuggests   = splitrsuggests
			srcrprovides   = splitrprovides
			srcrreplaces   = splitrreplaces
			srcrconflicts  = splitrconflicts

			srcpreinst  = localdata.getVar('pkg_preinst', True)
			srcpostinst = localdata.getVar('pkg_postinst', True)
			srcprerm    = localdata.getVar('pkg_prerm', True)
			srcpostrm   = localdata.getVar('pkg_postrm', True)

			file_list = []
			walk_files(root, file_list, conffiles)
			if not file_list and localdata.getVar('ALLOW_EMPTY') != "1":
				bb.note("Not creating empty RPM package for %s" % splitname)
			else:
				bb.note("Creating RPM package for %s" % splitname)
				spec_files_top.append('%files')
				spec_files_top.append('%defattr(-,-,-,-)')
				if file_list:
					bb.note("Creating RPM package for %s" % splitname)
					spec_files_top.extend(file_list)
				else:
					bb.note("Creating EMPTY RPM Package for %s" % splitname)
				spec_files_top.append('')

			bb.utils.unlockfile(lf)
			continue

		# Process subpackage data
		spec_preamble_bottom.append('%%package -n %s' % splitname)
		spec_preamble_bottom.append('Summary: %s' % splitsummary)
		if srcversion != splitversion:
			spec_preamble_bottom.append('Version: %s' % splitversion)
		if srcrelease != splitrelease:
			spec_preamble_bottom.append('Release: %s' % splitrelease)
		if srcepoch != splitepoch:
			spec_preamble_bottom.append('Epoch: %s' % splitepoch)
		if srclicense != splitlicense:
			spec_preamble_bottom.append('License: %s' % splitlicense)
		spec_preamble_bottom.append('Group: %s' % splitsection)

		# Replaces == Obsoletes && Provides
		if splitrreplaces and splitrreplaces.strip() != "":
			for dep in splitrreplaces.split(','):
				if splitrprovides:
					splitrprovides = splitrprovides + ", " + dep
				else:
					splitrprovides = dep
				if splitrobsoletes:
					splitrobsoletes = splitrobsoletes + ", " + dep
				else:
					splitrobsoletes = dep

		print_deps(splitrdepends,	"Requires", spec_preamble_bottom, d)
		# Suggests in RPM are like recommends in OE-core!
		print_deps(splitrrecommends,	"Suggests", spec_preamble_bottom, d)
		# While there is no analog for suggests... (So call them recommends for now)
		print_deps(splitrsuggests, 	"Recommends", spec_preamble_bottom, d)
		print_deps(splitrprovides, 	"Provides", spec_preamble_bottom, d)
		print_deps(splitrobsoletes, 	"Obsoletes", spec_preamble_bottom, d)

		# conflicts can not be in a provide!  We will need to filter it.
		if splitrconflicts:
			depends_dict = bb.utils.explode_dep_versions(splitrconflicts)
			newdeps_dict = {}
			for dep in depends_dict:
				if dep not in splitrprovides:
					newdeps_dict[dep] = depends_dict[dep]
			if newdeps_dict:
				splitrconflicts = bb.utils.join_deps(newdeps_dict)
			else:
				splitrconflicts = ""

		print_deps(splitrconflicts, 	"Conflicts", spec_preamble_bottom, d)

		spec_preamble_bottom.append('')

		spec_preamble_bottom.append('%%description -n %s' % splitname)
		dedent_text = textwrap.dedent(splitdescription).strip()
		spec_preamble_bottom.append('%s' % textwrap.fill(dedent_text, width=75))

		spec_preamble_bottom.append('')

		# Now process scriptlets
		for script in ["preinst", "postinst", "prerm", "postrm"]:
			scriptvar = localdata.getVar('pkg_%s' % script, True)
			if not scriptvar:
				continue
			if script == 'preinst':
				spec_scriptlets_bottom.append('%%pre -n %s' % splitname)
			elif script == 'postinst':
				spec_scriptlets_bottom.append('%%post -n %s' % splitname)
			elif script == 'prerm':
				spec_scriptlets_bottom.append('%%preun -n %s' % splitname)
				scriptvar = wrap_uninstall(scriptvar)
			elif script == 'postrm':
				spec_scriptlets_bottom.append('%%postun -n %s' % splitname)
				scriptvar = wrap_uninstall(scriptvar)
			spec_scriptlets_bottom.append('# %s - %s' % (splitname, script))
			spec_scriptlets_bottom.append(scriptvar)
			spec_scriptlets_bottom.append('')

		# Now process files
		file_list = []
		walk_files(root, file_list, conffiles)
		if not file_list and localdata.getVar('ALLOW_EMPTY') != "1":
			bb.note("Not creating empty RPM package for %s" % splitname)
		else:
			spec_files_bottom.append('%%files -n %s' % splitname)
			spec_files_bottom.append('%defattr(-,-,-,-)')
			if file_list:
				bb.note("Creating RPM package for %s" % splitname)
				spec_files_bottom.extend(file_list)
			else:
				bb.note("Creating EMPTY RPM Package for %s" % splitname)
			spec_files_bottom.append('')

		del localdata
		bb.utils.unlockfile(lf)

	spec_preamble_top.append('Summary: %s' % srcsummary)
	spec_preamble_top.append('Name: %s' % srcname)
	spec_preamble_top.append('Version: %s' % srcversion)
	spec_preamble_top.append('Release: %s' % srcrelease)
	if srcepoch and srcepoch.strip() != "":
		spec_preamble_top.append('Epoch: %s' % srcepoch)
	spec_preamble_top.append('License: %s' % srclicense)
	spec_preamble_top.append('Group: %s' % srcsection)
	spec_preamble_top.append('Packager: %s' % srcmaintainer)
	spec_preamble_top.append('URL: %s' % srchomepage)

	# Replaces == Obsoletes && Provides
	if srcrreplaces and srcrreplaces.strip() != "":
		for dep in srcrreplaces.split(','):
			if srcrprovides:
				srcrprovides = srcrprovides + ", " + dep
			else:
				srcrprovides = dep
			if srcrobsoletes:
				srcrobsoletes = srcrobsoletes + ", " + dep
			else:
				srcrobsoletes = dep

	print_deps(srcdepends,		"BuildRequires", spec_preamble_top, d)
	print_deps(srcrdepends,		"Requires", spec_preamble_top, d)
	# Suggests in RPM are like recommends in OE-core!
	print_deps(srcrrecommends,	"Suggests", spec_preamble_top, d)
	# While there is no analog for suggests... (So call them recommends for now)
	print_deps(srcrsuggests, 	"Recommends", spec_preamble_top, d)
	print_deps(srcrprovides, 	"Provides", spec_preamble_top, d)
	print_deps(srcrobsoletes, 	"Obsoletes", spec_preamble_top, d)

	# conflicts can not be in a provide!  We will need to filter it.
	if srcrconflicts:
		depends_dict = bb.utils.explode_dep_versions(srcrconflicts)
		newdeps_dict = {}
		for dep in depends_dict:
			if dep not in srcrprovides:
				newdeps_dict[dep] = depends_dict[dep]
		if newdeps_dict:
			srcrconflicts = bb.utils.join_deps(newdeps_dict)
		else:
			srcrconflicts = ""

	print_deps(srcrconflicts, 	"Conflicts", spec_preamble_top, d)

	spec_preamble_top.append('')

	spec_preamble_top.append('%description')
	dedent_text = textwrap.dedent(srcdescription).strip()
	spec_preamble_top.append('%s' % textwrap.fill(dedent_text, width=75))

	spec_preamble_top.append('')

	if srcpreinst:
		spec_scriptlets_top.append('%pre')
		spec_scriptlets_top.append('# %s - preinst' % srcname)
		spec_scriptlets_top.append(srcpreinst)
		spec_scriptlets_top.append('')
	if srcpostinst:
		spec_scriptlets_top.append('%post')
		spec_scriptlets_top.append('# %s - postinst' % srcname)
		spec_scriptlets_top.append(srcpostinst)
		spec_scriptlets_top.append('')
	if srcprerm:
		spec_scriptlets_top.append('%preun')
		spec_scriptlets_top.append('# %s - prerm' % srcname)
		scriptvar = wrap_uninstall(srcprerm)
		spec_scriptlets_top.append(scriptvar)
		spec_scriptlets_top.append('')
	if srcpostrm:
		spec_scriptlets_top.append('%postun')
		spec_scriptlets_top.append('# %s - postrm' % srcname)
		scriptvar = wrap_uninstall(srcpostrm)
		spec_scriptlets_top.append(scriptvar)
		spec_scriptlets_top.append('')

	# Write the SPEC file
	try:
		from __builtin__ import file
		specfile = file(outspecfile, 'w')
	except OSError:
		raise bb.build.FuncFailed("unable to open spec file for writing.")

	# RPMSPEC_PREAMBLE is a way to add arbitrary text to the top
	# of the generated spec file
	external_preamble = d.getVar("RPMSPEC_PREAMBLE", True)
	if external_preamble:
		specfile.write(external_preamble + "\n")

	for line in spec_preamble_top:
		specfile.write(line + "\n")

	for line in spec_preamble_bottom:
		specfile.write(line + "\n")

	for line in spec_scriptlets_top:
		specfile.write(line + "\n")

	for line in spec_scriptlets_bottom:
		specfile.write(line + "\n")

	for line in spec_files_top:
		specfile.write(line + "\n")

	for line in spec_files_bottom:
		specfile.write(line + "\n")

	specfile.close()
}


python oe_filter_out () {
def oe_filter_out(f, str, d):
    return oe.utils.str_filter_out(f, str, d)
}


python oe_terminal () {
def oe_terminal(command, title, d):
    import oe.data
    import oe.terminal

    for export in oe.data.typed_value('OE_TERMINAL_EXPORTS', d):
        value = d.getVar(export, True)
        if value is not None:
            os.environ[export] = str(value)

    terminal = oe.data.typed_value('OE_TERMINAL', d).lower()
    if terminal == 'none':
        bb.fatal('Devshell usage disabled with OE_TERMINAL')
    elif terminal != 'auto':
        try:
            oe.terminal.spawn(terminal, command, title)
            return
        except oe.terminal.UnsupportedTerminal:
            bb.warn('Unsupported terminal "%s", defaulting to "auto"' %
                    terminal)
        except oe.terminal.ExecutionError as exc:
            bb.fatal('Unable to spawn terminal %s: %s' % (terminal, exc))

    try:
        oe.terminal.spawn_preferred(command, title)
    except oe.terminal.NoSupportedTerminals:
        bb.fatal('No valid terminal found, unable to open devshell')
    except oe.terminal.ExecutionError as exc:
        bb.fatal('Unable to spawn terminal %s: %s' % (terminal, exc))}


python package_qa_get_machine_dict () {
def package_qa_get_machine_dict():
    return {
            "darwin9" : {
                        "arm" :       (40,     0,    0,          True,          32),
                      },
            "linux" : {
                        "arm" :       (40,    97,    0,          True,          32),
                        "armeb":      (40,    97,    0,          False,         32),
                        "powerpc":    (20,     0,    0,          False,         32),
                        "powerpc64":  (21,     0,    0,          False,         64),
                        "i386":       ( 3,     0,    0,          True,          32),
                        "i486":       ( 3,     0,    0,          True,          32),
                        "i586":       ( 3,     0,    0,          True,          32),
                        "i686":       ( 3,     0,    0,          True,          32),
                        "x86_64":     (62,     0,    0,          True,          64),
                        "ia64":       (50,     0,    0,          True,          64),
                        "alpha":      (36902,  0,    0,          True,          64),
                        "hppa":       (15,     3,    0,          False,         32),
                        "m68k":       ( 4,     0,    0,          False,         32),
                        "mips":       ( 8,     0,    0,          False,         32),
                        "mipsel":     ( 8,     0,    0,          True,          32),
                        "s390":       (22,     0,    0,          False,         32),
                        "sh4":        (42,     0,    0,          True,          32),
                        "sparc":      ( 2,     0,    0,          False,         32),
                      },
            "linux-uclibc" : {
                        "arm" :       (  40,    97,    0,          True,          32),
                        "armeb":      (  40,    97,    0,          False,         32),
                        "powerpc":    (  20,     0,    0,          False,         32),
                        "i386":       (   3,     0,    0,          True,          32),
                        "i486":       (   3,     0,    0,          True,          32),
                        "i586":       (   3,     0,    0,          True,          32),
                        "i686":       (   3,     0,    0,          True,          32),
                        "x86_64":     (  62,     0,    0,          True,          64),
                        "mips":       (   8,     0,    0,          False,         32),
                        "mipsel":     (   8,     0,    0,          True,          32),
                        "avr32":      (6317,     0,    0,          False,         32),
			"sh4":        (42,	 0,    0,          True,          32),

                      },
            "uclinux-uclibc" : {
                        "bfin":       ( 106,     0,    0,          True,         32),
                      },
            "linux-gnueabi" : {
                        "arm" :       (40,     0,    0,          True,          32),
                        "armeb" :     (40,     0,    0,          False,         32),
                      },
            "linux-uclibceabi" : {
                        "arm" :       (40,     0,    0,          True,          32),
                        "armeb" :     (40,     0,    0,          False,         32),
                      },
            "linux-gnu" : {
                        "powerpc":    (20,     0,    0,          False,         32),
                      },
            "linux-gnuspe" : {
                        "powerpc":    (20,     0,    0,          False,         32),
                      },
            "linux-uclibcspe" : {
                        "powerpc":    (20,     0,    0,          False,         32),
                      },
            "linux-gnu" :       {
                        "microblaze":   (47787,  0,    0,          False,         32),
                        "microblazeel": (47787,  0,    0,          True,          32),
                      },
            "linux-gnux32" :       {
                        "x86_64":     (62,     0,    0,          True,          32),
                      },
       }

}


python oe_run () {
def oe_run(d, cmd, **kwargs):
    import oe.process
    kwargs["env"] = oe_popen_env(d)
    return oe.process.run(cmd, **kwargs)
}


python get_diskdata () {
def get_diskdata(var, dev, data):
    olddiskdata = data.getVar(var, False)
    diskdata = {}
    if olddiskdata is None:
       return
    newdiskdata = get_diskstats(dev)
    for key in olddiskdata.iterkeys():
        diskdata["Start"+key] = str(int(olddiskdata[key]))
        diskdata["End"+key] = str(int(newdiskdata[key]))
    return diskdata
}


python get_device () {
def get_device(e):
    file = open(e.data.getVar('DEVFILE', True))
    device = file.readline()
    file.close()
    return device
}


python sstate_clean_cachefile () {
def sstate_clean_cachefile(ss, d):
    import oe.path

    sstatepkgdir = d.getVar('SSTATE_DIR', True)
    sstatepkgfile = sstatepkgdir + '/' + d.getVar('SSTATE_PKGSPEC', True) + "*_" + ss['name'] + ".tgz*"
    bb.note("Removing %s" % sstatepkgfile)
    oe.path.remove(sstatepkgfile)
}


python extend_variants () {
def extend_variants(d, var, extend, delim=':'):
	"""Return a string of all bb class extend variants for the given extend"""
	variants = []
	whole = d.getVar(var, True) or ""
	for ext in whole.split():
		eext = ext.split(delim)
		if len(eext) > 1 and eext[0] == extend:
			variants.append(eext[1])
	return " ".join(variants)
}


python package_qa_check_rdepends () {
def package_qa_check_rdepends(pkg, pkgdest, skip, d):
    # Don't do this check for kernel/module recipes, there aren't too many debug/development
    # packages and you can get false positives e.g. on kernel-module-lirc-dev
    if bb.data.inherits_class("kernel", d) or bb.data.inherits_class("module-base", d):
        return True

    sane = True
    if not "-dbg" in pkg and not "task-" in pkg and not "-image" in pkg:
        # Copied from package_ipk.bbclass
        # boiler plate to update the data
        localdata = bb.data.createCopy(d)
        root = "%s/%s" % (pkgdest, pkg)

        localdata.setVar('ROOT', '')
        localdata.setVar('ROOT_%s' % pkg, root)
        pkgname = localdata.getVar('PKG_%s' % pkg, True)
        if not pkgname:
            pkgname = pkg
        localdata.setVar('PKG', pkgname)

        localdata.setVar('OVERRIDES', pkg)

        bb.data.update_data(localdata)

        # Now check the RDEPENDS
        rdepends = bb.utils.explode_deps(localdata.getVar('RDEPENDS', True) or "")


        # Now do the sanity check!!!
        for rdepend in rdepends:
            if "-dbg" in rdepend and "debug-deps" not in skip:
                error_msg = "%s rdepends on %s" % (pkgname,rdepend)
                sane = package_qa_handle_error("debug-deps", error_msg, d)
            if (not "-dev" in pkg and not "-staticdev" in pkg) and rdepend.endswith("-dev") and "dev-deps" not in skip:
                error_msg = "%s rdepends on %s" % (pkgname, rdepend)
                sane = package_qa_handle_error("dev-deps", error_msg, d)

    return sane
}


python package_qa_check_unsafe_references_in_binaries () {
def package_qa_check_unsafe_references_in_binaries(path, name, d, elf, messages):
	"""
	Ensure binaries in base_[bindir|sbindir|libdir] do not link to files under exec_prefix
	"""
	if unsafe_references_skippable(path, name, d):
		return

	if elf:
		import subprocess as sub
		pn = d.getVar('PN', True)

		exec_prefix = d.getVar('exec_prefix', True)
		sysroot_path = d.getVar('STAGING_DIR_TARGET', True)
		sysroot_path_usr = sysroot_path + exec_prefix

		try:
			ldd_output = bb.process.Popen(["prelink-rtld", "--root", sysroot_path, path], stdout=sub.PIPE).stdout.read()
		except bb.process.CmdError:
			error_msg = pn + ": prelink-rtld aborted when processing %s" % path
			package_qa_handle_error("unsafe-references-in-binaries", error_msg, d)
			return False

		if sysroot_path_usr in ldd_output:
			error_msg = pn + ": %s links to something under exec_prefix" % path
			package_qa_handle_error("unsafe-references-in-binaries", error_msg, d)
			error_msg = "ldd reports: %s" % ldd_output
			package_qa_handle_error("unsafe-references-in-binaries", error_msg, d)
			return False
}


python set_bn () {
def set_bn(e):
    bn = e.getPkgs()[0] + "-" + e.data.getVar('MACHINE', True)
    try:
        os.remove(e.data.getVar('BNFILE', True))
    except:
        pass
    file = open(e.data.getVar('BNFILE', True), "w")
    file.write(os.path.join(bn, e.data.getVar('BUILDNAME', True)))
    file.close()
}


python get_package_mapping () {
def get_package_mapping (pkg, d):
	import oe.packagedata

	data = oe.packagedata.read_subpkgdata(pkg, d)
	key = "PKG_%s" % pkg

	if key in data:
		return data[key]

	return pkg
}


python do_clean () {
	"""clear the build and temp directories"""
	dir = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0")
	bb.note("Removing " + dir)
	oe.path.remove(dir)

	dir = "%s.*" % bb.data.expand(d.getVar('STAMP'), d)
	bb.note("Removing " + dir)
	oe.path.remove(dir)

	for f in (d.getVar('CLEANFUNCS', True) or '').split():
		bb.build.exec_func(f, d)
}


python do_package_write_rpm_setscene () {
	sstate_setscene(d)
}


python sstate_task_prefunc () {
    shared_state = sstate_state_fromvars(d)
    sstate_clean(shared_state, d)
}


python check_sanity_sstate_dir_change () {
def check_sanity_sstate_dir_change(sstate_dir, data):
    # Sanity checks to be done when the value of SSTATE_DIR changes

    # Check that SSTATE_DIR isn't on a filesystem with limited filename length (eg. eCryptFS)
    testmsg = ""
    if sstate_dir != "":
        testmsg = check_create_long_filename(sstate_dir, "SSTATE_DIR")
    return testmsg
}


python write_task_data () {
def write_task_data(status, logfile, dev, e):
    bn = get_bn(e)
    bsdir = os.path.join(e.data.getVar('BUILDSTATS_BASE', True), bn)
    taskdir = os.path.join(bsdir, e.data.expand("bblayers-1.0-r0"))
    file = open(os.path.join(logfile), "a")
    timedata = get_timedata("__timedata_task", e.data)
    if timedata:
        elapsedtime, cpu = timedata
        file.write(bb.data.expand("bblayers-1.0-r0: %s: Elapsed time: %0.2f seconds \n" %
                                 (e.task, elapsedtime), e.data))
        if cpu:
            file.write("CPU usage: %0.1f%% \n" % cpu)
    ############################################################################
    # Here we gather up disk data. In an effort to avoid lying with stats
    # I do a bare minimum of analysis of collected data.
    # The simple fact is, doing disk io collection on a per process basis
    # without effecting build time would be difficult.
    # For the best information, running things with BB_TOTAL_THREADS = "1"
    # would return accurate per task results.
    ############################################################################
    if dev != "NoLogicalDevice":
        diskdata = get_diskdata("__diskdata_task", dev, e.data)
        if diskdata:
            for key in sorted(diskdata.iterkeys()):
                file.write(key + ": " + diskdata[key] + "\n")
    if status is "passed":
	    file.write("Status: PASSED \n")
    else:
        file.write("Status: FAILED \n")
    file.write("Ended: %0.2f \n" % time.time())
    file.close()
}


python sstate_setscene () {
def sstate_setscene(d):
    shared_state = sstate_state_fromvars(d)
    accelerate = sstate_installpkg(shared_state, d)
    if not accelerate:
        raise bb.build.FuncFailed("No suitable staging package found")
}


python unsafe_references_skippable () {
def unsafe_references_skippable(path, name, d):
	if bb.data.inherits_class('native', d) or bb.data.inherits_class('nativesdk', d):
		return True

	if "-dbg" in name or "-dev" in name:
		return True

	# Other package names to skip:
	if name.startswith("kernel-module-"):
		return True

	# Skip symlinks
	if os.path.islink(path):
		return True

	# Skip unusual rootfs layouts which make these tests irrelevant
	exec_prefix = d.getVar('exec_prefix', True)
	if exec_prefix == "":
		return True

	pkgdest = d.getVar('PKGDEST', True)
	pkgdest = pkgdest + "/" + name
	pkgdest = os.path.abspath(pkgdest)
	base_bindir = pkgdest + d.getVar('base_bindir', True)
	base_sbindir = pkgdest + d.getVar('base_sbindir', True)
	base_libdir = pkgdest + d.getVar('base_libdir', True)
	bindir = pkgdest + d.getVar('bindir', True)
	sbindir = pkgdest + d.getVar('sbindir', True)
	libdir = pkgdest + d.getVar('libdir', True)

	if base_bindir == bindir and base_sbindir == sbindir and base_libdir == libdir:
		return True

	# Skip files not in base_[bindir|sbindir|libdir]
	path = os.path.abspath(path)
	if not (base_bindir in path or base_sbindir in path or base_libdir in path):
		return True

	return False
}


python sysroot_cleansstate () {
     ss = sstate_state_fromvars(d, "populate_sysroot")
     sstate_clean(ss, d)
}


python package_depchains () {
	"""
	For a given set of prefix and postfix modifiers, make those packages
	RRECOMMENDS on the corresponding packages for its RDEPENDS.

	Example:  If package A depends upon package B, and A's .bb emits an
	A-dev package, this would make A-dev Recommends: B-dev.

	If only one of a given suffix is specified, it will take the RRECOMMENDS
	based on the RDEPENDS of *all* other packages. If more than one of a given
	suffix is specified, its will only use the RDEPENDS of the single parent
	package.
	"""

	packages  = d.getVar('PACKAGES', True)
	postfixes = (d.getVar('DEPCHAIN_POST', True) or '').split()
	prefixes  = (d.getVar('DEPCHAIN_PRE', True) or '').split()

	def pkg_adddeprrecs(pkg, base, suffix, getname, depends, d):

		#bb.note('depends for %s is %s' % (base, depends))
		rreclist = bb.utils.explode_dep_versions(d.getVar('RRECOMMENDS_' + pkg, True) or d.getVar('RRECOMMENDS', True) or "")

		for depend in depends:
			if depend.find('-native') != -1 or depend.find('-cross') != -1 or depend.startswith('virtual/'):
				#bb.note("Skipping %s" % depend)
				continue
			if depend.endswith('-dev'):
				depend = depend.replace('-dev', '')
			if depend.endswith('-dbg'):
				depend = depend.replace('-dbg', '')
			pkgname = getname(depend, suffix)
			#bb.note("Adding %s for %s" % (pkgname, depend))
			if pkgname not in rreclist:
				rreclist[pkgname] = ""

		#bb.note('setting: RRECOMMENDS_%s=%s' % (pkg, ' '.join(rreclist)))
		d.setVar('RRECOMMENDS_%s' % pkg, bb.utils.join_deps(rreclist, commasep=False))

	def pkg_addrrecs(pkg, base, suffix, getname, rdepends, d):

		#bb.note('rdepends for %s is %s' % (base, rdepends))
		rreclist = bb.utils.explode_dep_versions(d.getVar('RRECOMMENDS_' + pkg, True) or d.getVar('RRECOMMENDS', True) or "")

		for depend in rdepends:
			if depend.find('virtual-locale-') != -1:
				#bb.note("Skipping %s" % depend)
				continue
			if depend.endswith('-dev'):
				depend = depend.replace('-dev', '')
			if depend.endswith('-dbg'):
				depend = depend.replace('-dbg', '')
			pkgname = getname(depend, suffix)
			#bb.note("Adding %s for %s" % (pkgname, depend))
			if pkgname not in rreclist:
				rreclist[pkgname] = ""

		#bb.note('setting: RRECOMMENDS_%s=%s' % (pkg, ' '.join(rreclist)))
		d.setVar('RRECOMMENDS_%s' % pkg, bb.utils.join_deps(rreclist, commasep=False))

	def add_dep(list, dep):
		dep = dep.split(' (')[0].strip()
		if dep not in list:
			list.append(dep)

	depends = []
	for dep in bb.utils.explode_deps(d.getVar('DEPENDS', True) or ""):
		add_dep(depends, dep)

	rdepends = []
	for dep in bb.utils.explode_deps(d.getVar('RDEPENDS', True) or ""):
		add_dep(rdepends, dep)

	for pkg in packages.split():
		for dep in bb.utils.explode_deps(d.getVar('RDEPENDS_' + pkg, True) or ""):
			add_dep(rdepends, dep)

	#bb.note('rdepends is %s' % rdepends)

	def post_getname(name, suffix):
		return '%s%s' % (name, suffix)
	def pre_getname(name, suffix):
		return '%s%s' % (suffix, name)

	pkgs = {}
	for pkg in packages.split():
		for postfix in postfixes:
			if pkg.endswith(postfix):
				if not postfix in pkgs:
					pkgs[postfix] = {}
				pkgs[postfix][pkg] = (pkg[:-len(postfix)], post_getname)

		for prefix in prefixes:
			if pkg.startswith(prefix):
				if not prefix in pkgs:
					pkgs[prefix] = {}
				pkgs[prefix][pkg] = (pkg[:-len(prefix)], pre_getname)

	for suffix in pkgs:
		for pkg in pkgs[suffix]:
			if d.getVarFlag('RRECOMMENDS_' + pkg, 'nodeprrecs'):
				continue
			(base, func) = pkgs[suffix][pkg]
			if suffix == "-dev":
				pkg_adddeprrecs(pkg, base, suffix, func, depends, d)
			if len(pkgs[suffix]) == 1:
				pkg_addrrecs(pkg, base, suffix, func, rdepends, d)
			else:
				rdeps = []
				for dep in bb.utils.explode_deps(d.getVar('RDEPENDS_' + base, True) or d.getVar('RDEPENDS', True) or ""):
					add_dep(rdeps, dep)
				pkg_addrrecs(pkg, base, suffix, func, rdeps, d)
}


python package_mapping_rename_hook () {
	"""
	Rewrite variables to account for package renaming in things
	like debian.bbclass or manual PKG variable name changes
	"""
	runtime_mapping_rename("RDEPENDS", d)
	runtime_mapping_rename("RRECOMMENDS", d)
	runtime_mapping_rename("RSUGGESTS", d)
	runtime_mapping_rename("RPROVIDES", d)
	runtime_mapping_rename("RREPLACES", d)
	runtime_mapping_rename("RCONFLICTS", d)
}


python splitfile () {
def splitfile(file, debugfile, debugsrcdir, d):
    # Function to split a single file, called from split_and_strip_files below
    # A working 'file' (one which works on the target architecture)
    # is split and the split off portions go to debugfile.
    #
    # The debug information is then processed for src references.  These
    # references are copied to debugsrcdir, if defined.

    import commands, stat

    dvar = d.getVar('PKGD', True)
    pathprefix = "export PATH=%s; " % d.getVar('PATH', True)
    objcopy = d.getVar("OBJCOPY", True)
    debugedit = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/bin/debugedit")
    workdir = d.getVar("WORKDIR", True)
    workparentdir = os.path.dirname(workdir)
    sourcefile = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/debugsources.list")

    # We ignore kernel modules, we don't generate debug info files.
    if file.find("/lib/modules/") != -1 and file.endswith(".ko"):
	return 1

    newmode = None
    if not os.access(file, os.W_OK) or os.access(file, os.R_OK):
        origmode = os.stat(file)[stat.ST_MODE]
        newmode = origmode | stat.S_IWRITE | stat.S_IREAD
        os.chmod(file, newmode)

    # We need to extract the debug src information here...
    if debugsrcdir:
	os.system("%s'%s' -b '%s' -d '%s' -i -l '%s' '%s'" % (pathprefix, debugedit, workparentdir, debugsrcdir, sourcefile, file))

    bb.mkdirhier(os.path.dirname(debugfile))

    os.system("%s'%s' --only-keep-debug '%s' '%s'" % (pathprefix, objcopy, file, debugfile))

    # Set the debuglink to have the view of the file path on the target
    os.system("%s'%s' --add-gnu-debuglink='%s' '%s'" % (pathprefix, objcopy, debugfile, file))

    if newmode:
        os.chmod(file, origmode)

    return 0
}


python do_cleanall () {
        src_uri = (d.getVar('SRC_URI', True) or "").split()
        if len(src_uri) == 0:
            return

	localdata = bb.data.createCopy(d)
	bb.data.update_data(localdata)

        try:
            fetcher = bb.fetch2.Fetch(src_uri, localdata)
            fetcher.clean()
        except bb.fetch2.BBFetchException, e:
            raise bb.build.FuncFailed(e)
}


python sstate_package () {
def sstate_package(ss, d):
    import oe.path

    def make_relative_symlink(path, outputpath, d):
        # Replace out absolute TMPDIR paths in symlinks with relative ones
        if not os.path.islink(path):
            return
        link = os.readlink(path)
        if not os.path.isabs(link):
            return
        if not link.startswith(tmpdir):
            return

        depth = link.rpartition(tmpdir)[2].count('/')
        base = link.partition(tmpdir)[2].strip()
        while depth > 1:
            base = "../" + base
            depth -= 1

        bb.debug(2, "Replacing absolute path %s with relative path %s" % (link, base))
        os.remove(path)
        os.symlink(base, path)

    tmpdir = d.getVar('TMPDIR', True)

    sstatebuild = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/sstate-build-%s/" % ss['name'])
    sstatepkg = d.getVar('SSTATE_PKG', True) + '_'+ ss['name'] + ".tgz"
    bb.mkdirhier(sstatebuild)
    bb.mkdirhier(os.path.dirname(sstatepkg))
    for state in ss['dirs']:
        srcbase = state[0].rstrip("/").rsplit('/', 1)[0]
        for walkroot, dirs, files in os.walk(state[1]):
            for file in files:
                srcpath = os.path.join(walkroot, file)
                dstpath = srcpath.replace(state[1], sstatebuild + state[0])
                make_relative_symlink(srcpath, dstpath, d)
            for dir in dirs:
                srcpath = os.path.join(walkroot, dir)
                dstpath = srcpath.replace(state[1], sstatebuild + state[0])
                make_relative_symlink(srcpath, dstpath, d)
        bb.debug(2, "Preparing tree %s for packaging at %s" % (state[1], sstatebuild + state[0]))
        oe.path.copytree(state[1], sstatebuild + state[0])

    workdir = d.getVar('WORKDIR', True)
    for plain in ss['plaindirs']:
        pdir = plain.replace(workdir, sstatebuild)
        bb.mkdirhier(plain)
        bb.mkdirhier(pdir)
        oe.path.copytree(plain, pdir)

    d.setVar('SSTATE_BUILDDIR', sstatebuild)
    d.setVar('SSTATE_PKG', sstatepkg)
    sstate_hardcode_path(d)
    bb.build.exec_func('sstate_create_package', d)

    bb.siggen.dump_this_task(sstatepkg + ".siginfo", d)

    return
}


python do_populate_lic () {
    """
    Populate LICENSE_DIRECTORY with licenses.
    """
    import os
    import bb
    import shutil
    import oe.license

    pn = d.getVar('PN', True)
    for package in d.getVar('PACKAGES', True):
        if d.getVar('LICENSE_' + pn + '-' + package, True):
            license_types = license_types + ' & ' + \
                            d.getVar('LICENSE_' + pn + '-' + package, True)

    #If we get here with no license types, then that means we have a recipe
    #level license. If so, we grab only those.
    try:
        license_types
    except NameError:
        # All the license types at the recipe level
        license_types = d.getVar('LICENSE', True)

    # All the license files for the package
    lic_files = d.getVar('LIC_FILES_CHKSUM', True)
    pn = d.getVar('PN', True)
    # The base directory we wrangle licenses to
    destdir = os.path.join(d.getVar('LICSSTATEDIR', True), pn)
    # The license files are located in S/LIC_FILE_CHECKSUM.
    srcdir = d.getVar('S', True)
    # Directory we store the generic licenses as set in the distro configuration
    generic_directory = d.getVar('COMMON_LICENSE_DIR', True)
    license_source_dirs = []
    license_source_dirs.append(generic_directory)
    try:
        additional_lic_dirs = d.getVar('LICENSE_DIR', True).split()
        for lic_dir in additional_lic_dirs:
            license_source_dirs.append(lic_dir)
    except:
        pass

    class FindVisitor(oe.license.LicenseVisitor):
        def visit_Str(self, node):
            #
            # Until I figure out what to do with
            # the two modifiers I support (or greater = +
            # and "with exceptions" being *
            # we'll just strip out the modifier and put
            # the base license.
            find_license(node.s.replace("+", "").replace("*", ""))
            self.generic_visit(node)

    def find_license(license_type):
        try:
            bb.mkdirhier(gen_lic_dest)
        except:
            pass
        spdx_generic = None
        license_source = None
        # If the generic does not exist we need to check to see if there is an SPDX mapping to it
        for lic_dir in license_source_dirs:
            if not os.path.isfile(os.path.join(lic_dir, license_type)):
                if d.getVarFlag('SPDXLICENSEMAP', license_type) != None:
                    # Great, there is an SPDXLICENSEMAP. We can copy!
                    bb.debug(1, "We need to use a SPDXLICENSEMAP for %s" % (license_type))
                    spdx_generic = d.getVarFlag('SPDXLICENSEMAP', license_type)
                    license_source = lic_dir
                    break
            elif os.path.isfile(os.path.join(lic_dir, license_type)):
                spdx_generic = license_type
                license_source = lic_dir
                break

        if spdx_generic and license_source:
            # we really should copy to generic_ + spdx_generic, however, that ends up messing the manifest
            # audit up. This should be fixed in emit_pkgdata (or, we actually got and fix all the recipes)
            ret = bb.copyfile(os.path.join(license_source, spdx_generic), os.path.join(os.path.join(d.getVar('LICSSTATEDIR', True), pn), "generic_" + license_type))
            # If the copy didn't occur, something horrible went wrong and we fail out
            if not ret:
                bb.warn("%s for %s could not be copied for some reason. It may not exist. WARN for now." % (spdx_generic, pn))
        else:
            # And here is where we warn people that their licenses are lousy
            bb.warn("%s: No generic license file exists for: %s in any provider" % (pn, license_type))
            pass

    try:
        bb.mkdirhier(destdir)
    except:
        pass

    if not generic_directory:
        raise bb.build.FuncFailed("COMMON_LICENSE_DIR is unset. Please set this in your distro config")

    if not lic_files:
        # No recipe should have an invalid license file. This is checked else
        # where, but let's be pedantic
        bb.note(pn + ": Recipe file does not have license file information.")
        return True

    for url in lic_files.split():
        (type, host, path, user, pswd, parm) = bb.decodeurl(url)
        # We want the license file to be copied into the destination
        srclicfile = os.path.join(srcdir, path)
        ret = bb.copyfile(srclicfile, os.path.join(destdir, os.path.basename(path)))
        # If the copy didn't occur, something horrible went wrong and we fail out
        if not ret:
            bb.warn("%s could not be copied for some reason. It may not exist. WARN for now." % srclicfile)

    v = FindVisitor()
    try:
        v.visit_string(license_types)
    except oe.license.InvalidLicense as exc:
        bb.fatal('%s: %s' % (d.getVar('PF', True), exc))
    except SyntaxError:
        bb.warn("%s: Failed to parse it's LICENSE field." % (d.getVar('PF', True)))

}


python oe_popen_env () {
def oe_popen_env(d):
    env = d.getVar("__oe_popen_env", False)
    if env is None:
        env = {}
        for v in d.keys():
            if d.getVarFlag(v, "export"):
                env[v] = d.getVar(v, True) or ""
        d.setVar("__oe_popen_env", env)
    return env
}


python sstate_checkhashes () {
def sstate_checkhashes(sq_fn, sq_task, sq_hash, sq_hashfn, d):

    ret = []
    # This needs to go away, FIXME
    mapping = {
        "do_populate_sysroot" : "populate-sysroot",
        "do_populate_lic" : "populate-lic",
        "do_package_write_ipk" : "deploy-ipk",
        "do_package_write_deb" : "deploy-deb",
        "do_package_write_rpm" : "deploy-rpm",
        "do_package" : "package",
        "do_deploy" : "deploy",
    }

    for task in range(len(sq_fn)):
        sstatefile = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/" + sq_hashfn[task] + "_" + mapping[sq_task[task]] + ".tgz")
        sstatefile = sstatefile.replace("${BB_TASKHASH}", sq_hash[task])
        if os.path.exists(sstatefile):
            bb.debug(2, "SState: Found valid sstate file %s" % sstatefile)
            ret.append(task)
            continue
        else:
            bb.debug(2, "SState: Looked for but didn't find file %s" % sstatefile)

    mirrors = d.getVar("SSTATE_MIRRORS", True)
    if mirrors:
        # Copy the data object and override DL_DIR and SRC_URI
        localdata = bb.data.createCopy(d)
        bb.data.update_data(localdata)

        dldir = localdata.expand("/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache")
        localdata.setVar('DL_DIR', dldir)
        localdata.setVar('PREMIRRORS', mirrors)

        bb.debug(2, "SState using premirror of: %s" % mirrors)

        for task in range(len(sq_fn)):
            if task in ret:
                continue

            sstatefile = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/sstate-cache/" + sq_hashfn[task] + "_" + mapping[sq_task[task]] + ".tgz")
            sstatefile = sstatefile.replace("${BB_TASKHASH}", sq_hash[task])

            srcuri = "file://" + os.path.basename(sstatefile)
            localdata.setVar('SRC_URI', srcuri)
            bb.debug(2, "SState: Attempting to fetch %s" % srcuri)

            try:
                fetcher = bb.fetch2.Fetch(srcuri.split(), localdata)
                fetcher.checkstatus()
                bb.debug(2, "SState: Successful fetch test for %s" % srcuri)
                ret.append(task)
            except:
                bb.debug(2, "SState: Unsuccessful fetch test for %s" % srcuri)
                pass

    return ret
}


python package_qa_handle_error () {
def package_qa_handle_error(error_class, error_msg, d):
    package_qa_write_error(error_msg, d)
    if error_class in (d.getVar("ERROR_QA", True) or "").split():
        bb.error("QA Issue: %s" % error_msg)
        return False
    else:
        bb.warn("QA Issue: %s" % error_msg)
        return True
}


python do_fetch () {
	bb.build.exec_func('base_do_fetch', d)
}


python package_rpm_mapping_rename_hook () {
	bb.build.exec_func('package_mapping_rename_hook', d)
}


python all_multilib_tune_values () {
def all_multilib_tune_values(d, var, unique = True, need_split = True, delim = ' '):
	"""Return a string of all ${var} in all multilib tune configuration"""
	values = []
	value = d.getVar(var, True) or ""
	if value != "":
		if need_split:
			for item in value.split(delim):
				values.append(item)
		else:
			values.append(value)
	variants = d.getVar("MULTILIB_VARIANTS", True) or ""
	for item in variants.split():
		localdata = bb.data.createCopy(d)
		overrides = localdata.getVar("OVERRIDES", False) + ":virtclass-multilib-" + item
		localdata.setVar("OVERRIDES", overrides)
		bb.data.update_data(localdata)
		value = localdata.getVar(var, True) or ""
		if value != "":
			if need_split:
				for item in value.split(delim):
					values.append(item)
			else:
				values.append(value)
	if unique:
		#we do this to keep order as much as possible
		ret = []
		for value in values:
			if not value in ret:
				ret.append(value)
	else:
		ret = values
	return " ".join(ret)}


python set_timedata () {
def set_timedata(var, data):
    import time
    time = time.time()
    cputime = get_cputime()
    proctime = get_process_cputime(os.getpid())
    data.setVar(var, (time, cputime, proctime))
}


python package_get_auto_pr () {
	# per recipe PRSERV_HOST PRSERV_PORT
	pn = d.getVar('PN', True)
	host = d.getVar("PRSERV_HOST_" + pn, True)
	port = d.getVar("PRSERV_PORT_" + pn, True)
	if not (host is None):
		d.setVar("PRSERV_HOST", host)
	if not (port is None):
		d.setVar("PRSERV_PORT", port)
	if d.getVar('USE_PR_SERV', True) != "0":
		try:
			auto_pr=prserv_get_pr_auto(d)
		except Exception as e:
			bb.fatal("Can NOT get PRAUTO, exception %s" %  str(e))
			return
		if auto_pr is None:
			if d.getVar('PRSERV_LOCKDOWN', True):
				bb.fatal("Can NOT get PRAUTO from lockdown exported file")
			else:
				bb.fatal("Can NOT get PRAUTO from remote PR service")
			return
		d.setVar('PRAUTO',str(auto_pr))
}


python read_shlibdeps () {
	packages = d.getVar('PACKAGES', True).split()
	for pkg in packages:
		rdepends = bb.utils.explode_dep_versions(d.getVar('RDEPENDS_' + pkg, False) or d.getVar('RDEPENDS', False) or "")

		for extension in ".shlibdeps", ".pcdeps", ".clilibdeps":
			depsfile = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/packages-split/" + pkg + extension)
			if os.access(depsfile, os.R_OK):
				fd = file(depsfile)
				lines = fd.readlines()
				fd.close()
				for l in lines:
					rdepends[l.rstrip()] = ""
		d.setVar('RDEPENDS_' + pkg, bb.utils.join_deps(rdepends, commasep=False))
}


python base_ifelse () {
def base_ifelse(condition, iftrue = True, iffalse = False):
    return oe.utils.ifelse(condition, iftrue, iffalse)
}


python package_qa_check_license () {
def package_qa_check_license(workdir, d):
    """
    Check for changes in the license files
    """
    import tempfile
    sane = True

    lic_files = d.getVar('LIC_FILES_CHKSUM', True)
    lic = d.getVar('LICENSE', True)
    pn = d.getVar('PN', True)

    if lic == "CLOSED":
        return True

    if not lic_files:
        # just throw a warning now. Once licensing data in entered for enough of the recipes,
        # this will be converted into error and False will be returned.
        bb.error(pn + ": Recipe file does not have license file information (LIC_FILES_CHKSUM)")
        return False

    srcdir = d.getVar('S', True)

    for url in lic_files.split():
        (type, host, path, user, pswd, parm) = bb.decodeurl(url)
        srclicfile = os.path.join(srcdir, path)
        if not os.path.isfile(srclicfile):
            raise bb.build.FuncFailed( pn + ": LIC_FILES_CHKSUM points to an invalid file: " + srclicfile)

        if 'md5' not in parm:
            bb.error(pn + ": md5 checksum is not specified for ", url)
            return False
        beginline, endline = 0, 0
        if 'beginline' in parm:
            beginline = int(parm['beginline'])
        if 'endline' in parm:
            endline = int(parm['endline'])

        if (not beginline) and (not endline):
            md5chksum = bb.utils.md5_file(srclicfile)
        else:
            fi = open(srclicfile, 'r')
            fo = tempfile.NamedTemporaryFile(mode='wb', prefix='poky.', suffix='.tmp', delete=False)
            tmplicfile = fo.name;
            lineno = 0
            linesout = 0
            for line in fi:
                lineno += 1
                if (lineno >= beginline):
                    if ((lineno <= endline) or not endline):
                        fo.write(line)
                        linesout += 1
                    else:
                        break
            fo.flush()
            fo.close()
            fi.close()
            md5chksum = bb.utils.md5_file(tmplicfile)
            os.unlink(tmplicfile)

        if parm['md5'] == md5chksum:
            bb.note (pn + ": md5 checksum matched for ", url)
        else:
            bb.error (pn + ": md5 data is not matching for ", url)
            bb.error (pn + ": The new md5 checksum is ", md5chksum)
            bb.error (pn + ": Check if the license information has changed in")
            sane = False

    return sane
}


python base_do_fetch () {

	src_uri = (d.getVar('SRC_URI', True) or "").split()
	if len(src_uri) == 0:
		return

	localdata = bb.data.createCopy(d)
	bb.data.update_data(localdata)

        try:
            fetcher = bb.fetch2.Fetch(src_uri, localdata)
            fetcher.download()
        except bb.fetch2.BBFetchException, e:
            raise bb.build.FuncFailed(e)
}


python do_package_qa () {
    bb.note("DO PACKAGE QA")

    logdir = d.getVar('T', True)
    pkg = d.getVar('PN', True)

    # Check the compile log for host contamination
    compilelog = os.path.join(logdir,"log.do_compile")

    statement = "grep -e 'CROSS COMPILE Badness:' -e 'is unsafe for cross-compilation' %s > /dev/null" % compilelog
    if os.system(statement) == 0:
        bb.warn("%s: The compile log indicates that host include and/or library paths were used.  Please check the log '%s' for more information." % \
                (pkg, compilelog))


    # Check the install log for host contamination
    installlog = os.path.join(logdir,"log.do_install")

    statement = "grep -e 'CROSS COMPILE Badness:' -e 'is unsafe for cross-compilation' %s > /dev/null" % installlog
    if os.system(statement) == 0:
        bb.warn("%s: The install log indicates that host include and/or library paths were used.  Please check the log '%s' for more information." % \
                (pkg, installlog))

    # Scan the packages...
    pkgdest = d.getVar('PKGDEST', True)
    packages = d.getVar('PACKAGES', True)

    # no packages should be scanned
    if not packages:
        return

    testmatrix = d.getVarFlags("QAPATHTEST")

    g = globals()
    walk_sane = True
    rdepends_sane = True
    for package in packages.split():
        skip = (d.getVar('INSANE_SKIP_' + package, True) or "").split()
        if skip:
            bb.note("Package %s skipping QA tests: %s" % (package, str(skip)))
        warnchecks = []
        for w in (d.getVar("WARN_QA", True) or "").split():
            if w in skip:
               continue
            if w in testmatrix and testmatrix[w] in g:
                warnchecks.append(g[testmatrix[w]])
        errorchecks = []
        for e in (d.getVar("ERROR_QA", True) or "").split():
            if e in skip:
               continue
            if e in testmatrix and testmatrix[e] in g:
                errorchecks.append(g[testmatrix[e]])

        bb.note("Checking Package: %s" % package)
        path = "%s/%s" % (pkgdest, package)
        if not package_qa_walk(path, warnchecks, errorchecks, skip, package, d):
            walk_sane  = False
        if not package_qa_check_rdepends(package, pkgdest, skip, d):
            rdepends_sane = False


    if not walk_sane or not rdepends_sane:
        bb.fatal("QA run found fatal errors. Please consider fixing them.")
    bb.note("DONE with PACKAGE QA")
}


python do_populate_sysroot () {
    #
    # if do_stage exists, we're legacy. In that case run the do_stage,
    # modify the SYSROOT_DESTDIR variable and then run the staging preprocess
    # functions against staging directly.
    #
    # Otherwise setup a destdir, copy the results from do_install
    # and run the staging preprocess against that
    #

    bb.build.exec_func("sysroot_stage_all", d)
    for f in (d.getVar('SYSROOT_PREPROCESS_FUNCS', True) or '').split():
        bb.build.exec_func(f, d)
}


python __anonymous () {
None}


python base_prune_suffix () {
def base_prune_suffix(var, suffixes, d):
    return oe.utils.prune_suffix(var, suffixes, d)
}


python do_package_rpm () {
	import os

	# We need a simple way to remove the MLPREFIX from the package name,
	# and dependency information...
	def strip_multilib(name, d):
		ml = d.getVar("MLPREFIX", True)
		if ml and name and len(ml) != 0 and name.find(ml) >= 0:
			return "".join(name.split(ml))
		return name

	workdir = d.getVar('WORKDIR', True)
	outdir = d.getVar('DEPLOY_DIR_IPK', True)
	tmpdir = d.getVar('TMPDIR', True)
	pkgd = d.getVar('PKGD', True)
	pkgdest = d.getVar('PKGDEST', True)
	if not workdir or not outdir or not pkgd or not tmpdir:
		bb.error("Variables incorrectly set, unable to package")
		return

	packages = d.getVar('PACKAGES', True)
	if not packages or packages == '':
		bb.debug(1, "No packages; nothing to do")
		return

	# Construct the spec file...
	srcname    = strip_multilib(d.getVar('PN', True), d)
	outspecfile = workdir + "/" + srcname + ".spec"
	d.setVar('OUTSPECFILE', outspecfile)
	bb.build.exec_func('write_specfile', d)

	# Construct per file dependencies file
	def dump_filerdeps(varname, outfile, d):
		outfile.write("#!/bin/sh\n")
		outfile.write("\n# Dependency table\n")
		for pkg in packages.split():
			dependsflist_key = 'FILE' + varname + 'FLIST' + "_" + pkg
			dependsflist = (d.getVar(dependsflist_key, True) or "")
			for dfile in dependsflist.split():
				key = "FILE" + varname + "_" + dfile + "_" + pkg
				depends_dict = bb.utils.explode_dep_versions(d.getVar(key, True) or "")
				file = dfile.replace("@underscore@", "_")
				file = file.replace("@closebrace@", "]")
				file = file.replace("@openbrace@", "[")
				file = file.replace("@tab@", "\t")
				file = file.replace("@space@", " ")
				file = file.replace("@at@", "@")
				outfile.write("#" + pkgd + file + "\t")
				for dep in depends_dict:
					ver = depends_dict[dep]
					if dep and ver:
						ver = ver.replace("(","")
						ver = ver.replace(")","")
						outfile.write(dep + " " + ver + " ")
					else:
						outfile.write(dep + " ")
				outfile.write("\n")
		outfile.write("\n\nwhile read file_name ; do\n")
		outfile.write("\tlength=$(echo \"#${file_name}\t\" | wc -c )\n")
		outfile.write("\tline=$(grep \"^#${file_name}\t\" $0 | cut -c ${length}- )\n")
		outfile.write("\tprintf \"%s\\n\" ${line}\n")
		outfile.write("done\n")

	# OE-core dependencies a.k.a. RPM requires
	outdepends = workdir + "/" + srcname + ".requires"

	try:
		from __builtin__ import file
		dependsfile = file(outdepends, 'w')
	except OSError:
		raise bb.build.FuncFailed("unable to open spec file for writing.")

	dump_filerdeps('RDEPENDS', dependsfile, d)

	dependsfile.close()
	os.chmod(outdepends, 0755)

	# OE-core / RPM Provides
	outprovides = workdir + "/" + srcname + ".provides"

	try:
		from __builtin__ import file
		providesfile = file(outprovides, 'w')
	except OSError:
		raise bb.build.FuncFailed("unable to open spec file for writing.")

	dump_filerdeps('RPROVIDES', providesfile, d)

	providesfile.close()
	os.chmod(outprovides, 0755)

	# Setup the rpmbuild arguments...
	rpmbuild = d.getVar('RPMBUILD', True)
	targetsys = d.getVar('TARGET_SYS', True)
	targetvendor = d.getVar('TARGET_VENDOR', True)
	package_arch = d.getVar('PACKAGE_ARCH', True) or ""
	if package_arch not in "all any noarch".split():
		ml_prefix = (d.getVar('MLPREFIX', True) or "").replace("-", "_")
		d.setVar('PACKAGE_ARCH_EXTEND', ml_prefix + package_arch)
	else:
		d.setVar('PACKAGE_ARCH_EXTEND', package_arch)
	pkgwritedir = d.expand('/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/deploy-rpms/${PACKAGE_ARCH_EXTEND}')
	pkgarch = d.expand('${PACKAGE_ARCH_EXTEND}-poky-linux')
	magicfile = d.expand('/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/share/misc/magic.mgc')
	bb.mkdirhier(pkgwritedir)
	os.chmod(pkgwritedir, 0755)

	cmd = rpmbuild
	cmd = cmd + " --nodeps --short-circuit --target " + pkgarch + " --buildroot " + pkgd
	cmd = cmd + " --define '_topdir " + workdir + "' --define '_rpmdir " + pkgwritedir + "'"
	cmd = cmd + " --define '_build_name_fmt %%{NAME}-%%{VERSION}-%%{RELEASE}.%%{ARCH}.rpm'"
	cmd = cmd + " --define '_use_internal_dependency_generator 0'"
	cmd = cmd + " --define '__find_requires " + outdepends + "'"
	cmd = cmd + " --define '__find_provides " + outprovides + "'"
	cmd = cmd + " --define '_unpackaged_files_terminate_build 0'"
	cmd = cmd + " --define 'debug_package %{nil}'"
	cmd = cmd + " --define '_rpmfc_magic_path " + magicfile + "'"
	cmd = cmd + " --define '_tmppath " + workdir + "'"
	cmd = cmd + " -bb " + outspecfile

	# Build the rpm package!
	d.setVar('BUILDSPEC', cmd + "\n")
	d.setVarFlag('BUILDSPEC', 'func', '1')
	bb.build.exec_func('BUILDSPEC', d)
}


python package_name_hook () {
	bb.build.exec_func('debian_package_name_hook', d)
}


python patch_path () {
def patch_path(url, fetch, workdir):
	"""Return the local path of a patch, or None if this isn't a patch"""

	local = fetch.localpath(url)
	base, ext = os.path.splitext(os.path.basename(local))
	if ext in ('.gz', '.bz2', '.Z'):
		local = os.path.join(workdir, base)
		ext = os.path.splitext(base)[1]

	urldata = fetch.ud[url]
	if "apply" in urldata.parm:
		apply = oe.types.boolean(urldata.parm["apply"])
		if not apply:
			return
	elif ext not in (".diff", ".patch"):
		return

	return local
}


python get_timedata () {
def get_timedata(var, data):
    import time
    timedata = data.getVar(var, False)
    if timedata is None:
        return
    oldtime, oldcpu, oldproc = timedata
    procdiff = get_process_cputime(os.getpid()) - oldproc
    cpudiff = get_cputime() - oldcpu
    timediff = time.time() - oldtime
    if cpudiff > 0:
        cpuperc = float(procdiff) * 100 / cpudiff
    else:
        cpuperc = None
    return timediff, cpuperc
}


python base_get_metadata_monotone_revision () {
def base_get_metadata_monotone_revision(path, d):
	monotone_revision = "<unknown>"
	try:
		monotone_revision = file( "%s/_MTN/revision" % path ).read().strip()
		if monotone_revision.startswith( "format_version" ):
			monotone_revision_words = monotone_revision.split()
			monotone_revision = monotone_revision_words[ monotone_revision_words.index( "old_revision" )+1][1:-1]
	except IOError:
		pass
	return monotone_revision
}


python read_subpackage_metadata () {
	import oe.packagedata

	data = oe.packagedata.read_pkgdata(d.getVar('PN', True), d)

	for key in data.keys():
		d.setVar(key, data[key])

	for pkg in d.getVar('PACKAGES', True).split():
		sdata = oe.packagedata.read_subpkgdata(pkg, d)
		for key in sdata.keys():
			d.setVar(key, sdata[key])
}


python do_package () {
        # Change the following version to cause sstate to invalidate the package
        # cache.  This is useful if an item this class depends on changes in a
        # way that the output of this class changes.  rpmdeps is a good example
        # as any change to rpmdeps requires this to be rerun.
        # PACKAGE_BBCLASS_VERSION = "1"

	packages = (d.getVar('PACKAGES', True) or "").split()
	if len(packages) < 1:
		bb.debug(1, "No packages to build, skipping do_package")
		return

	workdir = d.getVar('WORKDIR', True)
	outdir = d.getVar('DEPLOY_DIR', True)
	dest = d.getVar('D', True)
	dvar = d.getVar('PKGD', True)
	pn = d.getVar('PN', True)

	if not workdir or not outdir or not dest or not dvar or not pn or not packages:
		bb.error("WORKDIR, DEPLOY_DIR, D, PN and PKGD all must be defined, unable to package")
		return

	for f in (d.getVar('PACKAGEFUNCS', True) or '').split():
		bb.build.exec_func(f, d)
}


python check_license_flags () {
def check_license_flags(d):
    """
    This function checks if a recipe has any LICENSE_FLAGs that
    aren't whitelisted.

    If it does, it returns the first LICENSE_FLAG missing from the
    whitelist, or all the LICENSE_FLAGs if there is no whitelist.

    If everything is is properly whitelisted, it returns None.
    """

    def license_flag_matches(flag, whitelist, pn):
        """
        Return True if flag matches something in whitelist, None if not.

        Before we test a flag against the whitelist, we append _bblayers
        to it.  We then try to match that string against the
        whitelist.  This covers the normal case, where we expect
        LICENSE_FLAGS to be a simple string like 'commercial', which
        the user typically matches exactly in the whitelist by
        explicitly appending the package name e.g 'commercial_foo'.
        If we fail the match however, we then split the flag across
        '_' and append each fragment and test until we either match or
        run out of fragments.
        """
        flag_pn = ("%s_%s" % (flag, pn))
        for candidate in whitelist:
            if flag_pn == candidate:
                    return True

        flag_cur = ""
        flagments = flag_pn.split("_")
        flagments.pop() # we've already tested the full string
        for flagment in flagments:
            if flag_cur:
                flag_cur += "_"
            flag_cur += flagment
            for candidate in whitelist:
                if flag_cur == candidate:
                    return True
        return False

    def all_license_flags_match(license_flags, whitelist):
        """ Return first unmatched flag, None if all flags match """
        pn = d.getVar('PN', True)
        split_whitelist = whitelist.split()
        for flag in license_flags.split():
            if not license_flag_matches(flag, split_whitelist, pn):
                return flag
        return None

    license_flags = d.getVar('LICENSE_FLAGS', True)
    if license_flags:
        whitelist = d.getVar('LICENSE_FLAGS_WHITELIST', True)
        if not whitelist:
            return license_flags
        unmatched_flag = all_license_flags_match(license_flags, whitelist)
        if unmatched_flag:
            return unmatched_flag
    return None

}


python set_device () {
def set_device(e):
    tmpdir = e.data.getVar('TMPDIR', True)
    try:
        os.remove(e.data.getVar('DEVFILE', True))
    except:
        pass
    ############################################################################
    # We look for the volume TMPDIR lives on. To do all disks would make little
    # sense and not give us any particularly useful data. In theory we could do
    # something like stick DL_DIR on a different partition and this would
    # throw stats gathering off. The same goes with SSTATE_DIR. However, let's
    # get the basics in here and work on the cornercases later.
    # A note. /proc/diskstats does not contain info on encryptfs, tmpfs, etc.
    # If we end up hitting one of these fs, we'll just skip diskstats collection.
    ############################################################################
    device=os.stat(tmpdir)
    majordev=os.major(device.st_dev)
    minordev=os.minor(device.st_dev)
    ############################################################################
    # Bug 1700:
    # Because tmpfs/encryptfs/ramfs etc inserts no entry in /proc/diskstats
    # we set rdev to NoLogicalDevice and search for it later. If we find NLD
    # we do not collect diskstats as the method to collect meaningful statistics
    # for these fs types requires a bit more research.
    ############################################################################
    rdev="NoLogicalDevice"
    try:
        for line in open("/proc/diskstats", "r"):
            if majordev == int(line.split()[0]) and minordev == int(line.split()[1]):
               rdev=line.split()[2]
    except:
        pass
    file = open(e.data.getVar('DEVFILE', True), "w")
    file.write(rdev)
    file.close()
}


python base_contains () {
def base_contains(variable, checkvalues, truevalue, falsevalue, d):
    return oe.utils.contains(variable, checkvalues, truevalue, falsevalue, d)
}


python package_qa_check_perm () {
def package_qa_check_perm(path,name,d, elf, messages):
    """
    Check the permission of files
    """
    return
}


python oe_import () {
def oe_import(d):
    import os, sys

    bbpath = d.getVar("BBPATH", True).split(":")
    sys.path[0:0] = [os.path.join(dir, "lib") for dir in bbpath]

    def inject(name, value):
        """Make a python object accessible from the metadata"""
        if hasattr(bb.utils, "_context"):
            bb.utils._context[name] = value
        else:
            __builtins__[name] = value

    import oe.data
    for toimport in oe.data.typed_value("OE_IMPORTS", d):
        imported = __import__(toimport)
        inject(toimport.split(".", 1)[0], imported)
}


python package_qa_walk () {
def package_qa_walk(path, warnfuncs, errorfuncs, skip, package, d):
    import oe.qa

    #if this will throw an exception, then fix the dict above
    target_os   = d.getVar('TARGET_OS', True)
    target_arch = d.getVar('TARGET_ARCH', True)

    warnings = []
    errors = []
    for root, dirs, files in os.walk(path):
        for file in files:
            path = os.path.join(root,file)
            elf = oe.qa.ELFFile(path)
            try:
                elf.open()
            except:
                elf = None
            for func in warnfuncs:
                func(path, package, d, elf, warnings)
            for func in errorfuncs:
                func(path, package, d, elf, errors)

    for w in warnings:
        bb.warn("QA Issue: %s" % w)
        package_qa_write_error(w, d)
    for e in errors:
        bb.error("QA Issue: %s" % e)
        package_qa_write_error(e, d)

    return len(errors) == 0
}


python do_split_packages () {
def do_split_packages(d, root, file_regex, output_pattern, description, postinst=None, recursive=False, hook=None, extra_depends=None, aux_files_pattern=None, postrm=None, allow_dirs=False, prepend=False, match_path=False, aux_files_pattern_verbatim=None, allow_links=False):
	"""
	Used in .bb files to split up dynamically generated subpackages of a
	given package, usually plugins or modules.
	"""

	ml = d.getVar("MLPREFIX", True)
	if ml:
		if not output_pattern.startswith(ml):
			output_pattern = ml + output_pattern

		newdeps = []
		for dep in (extra_depends or "").split():
			if dep.startswith(ml):
				newdeps.append(dep)
			else:
				newdeps.append(ml + dep)
		if newdeps:
			extra_depends = " ".join(newdeps)

	dvar = d.getVar('PKGD', True)

	packages = d.getVar('PACKAGES', True).split()

	if postinst:
		postinst = '#!/bin/sh\n' + postinst + '\n'
	if postrm:
		postrm = '#!/bin/sh\n' + postrm + '\n'
	if not recursive:
		objs = os.listdir(dvar + root)
	else:
		objs = []
		for walkroot, dirs, files in os.walk(dvar + root):
			for file in files:
				relpath = os.path.join(walkroot, file).replace(dvar + root + '/', '', 1)
				if relpath:
					objs.append(relpath)

	if extra_depends == None:
		# This is *really* broken
		mainpkg = packages[0]
		# At least try and patch it up I guess...
		if mainpkg.find('-dbg'):
			mainpkg = mainpkg.replace('-dbg', '')
		if mainpkg.find('-dev'):
			mainpkg = mainpkg.replace('-dev', '')
		extra_depends = mainpkg

	for o in sorted(objs):
		import re, stat
		if match_path:
			m = re.match(file_regex, o)
		else:
			m = re.match(file_regex, os.path.basename(o))

		if not m:
			continue
		f = os.path.join(dvar + root, o)
		mode = os.lstat(f).st_mode
		if not (stat.S_ISREG(mode) or (allow_links and stat.S_ISLNK(mode)) or (allow_dirs and stat.S_ISDIR(mode))):
			continue
		on = legitimize_package_name(m.group(1))
		pkg = output_pattern % on
		if not pkg in packages:
			if prepend:
				packages = [pkg] + packages
			else:
				packages.append(pkg)
		oldfiles = d.getVar('FILES_' + pkg, True)
		if not oldfiles:
			the_files = [os.path.join(root, o)]
			if aux_files_pattern:
				if type(aux_files_pattern) is list:
					for fp in aux_files_pattern:
						the_files.append(fp % on)
				else:
					the_files.append(aux_files_pattern % on)
			if aux_files_pattern_verbatim:
				if type(aux_files_pattern_verbatim) is list:
					for fp in aux_files_pattern_verbatim:
						the_files.append(fp % m.group(1))
				else:
					the_files.append(aux_files_pattern_verbatim % m.group(1))
			d.setVar('FILES_' + pkg, " ".join(the_files))
			if extra_depends != '':
				d.appendVar('RDEPENDS_' + pkg, ' ' + extra_depends)
			d.setVar('DESCRIPTION_' + pkg, description % on)
			if postinst:
				d.setVar('pkg_postinst_' + pkg, postinst)
			if postrm:
				d.setVar('pkg_postrm_' + pkg, postrm)
		else:
			d.setVar('FILES_' + pkg, oldfiles + " " + os.path.join(root, o))
		if callable(hook):
			hook(f, pkg, file_regex, output_pattern, m.group(1))

	d.setVar('PACKAGES', ' '.join(packages))
}


python sstate_state_fromvars () {
def sstate_state_fromvars(d, task = None):
    if task is None:
        task = d.getVar('BB_CURRENTTASK', True)
        if not task:
            bb.fatal("sstate code running without task context?!")
        task = task.replace("_setscene", "")

    name = d.getVarFlag("do_" + task, 'sstate-name', True)
    inputs = (d.getVarFlag("do_" + task, 'sstate-inputdirs', True) or "").split()
    outputs = (d.getVarFlag("do_" + task, 'sstate-outputdirs', True) or "").split()
    plaindirs = (d.getVarFlag("do_" + task, 'sstate-plaindirs', True) or "").split()
    lockfiles = (d.getVarFlag("do_" + task, 'sstate-lockfile', True) or "").split()
    lockfilesshared = (d.getVarFlag("do_" + task, 'sstate-lockfile-shared', True) or "").split()
    interceptfuncs = (d.getVarFlag("do_" + task, 'sstate-interceptfuncs', True) or "").split()
    if not name or len(inputs) != len(outputs):
        bb.fatal("sstate variables not setup correctly?!")

    ss = sstate_init(name, task, d)
    for i in range(len(inputs)):
        sstate_add(ss, inputs[i], outputs[i], d)
    ss['lockfiles'] = lockfiles
    ss['lockfiles-shared'] = lockfilesshared
    ss['plaindirs'] = plaindirs
    ss['interceptfuncs'] = interceptfuncs
    return ss
}


python do_unpack () {
	bb.build.exec_func('base_do_unpack', d)
}


python package_qa_check_arch () {
def package_qa_check_arch(path,name,d, elf, messages):
    """
    Check if archs are compatible
    """
    if not elf:
        return

    target_os   = d.getVar('TARGET_OS', True)
    target_arch = d.getVar('TARGET_ARCH', True)
    provides = d.getVar('PROVIDES', d, True)

    # FIXME: Cross package confuse this check, so just skip them
    for s in ['cross', 'nativesdk', 'cross-canadian']:
        if bb.data.inherits_class(s, d):
            return

    # avoid following links to /usr/bin (e.g. on udev builds)
    # we will check the files pointed to anyway...
    if os.path.islink(path):
        return

    #if this will throw an exception, then fix the dict above
    (machine, osabi, abiversion, littleendian, bits) \
        = package_qa_get_machine_dict()[target_os][target_arch]

    # Check the architecture and endiannes of the binary
    if not ((machine == elf.machine()) or \
	("virtual/kernel" in provides) and (target_os == "linux-gnux32")):
        messages.append("Architecture did not match (%d to %d) on %s" % \
                 (machine, elf.machine(), package_qa_clean_path(path,d)))
    elif not ((bits == elf.abiSize()) or  \
	("virtual/kernel" in provides) and (target_os == "linux-gnux32")):
        messages.append("Bit size did not match (%d to %d) %s on %s" % \
                 (bits, elf.abiSize(), bpn, package_qa_clean_path(path,d)))
    elif not littleendian == elf.isLittleEndian():
        messages.append("Endiannes did not match (%d to %d) on %s" % \
                 (littleendian, elf.isLittleEndian(), package_qa_clean_path(path,d)))
}


python runstrip () {
def runstrip(file, elftype, d):
    # Function to strip a single file, called from split_and_strip_files below
    # A working 'file' (one which works on the target architecture)
    #
    # The elftype is a bit pattern (explained in split_and_strip_files) to tell
    # us what type of file we're processing...
    # 4 - executable
    # 8 - shared library

    import commands, stat

    pathprefix = "export PATH=%s; " % d.getVar('PATH', True)
    strip = d.getVar("STRIP", True)

    # Handle kernel modules specifically - .debug directories here are pointless
    if file.find("/lib/modules/") != -1 and file.endswith(".ko"):
        return os.system("%s'%s' --strip-debug --remove-section=.comment --remove-section=.note --preserve-dates '%s'" % (pathprefix, strip, file))

    newmode = None
    if not os.access(file, os.W_OK) or os.access(file, os.R_OK):
        origmode = os.stat(file)[stat.ST_MODE]
        newmode = origmode | stat.S_IWRITE | stat.S_IREAD
        os.chmod(file, newmode)

    extraflags = ""
    # .so and shared library
    if ".so" in file and elftype & 8:
        extraflags = "--remove-section=.comment --remove-section=.note --strip-unneeded"
    # shared or executable:
    elif elftype & 8 or elftype & 4:
        extraflags = "--remove-section=.comment --remove-section=.note"

    stripcmd = "'%s' %s '%s'" % (strip, extraflags, file)
    bb.debug(1, "runstrip: %s" % stripcmd)

    ret = os.system("%s%s" % (pathprefix, stripcmd))

    if newmode:
        os.chmod(file, origmode)

    if ret:
        bb.error("runstrip: '%s' strip command failed" % stripcmd)

    return 0
}


python check_sanity_validmachine () {
def check_sanity_validmachine(e):
    from bb import data

    messages = ""

    # Check TUNE_ARCH is set
    if data.getVar('TUNE_ARCH', e.data, True) == 'INVALID':
        messages = messages + 'TUNE_ARCH is unset. Please ensure your MACHINE configuration includes a valid tune configuration file which will set this correctly.\n'

    # Check TARGET_ARCH is set correctly
    if data.getVar('TARGE_ARCH', e.data, False) == 'i586':
        messages = messages + 'TARGET_ARCH is being overwritten, likely by your MACHINE configuration files.\nPlease use a valid tune configuration file which should set this correctly automatically\nand avoid setting this in the machine configuration. See the OE-Core mailing list for more information.\n'

    # Check TARGET_OS is set
    if data.getVar('TARGET_OS', e.data, True) == 'INVALID':
        messages = messages + 'Please set TARGET_OS directly, or choose a MACHINE or DISTRO that does so.\n'

    # Check that we don't have duplicate entries in PACKAGE_ARCHS & that TUNE_PKGARCH is in PACKAGE_ARCHS
    pkgarchs = data.getVar('PACKAGE_ARCHS', e.data, True)
    tunepkg = data.getVar('TUNE_PKGARCH', e.data, True)
    tunefound = False
    seen = {}
    dups = []

    for pa in pkgarchs.split():
        if seen.get(pa, 0) == 1:
            dups.append(pa)
        else:
            seen[pa] = 1
        if pa == tunepkg:
            tunefound = True

    if len(dups):
       messages = messages + "Error, the PACKAGE_ARCHS variable contains duplicates. The following archs are listed more than once: %s" % " ".join(dups)

    if tunefound == False:
       messages = messages + "Error, the PACKAGE_ARCHS variable does not contain TUNE_PKGARCH (%s)." % tunepkg

    return messages

}


python package_qa_check_desktop () {
def package_qa_check_desktop(path, name, d, elf, messages):
    """
    Run all desktop files through desktop-file-validate.
    """
    if path.endswith(".desktop"):
        desktop_file_validate = os.path.join(d.getVar('STAGING_BINDIR_NATIVE',True),'desktop-file-validate')
        output = os.popen("%s %s" % (desktop_file_validate, path))
        # This only produces output on errors
        for l in output:
            messages.append("Desktop file issue: " + l.strip())
}


python get_diskstats () {
def get_diskstats(dev):
    import itertools
    ############################################################################
    # For info on what these are, see kernel doc file iostats.txt
    ############################################################################
    DSTAT_KEYS = ['ReadsComp', 'ReadsMerged', 'SectRead', 'TimeReads', 'WritesComp', 'SectWrite', 'TimeWrite', 'IOinProgress', 'TimeIO', 'WTimeIO']
    try:
        for x in open("/proc/diskstats", "r"):
            if dev in x:
                diskstats_val = x.rstrip().split()[4:]
    except IOError as e:
        return
    diskstats = dict(itertools.izip(DSTAT_KEYS, diskstats_val))
    return diskstats
}


python src_patches () {
def src_patches(d, all = False ):
	workdir = d.getVar('WORKDIR', True)
	fetch = bb.fetch2.Fetch([], d)
	patches = []
	sources = []
	for url in fetch.urls:
		local = patch_path(url, fetch, workdir)
		if not local:
			if all:
				local = fetch.localpath(url)
				sources.append(local)
			continue

		urldata = fetch.ud[url]
		parm = urldata.parm
		patchname = parm.get('pname') or os.path.basename(local)

		apply, reason = should_apply(parm, d)
		if not apply:
			if reason:
				bb.note("Patch %s %s" % (patchname, reason))
			continue

		patchparm = {'patchname': patchname}
		if "striplevel" in parm:
			striplevel = parm["striplevel"]
		elif "pnum" in parm:
			#bb.msg.warn(None, "Deprecated usage of 'pnum' url parameter in '%s', please use 'striplevel'" % url)
			striplevel = parm["pnum"]
		else:
			striplevel = '1'
		patchparm['striplevel'] = striplevel

		patchdir = parm.get('patchdir')
		if patchdir:
			patchparm['patchdir'] = patchdir

		localurl = bb.encodeurl(('file', '', local, '', '', patchparm))
		patches.append(localurl)

	if all:
		return sources

	return patches
}


python check_conf_exists () {
def check_conf_exists(fn, data):
    bbpath = []
    fn = data.expand(fn)
    vbbpath = data.getVar("BBPATH")
    if vbbpath:
        bbpath += vbbpath.split(":")
    for p in bbpath:
        currname = os.path.join(data.expand(p), fn)
        if os.access(currname, os.R_OK):
            return True
    return False
}


python package_qa_hash_style () {
def package_qa_hash_style(path, name, d, elf, messages):
    """
    Check if the binary has the right hash style...
    """

    if not elf:
        return

    if os.path.islink(path):
        return

    gnu_hash = "--hash-style=gnu" in d.getVar('LDFLAGS', True)
    if not gnu_hash:
        gnu_hash = "--hash-style=both" in d.getVar('LDFLAGS', True)
    if not gnu_hash:
        return

    objdump = d.getVar('OBJDUMP', True)
    env_path = d.getVar('PATH', True)

    sane = False
    has_syms = False

    # If this binary has symbols, we expect it to have GNU_HASH too.
    for line in os.popen("LC_ALL=C PATH=%s %s -p '%s' 2> /dev/null" % (env_path, objdump, path), "r"):
        if "SYMTAB" in line:
            has_syms = True
        if "GNU_HASH" in line:
            sane = True
        if "[mips32]" in line or "[mips64]" in line:
	    sane = True

    if has_syms and not sane:
        messages.append("No GNU_HASH in the elf binary: '%s'" % path)

}


python should_apply () {
def should_apply(parm, d):
	"""Determine if we should apply the given patch"""

	if "mindate" in parm or "maxdate" in parm:
		pn = d.getVar('PN', True)
		srcdate = d.getVar('SRCDATE_%s' % pn, True)
		if not srcdate:
			srcdate = d.getVar('SRCDATE', True)

		if srcdate == "now":
			srcdate = d.getVar('DATE', True)

		if "maxdate" in parm and parm["maxdate"] < srcdate:
			return False, 'is outdated'

		if "mindate" in parm and parm["mindate"] > srcdate:
			return False, 'is predated'


	if "minrev" in parm:
		srcrev = d.getVar('SRCREV', True)
		if srcrev and srcrev < parm["minrev"]:
			return False, 'applies to later revisions'

	if "maxrev" in parm:
		srcrev = d.getVar('SRCREV', True)
		if srcrev and srcrev > parm["maxrev"]:
			return False, 'applies to earlier revisions'

	if "rev" in parm:
		srcrev = d.getVar('SRCREV', True)
		if srcrev and parm["rev"] not in srcrev:
			return False, "doesn't apply to revision"

	if "notrev" in parm:
		srcrev = d.getVar('SRCREV', True)
		if srcrev and parm["notrev"] in srcrev:
			return False, "doesn't apply to revision"

	return True, None
}


python populate_packages () {
	import glob, stat, errno, re

	workdir = d.getVar('WORKDIR', True)
	outdir = d.getVar('DEPLOY_DIR', True)
	dvar = d.getVar('PKGD', True)
	packages = d.getVar('PACKAGES', True)
	pn = d.getVar('PN', True)

	bb.mkdirhier(outdir)
	os.chdir(dvar)

	# Sanity check PACKAGES for duplicates - should be moved to
	# sanity.bbclass once we have the infrastucture
	package_list = []
	for pkg in packages.split():
		if pkg in package_list:
			bb.error("%s is listed in PACKAGES multiple times, this leads to packaging errors." % pkg)
		else:
			package_list.append(pkg)

	pkgdest = d.getVar('PKGDEST', True)
	os.system('rm -rf %s' % pkgdest)

	seen = []

	for pkg in package_list:
		localdata = bb.data.createCopy(d)
		root = os.path.join(pkgdest, pkg)
		bb.mkdirhier(root)

		localdata.setVar('PKG', pkg)
		overrides = localdata.getVar('OVERRIDES', True)
		if not overrides:
			raise bb.build.FuncFailed('OVERRIDES not defined')
		localdata.setVar('OVERRIDES', overrides + ':' + pkg)
		bb.data.update_data(localdata)

		filesvar = localdata.getVar('FILES', True) or ""
		files = filesvar.split()
		file_links = {}
		for file in files:
			if os.path.isabs(file):
				file = '.' + file
			if not os.path.islink(file):
				if os.path.isdir(file):
					newfiles =  [ os.path.join(file,x) for x in os.listdir(file) ]
					if newfiles:
						files += newfiles
						continue
			globbed = glob.glob(file)
			if globbed:
				if [ file ] != globbed:
					files += globbed
					continue
			if (not os.path.islink(file)) and (not os.path.exists(file)):
				continue
			if file in seen:
				continue
			seen.append(file)

			def mkdir(src, dest, p):
				src = os.path.join(src, p)
				dest = os.path.join(dest, p)
				bb.mkdirhier(dest)
				fstat = os.stat(src)
				os.chmod(dest, fstat.st_mode)
				os.chown(dest, fstat.st_uid, fstat.st_gid)
				if p not in seen:
					seen.append(p)

			def mkdir_recurse(src, dest, paths):
				while paths.startswith("./"):
					paths = paths[2:]
				p = "."
				for c in paths.split("/"):
					p = os.path.join(p, c)
					if not os.path.exists(os.path.join(dest, p)):
						mkdir(src, dest, p)

			if os.path.isdir(file) and not os.path.islink(file):
				mkdir_recurse(dvar, root, file)
				continue

			mkdir_recurse(dvar, root, os.path.dirname(file))
			fpath = os.path.join(root,file)
			if not os.path.islink(file):
				os.link(file, fpath)
				fstat = os.stat(file)
				os.chmod(fpath, fstat.st_mode)
				os.chown(fpath, fstat.st_uid, fstat.st_gid)
				continue
			ret = bb.copyfile(file, fpath)
			if ret is False or ret == 0:
				raise bb.build.FuncFailed("File population failed")

		del localdata
	os.chdir(workdir)

	unshipped = []
	for root, dirs, files in os.walk(dvar):
		dir = root[len(dvar):]
		if not dir:
			dir = os.sep
		for f in (files + dirs):
			path = os.path.join(dir, f)
			if ('.' + path) not in seen:
				unshipped.append(path)

	if unshipped != []:
		bb.warn("For recipe %s, the following files/directories were installed but not shipped in any package:" % pn)
		for f in unshipped:
			bb.warn("  " + f)

	bb.build.exec_func("package_name_hook", d)

	for pkg in package_list:
		pkgname = d.getVar('PKG_%s' % pkg, True)
		if pkgname is None:
			d.setVar('PKG_%s' % pkg, pkg)

	dangling_links = {}
	pkg_files = {}
	for pkg in package_list:
		dangling_links[pkg] = []
		pkg_files[pkg] = []
		inst_root = os.path.join(pkgdest, pkg)
		for root, dirs, files in os.walk(inst_root):
			for f in files:
				path = os.path.join(root, f)
				rpath = path[len(inst_root):]
				pkg_files[pkg].append(rpath)
				try:
					s = os.stat(path)
				except OSError, (err, strerror):
					if err != errno.ENOENT:
						raise
					target = os.readlink(path)
					if target[0] != '/':
						target = os.path.join(root[len(inst_root):], target)
					dangling_links[pkg].append(os.path.normpath(target))

	for pkg in package_list:
		rdepends = bb.utils.explode_dep_versions(d.getVar('RDEPENDS_' + pkg, True) or d.getVar('RDEPENDS', True) or "")

		for l in dangling_links[pkg]:
			found = False
			bb.debug(1, "%s contains dangling link %s" % (pkg, l))
			for p in package_list:
				for f in pkg_files[p]:
					if f == l:
						found = True
						bb.debug(1, "target found in %s" % p)
						if p == pkg:
							break
						if p not in rdepends:
							rdepends[p] = ""
						break
			if found == False:
				bb.note("%s contains dangling symlink to %s" % (pkg, l))
		d.setVar('RDEPENDS_' + pkg, bb.utils.join_deps(rdepends, commasep=False))
}


python package_qa_check_buildpaths () {
def package_qa_check_buildpaths(path, name, d, elf, messages):
    """
    Check for build paths inside target files and error if not found in the whitelist
    """
    # Ignore .debug files, not interesting
    if path.find(".debug") != -1:
        return

    # Ignore symlinks
    if os.path.islink(path):
        return

    tmpdir = d.getVar('TMPDIR', True)
    file_content = open(path).read()
    if tmpdir in file_content:
        messages.append("File %s in package contained reference to tmpdir" % package_qa_clean_path(path,d))
}


python package_qa_check_staged () {
def package_qa_check_staged(path,d):
    """
    Check staged la and pc files for sanity
      -e.g. installed being false

        As this is run after every stage we should be able
        to find the one responsible for the errors easily even
        if we look at every .pc and .la file
    """

    sane = True
    tmpdir = d.getVar('TMPDIR', True)
    workdir = os.path.join(tmpdir, "work")

    installed = "installed=yes"
    if bb.data.inherits_class("native", d) or bb.data.inherits_class("cross", d):
        pkgconfigcheck = workdir
    else:
        pkgconfigcheck = tmpdir

    # find all .la and .pc files
    # read the content
    # and check for stuff that looks wrong
    for root, dirs, files in os.walk(path):
        for file in files:
            path = os.path.join(root,file)
            if file.endswith(".la"):
                file_content = open(path).read()
                if workdir in file_content:
                    error_msg = "%s failed sanity test (workdir) in path %s" % (file,root)
                    sane = package_qa_handle_error("la", error_msg, d)
            elif file.endswith(".pc"):
                file_content = open(path).read()
                if pkgconfigcheck in file_content:
                    error_msg = "%s failed sanity test (tmpdir) in path %s" % (file,root)
                    sane = package_qa_handle_error("pkgconfig", error_msg, d)

    return sane
}


python base_do_unpack () {
	src_uri = (d.getVar('SRC_URI', True) or "").split()
	if len(src_uri) == 0:
		return

	localdata = bb.data.createCopy(d)
	bb.data.update_data(localdata)

	rootdir = localdata.getVar('WORKDIR', True)

        try:
            fetcher = bb.fetch2.Fetch(src_uri, localdata)
            fetcher.unpack(rootdir)
        except bb.fetch2.BBFetchException, e:
            raise bb.build.FuncFailed(e)
}


python do_populate_sysroot_setscene () {
	sstate_setscene(d)
}


python get_layers_branch_rev () {
def get_layers_branch_rev(d):
	layers = (d.getVar("BBLAYERS", True) or "").split()
	layers_branch_rev = ["%-17s = \"%s:%s\"" % (os.path.basename(i), \
		base_get_metadata_git_branch(i, None).strip(), \
		base_get_metadata_git_revision(i, None)) \
			for i in layers]
	i = len(layers_branch_rev)-1
	p1 = layers_branch_rev[i].find("=")
	s1 = layers_branch_rev[i][p1:]
	while i > 0:
		p2 = layers_branch_rev[i-1].find("=")
		s2= layers_branch_rev[i-1][p2:]
		if s1 == s2:
			layers_branch_rev[i-1] = layers_branch_rev[i-1][0:p2]
			i -= 1
		else:
			i -= 1
			p1 = layers_branch_rev[i].find("=")
			s1= layers_branch_rev[i][p1:]
	return layers_branch_rev

}


python base_get_scmbasepath () {
def base_get_scmbasepath(d):
	return d.getVar( 'COREBASE', True)
}


python sstate_cleanall () {
    import fnmatch

    bb.note("Removing shared state for package %s" % d.getVar('PN', True))

    manifest_dir = d.getVar('SSTATE_MANIFESTS', True)
    manifest_prefix = d.getVar("SSTATE_MANFILEPREFIX", True)
    manifest_pattern = os.path.basename(manifest_prefix) + ".*"

    if not os.path.exists(manifest_dir):
        return

    for manifest in (os.listdir(manifest_dir)):
        if fnmatch.fnmatch(manifest, manifest_pattern):
             name = manifest.replace(manifest_pattern[:-1], "")
             namemap = d.getVar('SSTATETASKNAMES', True).split()
             tasks = d.getVar('SSTATETASKS', True).split()
             if name not in namemap:
                  continue
             taskname = tasks[namemap.index(name)]
             shared_state = sstate_state_fromvars(d, taskname[3:])
             sstate_clean(shared_state, d)
}


python base_path_out () {
def base_path_out(path, d):
    return oe.path.format_display(path, d)
}


python check_sanity_version_change () {
def check_sanity_version_change(data):
    # Sanity checks to be done when SANITY_VERSION changes
    return ""
}


python package_do_pkgconfig () {
	import re

	packages = d.getVar('PACKAGES', True)
	workdir = d.getVar('WORKDIR', True)
	pkgdest = d.getVar('PKGDEST', True)

	shlibs_dir = d.getVar('SHLIBSDIR', True)
	shlibswork_dir = d.getVar('SHLIBSWORKDIR', True)

	pc_re = re.compile('(.*)\.pc$')
	var_re = re.compile('(.*)=(.*)')
	field_re = re.compile('(.*): (.*)')

	pkgconfig_provided = {}
	pkgconfig_needed = {}
	for pkg in packages.split():
		pkgconfig_provided[pkg] = []
		pkgconfig_needed[pkg] = []
		top = os.path.join(pkgdest, pkg)
		for root, dirs, files in os.walk(top):
			for file in files:
				m = pc_re.match(file)
				if m:
					pd = bb.data.init()
					name = m.group(1)
					pkgconfig_provided[pkg].append(name)
					path = os.path.join(root, file)
					if not os.access(path, os.R_OK):
						continue
					f = open(path, 'r')
					lines = f.readlines()
					f.close()
					for l in lines:
						m = var_re.match(l)
						if m:
							name = m.group(1)
							val = m.group(2)
							pd.setVar(name, pd.expand(val))
							continue
						m = field_re.match(l)
						if m:
							hdr = m.group(1)
							exp = bb.data.expand(m.group(2), pd)
							if hdr == 'Requires':
								pkgconfig_needed[pkg] += exp.replace(',', ' ').split()

	# Take shared lock since we're only reading, not writing
	lf = bb.utils.lockfile(d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/package-output.lock"))

	for pkg in packages.split():
		pkgs_file = os.path.join(shlibswork_dir, pkg + ".pclist")
		if pkgconfig_provided[pkg] != []:
			f = open(pkgs_file, 'w')
			for p in pkgconfig_provided[pkg]:
				f.write('%s\n' % p)
			f.close()

	for dir in [shlibs_dir]:
		if not os.path.exists(dir):
			continue
		for file in os.listdir(dir):
			m = re.match('^(.*)\.pclist$', file)
			if m:
				pkg = m.group(1)
				fd = open(os.path.join(dir, file))
				lines = fd.readlines()
				fd.close()
				pkgconfig_provided[pkg] = []
				for l in lines:
					pkgconfig_provided[pkg].append(l.rstrip())

	for pkg in packages.split():
		deps = []
		for n in pkgconfig_needed[pkg]:
			found = False
			for k in pkgconfig_provided.keys():
				if n in pkgconfig_provided[k]:
					if k != pkg and not (k in deps):
						deps.append(k)
					found = True
			if found == False:
				bb.note("couldn't find pkgconfig module '%s' in any package" % n)
		deps_file = os.path.join(pkgdest, pkg + ".pcdeps")
		if len(deps):
			fd = open(deps_file, 'w')
			for dep in deps:
				fd.write(dep + '\n')
			fd.close()

	bb.utils.unlockfile(lf)
}


python set_diskdata () {
def set_diskdata(var, dev, data):
    data.setVar(var, get_diskstats(dev))
}


python do_package_write_rpm () {
	bb.build.exec_func("read_subpackage_metadata", d)
	bb.build.exec_func("do_package_rpm", d)
}


python base_eventhandler () {
	from bb.event import getName

	name = getName(e)

	if name.startswith("BuildStarted"):
		e.data.setVar( 'BB_VERSION', bb.__version__)
		statusvars = ['BB_VERSION', 'TARGET_ARCH', 'TARGET_OS', 'MACHINE', 'DISTRO', 'DISTRO_VERSION','TUNE_FEATURES', 'TARGET_FPU']
		statuslines = ["%-17s = \"%s\"" % (i, e.data.getVar(i, True) or '') for i in statusvars]

		statuslines += get_layers_branch_rev(e.data)
		statusmsg = "\nOE Build Configuration:\n%s\n" % '\n'.join(statuslines)
		bb.plain(statusmsg)

		needed_vars = [ "TARGET_ARCH", "TARGET_OS" ]
		pesteruser = []
		for v in needed_vars:
			val = e.data.getVar(v, True)
			if not val or val == 'INVALID':
				pesteruser.append(v)
		if pesteruser:
			bb.fatal('The following variable(s) were not set: %s\nPlease set them directly, or choose a MACHINE or DISTRO that sets them.' % ', '.join(pesteruser))

        if name == "ConfigParsed":
                generate_git_config(e)
                pkgarch_mapping(e.data)
                preferred_ml_updates(e.data)
}


python sstate_init () {
def sstate_init(name, task, d):
    ss = {}
    ss['task'] = task
    ss['name'] = name
    ss['dirs'] = []
    ss['plaindirs'] = []
    ss['lockfiles'] = []
    ss['lockfiles-shared'] = []
    return ss
}


python get_bn () {
def get_bn(e):
    file = open(e.data.getVar('BNFILE', True))
    bn = file.readline()
    file.close()
    return bn
}


python check_app_exists () {
def check_app_exists(app, d):
	from bb import which, data

	app = data.expand(app, d)
	path = data.getVar('PATH', d, 1)
	return bool(which(path, app))
}


python base_path_relative () {
def base_path_relative(src, dest):
    return oe.path.relative(src, dest)
}


python base_conditional () {
def base_conditional(variable, checkvalue, truevalue, falsevalue, d):
    return oe.utils.conditional(variable, checkvalue, truevalue, falsevalue, d)
}


python package_qa_check_staticdev () {
def package_qa_check_staticdev(path, name, d, elf, messages):
    """
    Check for ".a" library in non-staticdev packages
    There are a number of exceptions to this rule, -pic packages can contain
    static libraries, the _nonshared.a belong with their -dev packages and
    libgcc.a, libgcov.a will be skipped in their packages
    """

    if not name.endswith("-pic") and not name.endswith("-staticdev") and path.endswith(".a") and not path.endswith("_nonshared.a"):
        messages.append("non -staticdev package contains static .a library: %s path '%s'" % \
                 (name, package_qa_clean_path(path,d)))
}


python sstate_clean_manifest () {
def sstate_clean_manifest(manifest, d):
    import oe.path

    mfile = open(manifest)
    entries = mfile.readlines()
    mfile.close()

    for entry in entries:
        entry = entry.strip()
        bb.debug(2, "Removing manifest: %s" % entry)
        # We can race against another package populating directories as we're removing them
        # so we ignore errors here.
        try:
            if entry.endswith("/"):
               if os.path.islink(entry[:-1]):
                  os.remove(entry[:-1])
               elif os.path.exists(entry) and len(os.listdir(entry)) == 0:
                  os.rmdir(entry[:-1])
            else:
                oe.path.remove(entry)
        except OSError:
            pass

    oe.path.remove(manifest)
}


python sstate_clean () {
def sstate_clean(ss, d):
    import oe.path

    manifest = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control/manifest-i586-bblayers.%s" % ss['name'])

    if os.path.exists(manifest):
        locks = []
        for lock in ss['lockfiles-shared']:
            locks.append(bb.utils.lockfile(lock))
        for lock in ss['lockfiles']:
            locks.append(bb.utils.lockfile(lock))

        sstate_clean_manifest(manifest, d)

        for lock in locks:
            bb.utils.unlockfile(lock)

    stfile = d.getVar("STAMP", True) + ".do_" + ss['task']
    extrainf = d.getVarFlag("do_" + ss['task'], 'stamp-extra-info', True)
    oe.path.remove(stfile)
    oe.path.remove(stfile + "_setscene")
    if extrainf:
        oe.path.remove(stfile + ".*" + extrainf)
        oe.path.remove(stfile + "_setscene" + ".*" + extrainf)
    else:
        oe.path.remove(stfile + ".*")
        oe.path.remove(stfile + "_setscene" + ".*")
}


python preferred_ml_updates () {
def preferred_ml_updates(d):
    # If any PREFERRED_PROVIDER or PREFERRED_VERSIONS are set,
    # we need to mirror these variables in the multilib case
    multilibs = d.getVar('MULTILIBS', True) or ""
    if not multilibs:
        return

    prefixes = []
    for ext in multilibs.split():
        eext = ext.split(':')
        if len(eext) > 1 and eext[0] == 'multilib':
            prefixes.append(eext[1])

    versions = []
    providers = []
    for v in d.keys():
        if v.startswith("PREFERRED_VERSION_"):
            versions.append(v)
        if v.startswith("PREFERRED_PROVIDER_"):
            providers.append(v)

    for v in versions:
        val = d.getVar(v, False)
        pkg = v.replace("PREFERRED_VERSION_", "")
        if pkg.endswith("-native") or pkg.endswith("-nativesdk"):
            continue
        for p in prefixes:
            newname = "PREFERRED_VERSION_" + p + "-" + pkg
            if not d.getVar(newname, False):
                d.setVar(newname, val)

    for prov in providers:
        val = d.getVar(prov, False)
        pkg = prov.replace("PREFERRED_PROVIDER_", "")
        if pkg.endswith("-native") or pkg.endswith("-nativesdk"):
            continue
        virt = ""
        if pkg.startswith("virtual/"):
             pkg = pkg.replace("virtual/", "")
             virt = "virtual/"
        for p in prefixes:
            newname = "PREFERRED_PROVIDER_" + virt + p + "-" + pkg
            if pkg != "kernel":
                val = p + "-" + val
            if not d.getVar(newname, False):
                d.setVar(newname, val)


    mp = (d.getVar("MULTI_PROVIDER_WHITELIST", True) or "").split()
    extramp = []
    for p in mp:
        if p.endswith("-native") or p.endswith("-nativesdk"):
            continue
        virt = ""
        if p.startswith("virtual/"):
            p = p.replace("virtual/", "")
            virt = "virtual/"
        for pref in prefixes:
            extramp.append(virt + pref + "-" + p)
    d.setVar("MULTI_PROVIDER_WHITELIST", " ".join(mp + extramp))

}


python base_path_join () {
def base_path_join(a, *p):
    return oe.path.join(a, *p)
}


python package_qa_check_useless_rpaths () {
def package_qa_check_useless_rpaths(file, name, d, elf, messages):
    """
    Check for RPATHs that are useless but not dangerous
    """
    if not elf:
        return

    objdump = d.getVar('OBJDUMP', True)
    env_path = d.getVar('PATH', True)

    libdir = d.getVar("libdir", True)
    base_libdir = d.getVar("base_libdir", True)

    import re
    rpath_re = re.compile("\s+RPATH\s+(.*)")
    for line in os.popen("LC_ALL=C PATH=%s %s -p '%s' 2> /dev/null" % (env_path, objdump, file), "r"):
    	m = rpath_re.match(line)
	if m:
	   rpath = m.group(1)
	   if rpath == libdir or rpath == base_libdir:
	      # The dynamic linker searches both these places anyway.  There is no point in
	      # looking there again.
	      messages.append("%s: %s contains probably-redundant RPATH %s" % (name, package_qa_clean_path(file, d), rpath))
}


python check_connectivity () {
def check_connectivity(d):
    # URI's to check can be set in the CONNECTIVITY_CHECK_URIS variable
    # using the same syntax as for SRC_URI. If the variable is not set
    # the check is skipped
    test_uris = (d.getVar('CONNECTIVITY_CHECK_URIS', True) or "").split()
    retval = ""

    # Only check connectivity if network enabled and the
    # CONNECTIVITY_CHECK_URIS are set
    network_enabled = not d.getVar('BB_NO_NETWORK', True)
    check_enabled = len(test_uris)
    # Take a copy of the data store and unset MIRRORS and PREMIRROS
    data = bb.data.createCopy(d)
    data.delVar('PREMIRRORS')
    data.delVar('MIRRORS')
    if check_enabled and network_enabled:
        try:
            fetcher = bb.fetch2.Fetch(test_uris, data)
            fetcher.checkstatus()
        except Exception:
            # Allow the message to be configured so that users can be
            # pointed to a support mechanism.
            msg = data.getVar('CONNECTIVITY_CHECK_MSG', True) or ""
            if len(msg) == 0:
                msg = "Failed to fetch test data from the network. Please ensure your network is configured correctly.\n"
            retval = msg

    return retval
}


python base_get_metadata_svn_revision () {
def base_get_metadata_svn_revision(path, d):
	revision = "<unknown>"
	try:
		revision = file( "%s/.svn/entries" % path ).readlines()[3].strip()
	except IOError:
		pass
	return revision
}


python sstate_install () {
def sstate_install(ss, d):
    import oe.path

    sharedfiles = []
    shareddirs = []
    bb.mkdirhier(d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control"))
    manifest = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control/manifest-i586-bblayers.%s" % ss['name'])

    if os.access(manifest, os.R_OK):
        bb.fatal("Package already staged (%s)?!" % manifest)

    locks = []
    for lock in ss['lockfiles-shared']:
        locks.append(bb.utils.lockfile(lock, True))
    for lock in ss['lockfiles']:
        locks.append(bb.utils.lockfile(lock))

    for state in ss['dirs']:
        oe.path.copytree(state[1], state[2])
        for walkroot, dirs, files in os.walk(state[1]):
            bb.debug(2, "Staging files from %s to %s" % (state[1], state[2]))
            for file in files:
                srcpath = os.path.join(walkroot, file)
                dstpath = srcpath.replace(state[1], state[2])
                #bb.debug(2, "Staging %s to %s" % (srcpath, dstpath))
                sharedfiles.append(dstpath)
            for dir in dirs:
                srcdir = os.path.join(walkroot, dir)
                dstdir = srcdir.replace(state[1], state[2])
                #bb.debug(2, "Staging %s to %s" % (srcdir, dstdir))
                if not dstdir.endswith("/"):
                    dstdir = dstdir + "/"
                shareddirs.append(dstdir)
    f = open(manifest, "w")
    for file in sharedfiles:
        f.write(file + "\n")
    # We want to ensure that directories appear at the end of the manifest
    # so that when we test to see if they should be deleted any contents
    # added by the task will have been removed first.
    dirs = sorted(shareddirs, key=len)
    # Must remove children first, which will have a longer path than the parent
    for di in reversed(dirs):
        f.write(di + "\n")
    f.close()

    for postinst in (d.getVar('SSTATEPOSTINSTFUNCS', True) or '').split():
        bb.build.exec_func(postinst, d)

    for lock in locks:
        bb.utils.unlockfile(lock)
}


python sstate_clean_cachefiles () {
def sstate_clean_cachefiles(d):
    for task in (d.getVar('SSTATETASKS', True) or "").split():
        ss = sstate_state_fromvars(d, task[3:])
        sstate_clean_cachefile(ss, d)
}


python package_do_shlibs () {
	import re, pipes

	exclude_shlibs = d.getVar('EXCLUDE_FROM_SHLIBS', 0)
	if exclude_shlibs:
		bb.note("not generating shlibs")
		return

	lib_re = re.compile("^.*\.so")
	libdir_re = re.compile(".*/lib$")

	packages = d.getVar('PACKAGES', True)
	targetos = d.getVar('TARGET_OS', True)

	workdir = d.getVar('WORKDIR', True)

	ver = d.getVar('PKGV', True)
	if not ver:
		bb.error("PKGV not defined")
		return

	pkgdest = d.getVar('PKGDEST', True)

	shlibs_dir = d.getVar('SHLIBSDIR', True)
	shlibswork_dir = d.getVar('SHLIBSWORKDIR', True)

	# Take shared lock since we're only reading, not writing
	lf = bb.utils.lockfile(d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/package-output.lock"))

	def linux_so(root, path, file):
		cmd = d.getVar('OBJDUMP', True) + " -p " + pipes.quote(os.path.join(root, file)) + " 2>/dev/null"
		cmd = "PATH=\"%s\" %s" % (d.getVar('PATH', True), cmd)
		fd = os.popen(cmd)
		lines = fd.readlines()
		fd.close()
		for l in lines:
			m = re.match("\s+NEEDED\s+([^\s]*)", l)
			if m:
				needed[pkg].append(m.group(1))
			m = re.match("\s+SONAME\s+([^\s]*)", l)
			if m:
				this_soname = m.group(1)
				if not this_soname in sonames:
					# if library is private (only used by package) then do not build shlib for it
					if not private_libs or -1 == private_libs.find(this_soname):
						sonames.append(this_soname)
				if libdir_re.match(root):
					needs_ldconfig = True
				if snap_symlinks and (file != this_soname):
					renames.append((os.path.join(root, file), os.path.join(root, this_soname)))

	def darwin_so(root, path, file):
		fullpath = os.path.join(root, file)
		if not os.path.exists(fullpath):
			return

		def get_combinations(base):
			#
			# Given a base library name, find all combinations of this split by "." and "-"
			#
			combos = []
			options = base.split(".")
			for i in range(1, len(options) + 1):
				combos.append(".".join(options[0:i]))
			options = base.split("-")
			for i in range(1, len(options) + 1):
				combos.append("-".join(options[0:i]))
			return combos

		if (file.endswith('.dylib') or file.endswith('.so')) and not pkg.endswith('-dev') and not pkg.endswith('-dbg'):
			# Drop suffix
			name = file.rsplit(".",1)[0]
			# Find all combinations
			combos = get_combinations(name)
			for combo in combos:
				if not combo in sonames:
					sonames.append(combo)
		if file.endswith('.dylib') or file.endswith('.so'):
			lafile = fullpath.replace(os.path.join(pkgdest, pkg), d.getVar('PKGD', True))
			# Drop suffix
			lafile = lafile.rsplit(".",1)[0]
			lapath = os.path.dirname(lafile)
			lafile = os.path.basename(lafile)
			# Find all combinations
			combos = get_combinations(lafile)
			for combo in combos:
				if os.path.exists(lapath + '/' + combo + '.la'):
					break
			lafile = lapath + '/' + combo + '.la'

			#bb.note("Foo2: %s" % lafile)
			#bb.note("Foo %s %s" % (file, fullpath))
			if os.path.exists(lafile):
				fd = open(lafile, 'r')
				lines = fd.readlines()
				fd.close()
				for l in lines:
					m = re.match("\s*dependency_libs=\s*'(.*)'", l)
					if m:
						deps = m.group(1).split(" ")
						for dep in deps:
							#bb.note("Trying %s for %s" % (dep, pkg))
							name = None
							if dep.endswith(".la"):
								name = os.path.basename(dep).replace(".la", "")
							elif dep.startswith("-l"):
								name = dep.replace("-l", "lib")
							if pkg not in needed:
								needed[pkg] = []
							if name:
								needed[pkg].append(name)
								#bb.note("Adding %s for %s" % (name, pkg))

	if d.getVar('PACKAGE_SNAP_LIB_SYMLINKS', True) == "1":
		snap_symlinks = True
	else:
		snap_symlinks = False

	if (d.getVar('USE_LDCONFIG', True) or "1") == "1":
		use_ldconfig = True
	else:
		use_ldconfig = False

	needed = {}
	shlib_provider = {}
	for pkg in packages.split():
		private_libs = d.getVar('PRIVATE_LIBS_' + pkg, True) or d.getVar('PRIVATE_LIBS', True)
		needs_ldconfig = False
		bb.debug(2, "calculating shlib provides for %s" % pkg)

		pkgver = d.getVar('PKGV_' + pkg, True)
		if not pkgver:
			pkgver = d.getVar('PV_' + pkg, True)
		if not pkgver:
			pkgver = ver

		needed[pkg] = []
		sonames = list()
		renames = list()
		top = os.path.join(pkgdest, pkg)
		for root, dirs, files in os.walk(top):
			for file in files:
				soname = None
				path = os.path.join(root, file)
				if os.path.islink(path):
					continue
				if targetos == "darwin" or targetos == "darwin8":
					darwin_so(root, dirs, file)
				elif os.access(path, os.X_OK) or lib_re.match(file):
					linux_so(root, dirs, file)
		for (old, new) in renames:
		    	bb.note("Renaming %s to %s" % (old, new))
			os.rename(old, new)
		shlibs_file = os.path.join(shlibswork_dir, pkg + ".list")
		shver_file = os.path.join(shlibswork_dir, pkg + ".ver")
		if len(sonames):
			fd = open(shlibs_file, 'w')
			for s in sonames:
				fd.write(s + '\n')
				shlib_provider[s] = (pkg, pkgver)
			fd.close()
			fd = open(shver_file, 'w')
			fd.write(pkgver + '\n')
			fd.close()
		if needs_ldconfig and use_ldconfig:
			bb.debug(1, 'adding ldconfig call to postinst for %s' % pkg)
			postinst = d.getVar('pkg_postinst_%s' % pkg, True) or d.getVar('pkg_postinst', True)
			if not postinst:
				postinst = '#!/bin/sh\n'
			postinst += d.getVar('ldconfig_postinst_fragment', True)
			d.setVar('pkg_postinst_%s' % pkg, postinst)

	list_re = re.compile('^(.*)\.list$')
	for dir in [shlibs_dir]:
		if not os.path.exists(dir):
			continue
		for file in os.listdir(dir):
			m = list_re.match(file)
			if m:
				dep_pkg = m.group(1)
				fd = open(os.path.join(dir, file))
				lines = fd.readlines()
				fd.close()
				ver_file = os.path.join(dir, dep_pkg + '.ver')
				lib_ver = None
				if os.path.exists(ver_file):
					fd = open(ver_file)
					lib_ver = fd.readline().rstrip()
					fd.close()
				for l in lines:
					shlib_provider[l.rstrip()] = (dep_pkg, lib_ver)

	bb.utils.unlockfile(lf)

	assumed_libs = d.getVar('ASSUME_SHLIBS', True)
	if assumed_libs:
	    for e in assumed_libs.split():
		l, dep_pkg = e.split(":")
		lib_ver = None
		dep_pkg = dep_pkg.rsplit("_", 1)
		if len(dep_pkg) == 2:
		    lib_ver = dep_pkg[1]
		dep_pkg = dep_pkg[0]
		shlib_provider[l] = (dep_pkg, lib_ver)

	for pkg in packages.split():
		bb.debug(2, "calculating shlib requirements for %s" % pkg)

		deps = list()
		for n in needed[pkg]:
			if n in shlib_provider.keys():
				(dep_pkg, ver_needed) = shlib_provider[n]

				if dep_pkg == pkg:
					continue

				if ver_needed:
					dep = "%s (>= %s)" % (dep_pkg, ver_needed)
				else:
					dep = dep_pkg
				if not dep in deps:
					deps.append(dep)
			else:
				bb.note("Couldn't find shared library provider for %s" % n)

		deps_file = os.path.join(pkgdest, pkg + ".shlibdeps")
		if os.path.exists(deps_file):
			os.remove(deps_file)
		if len(deps):
			fd = open(deps_file, 'w')
			for dep in deps:
				fd.write(dep + '\n')
			fd.close()
}


python package_qa_check_dbg () {
def package_qa_check_dbg(path, name, d, elf, messages):
    """
    Check for ".debug" files or directories outside of the dbg package
    """

    if not "-dbg" in name:
        if '.debug' in path.split(os.path.sep):
            messages.append("non debug package contains .debug directory: %s path %s" % \
                     (name, package_qa_clean_path(path,d)))
}


python package_do_filedeps () {
	import re

	pkgdest = d.getVar('PKGDEST', True)
	packages = d.getVar('PACKAGES', True)

	rpmdeps = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/bin/rpmdeps-oecore --macros /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/macros --define '_rpmfc_magic_path /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/share/misc/magic.mgc' --rpmpopt /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/lib/rpm/rpmpopt")
	r = re.compile(r'[<>=]+ +[^ ]*')

	# Quick routine to process the results of the rpmdeps call...
	def process_deps(pipe, pkg, provides_files, requires_files):
		provides = {}
		requires = {}

		for line in pipe:
			f = line.split(" ", 1)[0].strip()
			line = line.split(" ", 1)[1].strip()

			if line.startswith("Requires:"):
				i = requires
			elif line.startswith("Provides:"):
				i = provides
			else:
				continue

			file = f.replace(pkgdest + "/" + pkg, "")
			file = file.replace("@", "@at@")
			file = file.replace(" ", "@space@")
			file = file.replace("\t", "@tab@")
			file = file.replace("[", "@openbrace@")
			file = file.replace("]", "@closebrace@")
			file = file.replace("_", "@underscore@")
			value = line.split(":", 1)[1].strip()
			value = r.sub(r'(\g<0>)', value)

			if value.startswith("rpmlib("):
				continue
			if value == "python":
				continue
			if file not in i:
				i[file] = []
			i[file].append(value)

		for file in provides:
			provides_files.append(file)
			key = "FILERPROVIDES_" + file + "_" + pkg
			d.setVar(key, " ".join(provides[file]))

		for file in requires:
			requires_files.append(file)
			key = "FILERDEPENDS_" + file + "_" + pkg
			d.setVar(key, " ".join(requires[file]))

	def chunks(files, n):
		return [files[i:i+n] for i in range(0, len(files), n)]

	# Determine dependencies
	for pkg in packages.split():
		if pkg.endswith('-dbg') or pkg.endswith('-doc') or pkg.find('-locale-') != -1 or pkg.find('-localedata-') != -1 or pkg.find('-gconv-') != -1 or pkg.find('-charmap-') != -1 or pkg.startswith('kernel-module-'):
			continue

		provides_files = []
		requires_files = []
		rpfiles = []
		for root, dirs, files in os.walk(pkgdest + "/" + pkg):
			for file in files:
				rpfiles.append(os.path.join(root, file))

		for files in chunks(rpfiles, 100):
			dep_pipe = os.popen(rpmdeps + " " + " ".join(files))

			process_deps(dep_pipe, pkg, provides_files, requires_files)

		d.setVar("FILERDEPENDSFLIST_" + pkg, " ".join(requires_files))
		d.setVar("FILERPROVIDESFLIST_" + pkg, " ".join(provides_files))
}


python base_detect_revision () {
def base_detect_revision(d):
	path = base_get_scmbasepath(d)

	scms = [base_get_metadata_git_revision, \
			base_get_metadata_svn_revision]

	for scm in scms:
		rev = scm(path, d)
		if rev <> "<unknown>":
			return rev

	return "<unknown>"
}


python sstate_installpkg () {
def sstate_installpkg(ss, d):
    import oe.path

    def prepdir(dir):
        # remove dir if it exists, ensure any parent directories do exist
        if os.path.exists(dir):
            oe.path.remove(dir)
        bb.mkdirhier(dir)
        oe.path.remove(dir)

    sstateinst = d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/sstate-install-%s/" % ss['name'])
    sstatepkg = d.getVar('SSTATE_PKG', True) + '_' + ss['name'] + ".tgz"

    if not os.path.exists(sstatepkg):
       pstaging_fetch(sstatepkg, d)

    if not os.path.isfile(sstatepkg):
        bb.note("Staging package %s does not exist" % sstatepkg)
        return False

    sstate_clean(ss, d)

    d.setVar('SSTATE_INSTDIR', sstateinst)
    d.setVar('SSTATE_PKG', sstatepkg)

    for preinst in (d.getVar('SSTATEPREINSTFUNCS', True) or '').split():
        bb.build.exec_func(preinst, d)

    bb.build.exec_func('sstate_unpack_package', d)

    # Fixup hardcoded paths
    fixmefn =  sstateinst + "fixmepath"
    if os.path.isfile(fixmefn):
        staging = d.getVar('STAGING_DIR', True)
        staging_target = d.getVar('STAGING_DIR_TARGET', True)
        staging_host = d.getVar('STAGING_DIR_HOST', True)
        fixmefd = open(fixmefn, "r")
        fixmefiles = fixmefd.readlines()
        fixmefd.close()
        for file in fixmefiles:
            os.system("sed -i -e s:FIXMESTAGINGDIRTARGET:%s:g %s" % (staging_target, sstateinst + file))
            os.system("sed -i -e s:FIXMESTAGINGDIRHOST:%s:g %s" % (staging_host, sstateinst + file))
            os.system("sed -i -e s:FIXMESTAGINGDIR:%s:g %s" % (staging, sstateinst + file))
        # Need to remove this or we'd copy it into the target directory and may
        # conflict with another writer
        os.remove(fixmefn)

    for state in ss['dirs']:
        prepdir(state[1])
        os.rename(sstateinst + state[0], state[1])
    sstate_install(ss, d)

    for plain in ss['plaindirs']:
        workdir = d.getVar('WORKDIR', True)
        src = sstateinst + "/" + plain.replace(workdir, '')
        dest = plain
        bb.mkdirhier(src)
        prepdir(dest)
        os.rename(src, dest)

    return True
}


python get_process_cputime () {
def get_process_cputime(pid):
    fields = open("/proc/%d/stat" % pid, "r").readline().rstrip().split()
    # 13: utime, 14: stime, 15: cutime, 16: cstime
    return sum(int(field) for field in fields[13:16])
}


python base_get_metadata_git_revision () {
def base_get_metadata_git_revision(path, d):
	f = os.popen("cd %s; git log -n 1 --pretty=oneline -- 2>&1" % path)
	data = f.read()
	if f.close() is None:
		rev = data.split(" ")[0]
		if len(rev) != 0:
			return rev
	return "<unknown>"
}


python raise_sanity_error () {
def raise_sanity_error(msg):
    bb.fatal(""" OE-core's config sanity checker detected a potential misconfiguration.
    Either fix the cause of this error or at your own risk disable the checker (see sanity.conf).
    Following is the list of potential problems / advisories:

    %s""" % msg)
}


python base_read_file () {
def base_read_file(filename):
    return oe.utils.read_file(filename)
}


python package_do_split_locales () {
	if (d.getVar('PACKAGE_NO_LOCALE', True) == '1'):
		bb.debug(1, "package requested not splitting locales")
		return

	packages = (d.getVar('PACKAGES', True) or "").split()

	datadir = d.getVar('datadir', True)
	if not datadir:
		bb.note("datadir not defined")
		return

	dvar = d.getVar('PKGD', True)
	pn = d.getVar('PN', True)

	if pn + '-locale' in packages:
		packages.remove(pn + '-locale')

	localedir = os.path.join(dvar + datadir, 'locale')

	if not os.path.isdir(localedir):
		bb.debug(1, "No locale files in this package")
		return

	locales = os.listdir(localedir)

	# This is *really* broken
	mainpkg = packages[0]
	# At least try and patch it up I guess...
	if mainpkg.find('-dbg'):
		mainpkg = mainpkg.replace('-dbg', '')
	if mainpkg.find('-dev'):
		mainpkg = mainpkg.replace('-dev', '')

	summary = d.getVar('SUMMARY', True) or pn
	description = d.getVar('DESCRIPTION', True) or ""
        locale_section = d.getVar('LOCALE_SECTION', True)
	for l in sorted(locales):
		ln = legitimize_package_name(l)
		pkg = pn + '-locale-' + ln
		packages.append(pkg)
		d.setVar('FILES_' + pkg, os.path.join(datadir, 'locale', l))
		d.setVar('RDEPENDS_' + pkg, '%s virtual-locale-%s' % (mainpkg, ln))
		d.setVar('RPROVIDES_' + pkg, '%s-locale %s-translation' % (pn, ln))
		d.setVar('SUMMARY_' + pkg, '%s - %s translations' % (summary, l))
		d.setVar('DESCRIPTION_' + pkg, '%s  This package contains language translation files for the %s locale.' % (description, l))
		if locale_section:
			d.setVar('SECTION_' + pkg, locale_section)

	d.setVar('PACKAGES', ' '.join(packages))

	# Disabled by RP 18/06/07
	# Wildcards aren't supported in debian
	# They break with ipkg since glibc-locale* will mean that
	# glibc-localedata-translit* won't install as a dependency
	# for some other package which breaks meta-toolchain
	# Probably breaks since virtual-locale- isn't provided anywhere
	#rdep = (d.getVar('RDEPENDS_%s' % mainpkg, True) or d.getVar('RDEPENDS', True) or "").split()
	#rdep.append('%s-locale*' % pn)
	#d.setVar('RDEPENDS_%s' % mainpkg, ' '.join(rdep))
}


python base_both_contain () {
def base_both_contain(variable1, variable2, checkvalue, d):
    return oe.utils.both_contain(variable1, variable2, checkvalue, d)
}


python debian_package_name_hook () {
	import glob, copy, stat, errno, re

	pkgdest = d.getVar('PKGDEST', True)
	packages = d.getVar('PACKAGES', True)
	bin_re = re.compile(".*/s?" + os.path.basename(d.getVar("bindir", True)) + "$")
	lib_re = re.compile(".*/" + os.path.basename(d.getVar("libdir", True)) + "$")
	so_re = re.compile("lib.*\.so")

	def socrunch(s):
		s = s.lower().replace('_', '-')
		m = re.match("^(.*)(.)\.so\.(.*)$", s)
		if m is None:
			return None
		if m.group(2) in '0123456789':
			bin = '%s%s-%s' % (m.group(1), m.group(2), m.group(3))
		else:
			bin = m.group(1) + m.group(2) + m.group(3)
		dev = m.group(1) + m.group(2)
		return (bin, dev)

	def isexec(path):
		try:
			s = os.stat(path)
		except (os.error, AttributeError):
			return 0
		return (s[stat.ST_MODE] & stat.S_IEXEC)

	def auto_libname(packages, orig_pkg):
		sonames = []
		has_bins = 0
		has_libs = 0
		pkg_dir = os.path.join(pkgdest, orig_pkg)
		for root, dirs, files in os.walk(pkg_dir):
			if bin_re.match(root) and files:
				has_bins = 1
			if lib_re.match(root) and files:
				has_libs = 1
				for f in files:
					if so_re.match(f):
						fp = os.path.join(root, f)
						cmd = (d.getVar('BUILD_PREFIX', True) or "") + "objdump -p " + fp + " 2>/dev/null"
						fd = os.popen(cmd)
						lines = fd.readlines()
						fd.close()
						for l in lines:
							m = re.match("\s+SONAME\s+([^\s]*)", l)
							if m and not m.group(1) in sonames:
								sonames.append(m.group(1))

		bb.debug(1, 'LIBNAMES: pkg %s libs %d bins %d sonames %s' % (orig_pkg, has_libs, has_bins, sonames))
		soname = None
		if len(sonames) == 1:
			soname = sonames[0]
		elif len(sonames) > 1:
			lead = d.getVar('LEAD_SONAME', True)
			if lead:
				r = re.compile(lead)
				filtered = []
				for s in sonames:
					if r.match(s):
						filtered.append(s)
				if len(filtered) == 1:
					soname = filtered[0]
				elif len(filtered) > 1:
					bb.note("Multiple matches (%s) for LEAD_SONAME '%s'" % (", ".join(filtered), lead))
				else:
					bb.note("Multiple libraries (%s) found, but LEAD_SONAME '%s' doesn't match any of them" % (", ".join(sonames), lead))
			else:
				bb.note("Multiple libraries (%s) found and LEAD_SONAME not defined" % ", ".join(sonames))

		if has_libs and not has_bins and soname:
			soname_result = socrunch(soname)
			if soname_result:
				(pkgname, devname) = soname_result
				for pkg in packages.split():
					if (d.getVar('PKG_' + pkg) or d.getVar('DEBIAN_NOAUTONAME_' + pkg)):
						continue
					debian_pn = d.getVar('DEBIANNAME_' + pkg)
					if debian_pn:
						newpkg = debian_pn
					elif pkg == orig_pkg:
						newpkg = pkgname
					else:
						newpkg = pkg.replace(orig_pkg, devname, 1)
					mlpre=d.getVar('MLPREFIX', True)
					if mlpre:
						if not newpkg.find(mlpre) == 0:
							newpkg = mlpre + newpkg
					if newpkg != pkg:
						d.setVar('PKG_' + pkg, newpkg)

	# reversed sort is needed when some package is substring of another
	# ie in ncurses we get without reverse sort:
	# DEBUG: LIBNAMES: pkgname libtic5 devname libtic pkg ncurses-libtic orig_pkg ncurses-libtic debian_pn None newpkg libtic5
	# and later
	# DEBUG: LIBNAMES: pkgname libtic5 devname libtic pkg ncurses-libticw orig_pkg ncurses-libtic debian_pn None newpkg libticw
	# so we need to handle ncurses-libticw->libticw5 before ncurses-libtic->libtic5
	for pkg in sorted((d.getVar('AUTO_LIBNAME_PKGS', True) or "").split(), reverse=True):
		auto_libname(packages, pkg)
}


python package_rpm_install () {
	bb.fatal("package_rpm_install not implemented!")
}


python oe_filter () {
def oe_filter(f, str, d):
    return oe.utils.str_filter(f, str, d)
}


python check_pseudo_wrapper () {
def check_pseudo_wrapper():
    import sys
    if not sys.argv[0].endswith('/bitbake'):
        return ""

    import subprocess as sub
    # Check if bitbake wrapper is being used
    pseudo_build = os.environ.get( 'PSEUDO_BUILD' )
    if not pseudo_build:
        bb.warn("Bitbake has not been run using the bitbake wrapper (scripts/bitbake); this is likely because your PATH has been altered from that normally set up by the oe-init-build-env script. Not using the wrapper may result in failures during package installation, so it is highly recommended that you set your PATH back so that the wrapper script is being executed.")

    if (not pseudo_build) or pseudo_build == '2':
        # pseudo ought to be working, let's see if it is...
        p = sub.Popen(['sh', '-c', 'PSEUDO_DISABLED=0 id -u'],stdout=sub.PIPE,stderr=sub.PIPE)
        out, err = p.communicate()
        if out.rstrip() != '0':
            msg = "Pseudo is not functioning correctly, which will cause failures during package installation. Please check your configuration."
            if pseudo_build == '2':
                return msg
            else:
                bb.warn(msg)
    return ""
}


python do_qa_staging () {
    bb.note("QA checking staging")

    if not package_qa_check_staged(d.expand('/media/OE/poky/meta-ettus/recipes/hello/build/tmp/work/i586-poky-linux/bblayers-1.0-r0/sysroot-destdir///media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/lib'), d):
        bb.fatal("QA staging was broken by the package built above")
}


python sstate_add () {
def sstate_add(ss, source, dest, d):
    srcbase = os.path.basename(source)
    ss['dirs'].append([srcbase, source, dest])
    return ss
}


python do_qa_configure () {
    configs = []
    workdir = d.getVar('WORKDIR', True)
    bb.note("Checking autotools environment for common misconfiguration")
    for root, dirs, files in os.walk(workdir):
        statement = "grep -e 'CROSS COMPILE Badness:' -e 'is unsafe for cross-compilation' %s > /dev/null" % \
                    os.path.join(root,"config.log")
        if "config.log" in files:
            if os.system(statement) == 0:
                bb.fatal("""This autoconf log indicates errors, it looked at host include and/or library paths while determining system capabilities.
Rerun configure task after fixing this. The path was '%s'""" % root)

        if "configure.ac" in files:
            configs.append(os.path.join(root,"configure.ac"))
        if "configure.in" in files:
            configs.append(os.path.join(root, "configure.in"))

    cnf = d.getVar('EXTRA_OECONF', True) or ""
    if "gettext" not in d.getVar('P', True) and "gcc-runtime" not in d.getVar('P', True) and "--disable-nls" not in cnf:
       ml = d.getVar("MLPREFIX", True) or ""
       if bb.data.inherits_class('native', d) or bb.data.inherits_class('cross', d) or bb.data.inherits_class('crosssdk', d) or bb.data.inherits_class('nativesdk', d):
          gt = "gettext-native"
       elif bb.data.inherits_class('cross-canadian', d):
          gt = "gettext-nativesdk"
       else:
          gt = "virtual/" + ml + "gettext"
       deps = bb.utils.explode_deps(d.getVar('DEPENDS', True) or "")
       if gt not in deps:
          for config in configs:
              gnu = "grep \"^[[:space:]]*AM_GNU_GETTEXT\" %s >/dev/null" % config
              if os.system(gnu) == 0:
                 bb.fatal("""%s required but not in DEPENDS for file %s.
Missing inherit gettext?""" % (gt, config))

    if not package_qa_check_license(workdir, d):
        bb.fatal("Licensing Error: LIC_FILES_CHKSUM does not match, please fix")
}


python prserv_get_pr_auto () {
def prserv_get_pr_auto(d):
    import oe.prservice
    if d.getVar('USE_PR_SERV', True) != "1":
        bb.warn("Not using network based PR service")
        return None

    version = d.getVar("PRAUTOINX", True)
    pkgarch = d.getVar("PACKAGE_ARCH", True)
    checksum = d.getVar("BB_TASKHASH", True)

    if d.getVar('PRSERV_LOCKDOWN', True):
        auto_rev = d.getVar('PRAUTO_' + version + '_' + pkgarch, True) or d.getVar('PRAUTO_' + version, True) or None
    else:
        conn = d.getVar("__PRSERV_CONN", True)
        if conn is None:
            conn = oe.prservice.prserv_make_conn(d)
            if conn is None:
                return None
        auto_rev = conn.getPR(version, pkgarch, checksum)

    return auto_rev}


python base_set_filespath () {
def base_set_filespath(path, d):
	filespath = []
	extrapaths = (d.getVar("FILESEXTRAPATHS", True) or "")
	# Don't prepend empty strings to the path list
	if extrapaths != "":
		path = extrapaths.split(":") + path
	# The ":" ensures we have an 'empty' override
	overrides = (d.getVar("OVERRIDES", True) or "") + ":"
	for p in path:
		if p != "":
			for o in overrides.split(":"):
				filespath.append(os.path.join(p, o))
	return ":".join(filespath)
}


python mapping_rename_hook () {
	bb.build.exec_func('package_rpm_mapping_rename_hook', d)
}


python check_supported_distro () {
def check_supported_distro(e):
    tested_distros = e.data.getVar('SANITY_TESTED_DISTROS', True)
    if not tested_distros:
        return

    if os.path.exists("/etc/redhat-release"):
        f = open("/etc/redhat-release", "r")
        try:
            distro = f.readline()
        finally:
            f.close()
    elif os.path.exists("/etc/SuSE-release"):
        f = open("/etc/SuSE-release", "r")
        try:
            distro = f.readline()
            # Remove the architecture suffix e.g. (i586)
            distro = re.sub(r' \([a-zA-Z0-9\-_]*\)$', '', distro).strip()
        finally:
            f.close()
    else:
        # Use LSB method
        import subprocess as sub
        try:
            p = sub.Popen(['lsb_release','-d','-s'],stdout=sub.PIPE,stderr=sub.PIPE)
            out, err = p.communicate()
            distro = out.rstrip()
        except Exception:
            distro = None

        if not distro:
            if os.path.exists("/etc/lsb-release"):
                f = open("/etc/lsb-release", "r")
                try:
                    for line in f:
                        lns = line.split('=')
                        if lns[0] == "DISTRIB_DESCRIPTION":
                            distro = lns[1].strip('"\n')
                            break
                finally:
                    f.close()
    if distro:
        if distro not in [x.strip() for x in tested_distros.split('\\n')]:
            bb.warn('Host distribution "%s" has not been validated with this version of the build system; you may possibly experience unexpected failures. It is recommended that you use a tested distribution.' % distro)
    else:
        bb.warn('Host distribution could not be determined; you may possibly experience unexpected failures. It is recommended that you use a tested distribution.')
}


python emit_pkgdata () {
	from glob import glob

	def write_if_exists(f, pkg, var):
		def encode(str):
			import codecs
			c = codecs.getencoder("string_escape")
			return c(str)[0]

		val = d.getVar('%s_%s' % (var, pkg), True)
		if val:
			f.write('%s_%s: %s\n' % (var, pkg, encode(val)))
			return
		val = d.getVar('%s' % (var), True)
		if val:
			f.write('%s: %s\n' % (var, encode(val)))
		return

	def get_directory_size(dir):
		if os.listdir(dir):
			size = int(os.popen('du -sk %s' % dir).readlines()[0].split('\t')[0])
		else:
			size = 0
		return size

	packages = d.getVar('PACKAGES', True)
	pkgdest = d.getVar('PKGDEST', True)
	pkgdatadir = d.getVar('PKGDESTWORK', True)

	# Take shared lock since we're only reading, not writing
	lf = bb.utils.lockfile(d.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/package-output.lock"), True)

	data_file = pkgdatadir + d.expand("/bblayers" )
	f = open(data_file, 'w')
	f.write("PACKAGES: %s\n" % packages)
	f.close()

	workdir = d.getVar('WORKDIR', True)

	for pkg in packages.split():
		subdata_file = pkgdatadir + "/runtime/%s" % pkg

		sf = open(subdata_file, 'w')
		write_if_exists(sf, pkg, 'PN')
		write_if_exists(sf, pkg, 'PV')
		write_if_exists(sf, pkg, 'PR')
		write_if_exists(sf, pkg, 'PKGV')
		write_if_exists(sf, pkg, 'PKGR')
		write_if_exists(sf, pkg, 'LICENSE')
		write_if_exists(sf, pkg, 'DESCRIPTION')
		write_if_exists(sf, pkg, 'SUMMARY')
		write_if_exists(sf, pkg, 'RDEPENDS')
		write_if_exists(sf, pkg, 'RPROVIDES')
		write_if_exists(sf, pkg, 'RRECOMMENDS')
		write_if_exists(sf, pkg, 'RSUGGESTS')
		write_if_exists(sf, pkg, 'RREPLACES')
		write_if_exists(sf, pkg, 'RCONFLICTS')
		write_if_exists(sf, pkg, 'SECTION')
		write_if_exists(sf, pkg, 'PKG')
		write_if_exists(sf, pkg, 'ALLOW_EMPTY')
		write_if_exists(sf, pkg, 'FILES')
		write_if_exists(sf, pkg, 'pkg_postinst')
		write_if_exists(sf, pkg, 'pkg_postrm')
		write_if_exists(sf, pkg, 'pkg_preinst')
		write_if_exists(sf, pkg, 'pkg_prerm')
		write_if_exists(sf, pkg, 'FILERPROVIDESFLIST')
		for dfile in (d.getVar('FILERPROVIDESFLIST_' + pkg, True) or "").split():
			write_if_exists(sf, pkg, 'FILERPROVIDES_' + dfile)

		write_if_exists(sf, pkg, 'FILERDEPENDSFLIST')
		for dfile in (d.getVar('FILERDEPENDSFLIST_' + pkg, True) or "").split():
			write_if_exists(sf, pkg, 'FILERDEPENDS_' + dfile)

		sf.write('%s_%s: %s\n' % ('PKGSIZE', pkg, get_directory_size(pkgdest + "/%s" % pkg)))
		sf.close()


		allow_empty = d.getVar('ALLOW_EMPTY_%s' % pkg, True)
		if not allow_empty:
			allow_empty = d.getVar('ALLOW_EMPTY', True)
		root = "%s/%s" % (pkgdest, pkg)
		os.chdir(root)
		g = glob('*')
		if g or allow_empty == "1":
			packagedfile = pkgdatadir + '/runtime/%s.packaged' % pkg
			file(packagedfile, 'w').close()

	bb.utils.unlockfile(lf)
}


python do_patch () {
	bb.build.exec_func('base_do_patch', d)
}


python base_less_or_equal () {
def base_less_or_equal(variable, checkvalue, truevalue, falsevalue, d):
    return oe.utils.less_or_equal(variable, checkvalue, truevalue, falsevalue, d)
}


python check_sanity () {
def check_sanity(e):
    from bb import note, error, data, __version__

    try:
        from distutils.version import LooseVersion
    except ImportError:
        def LooseVersion(v): print "WARNING: sanity.bbclass can't compare versions without python-distutils"; return 1
    import commands

    # Check the bitbake version meets minimum requirements
    minversion = data.getVar('BB_MIN_VERSION', e.data , True)
    if not minversion:
        # Hack: BB_MIN_VERSION hasn't been parsed yet so return
        # and wait for the next call
        print "Foo %s" % minversion
        return

    if 0 == os.getuid():
        raise_sanity_error("Do not use Bitbake as root.")

    messages = ""

    # Check the Python version, we now use Python 2.6 features in
    # various classes
    import sys
    if sys.hexversion < 0x020600F0:
        messages = messages + 'The system requires at least Python 2.6 to run. Please update your Python interpreter.\n'

    if (LooseVersion(__version__) < LooseVersion(minversion)):
        messages = messages + 'Bitbake version %s is required and version %s was found\n' % (minversion, __version__)

    # Check that the MACHINE is valid, if it is set
    if data.getVar('MACHINE', e.data, True):
        if not check_conf_exists("conf/machine/qemux86.conf", e.data):
            messages = messages + 'Please set a valid MACHINE in your local.conf or environment\n'
        else:
            messages = messages + check_sanity_validmachine(e)
    else:
        messages = messages + 'Please set a MACHINE in your local.conf or environment\n'

    # Check we are using a valid lacal.conf
    current_conf  = data.getVar('CONF_VERSION', e.data, True)
    conf_version =  data.getVar('LOCALCONF_VERSION', e.data, True)

    if current_conf != conf_version:
        messages = messages + "Your version of local.conf was generated from an older version of local.conf.sample and there have been updates made to this file. Please compare the two files and merge any changes before continuing.\nMatching the version numbers will remove this message.\n\"meld conf/local.conf conf/local.conf.sample\" is a good way to visualise the changes.\n"

    # Check bblayers.conf is valid
    current_lconf = data.getVar('LCONF_VERSION', e.data, True)
    lconf_version = data.getVar('LAYER_CONF_VERSION', e.data, True)
    if current_lconf != lconf_version:
        messages = messages + "Your version of bblayers.conf was generated from an older version of bblayers.conf.sample and there have been updates made to this file. Please compare the two files and merge any changes before continuing.\nMatching the version numbers will remove this message.\n\"meld conf/bblayers.conf conf/bblayers.conf.sample\" is a good way to visualise the changes.\n"

    # If we have a site.conf, check it's valid
    if check_conf_exists("conf/site.conf", e.data):
        current_sconf = data.getVar('SCONF_VERSION', e.data, True)
        sconf_version = data.getVar('SITE_CONF_VERSION', e.data, True)
        if current_sconf != sconf_version:
            messages = messages + "Your version of site.conf was generated from an older version of site.conf.sample and there have been updates made to this file. Please compare the two files and merge any changes before continuing.\nMatching the version numbers will remove this message.\n\"meld conf/site.conf conf/site.conf.sample\" is a good way to visualise the changes.\n"

    assume_provided = data.getVar('ASSUME_PROVIDED', e.data , True).split()
    # Check user doesn't have ASSUME_PROVIDED = instead of += in local.conf
    if "diffstat-native" not in assume_provided:
        messages = messages + 'Please use ASSUME_PROVIDED +=, not ASSUME_PROVIDED = in your local.conf\n'

    # Check that DL_DIR is set, exists and is writable. In theory, we should never even hit the check if DL_DIR isn't
    # set, since so much relies on it being set.
    dldir = data.getVar('DL_DIR', e.data, True)
    if not dldir:
        messages = messages + "DL_DIR is not set. Your environment is misconfigured, check that DL_DIR is set, and if the directory exists, that it is writable. \n"
    if os.path.exists(dldir) and not os.access(dldir, os.W_OK):
        messages = messages + "DL_DIR: %s exists but you do not appear to have write access to it. \n" % dldir

    # Check that the DISTRO is valid, if set
    # need to take into account DISTRO renaming DISTRO
    distro = data.getVar('DISTRO', e.data, True)
    if distro:
        if not ( check_conf_exists("conf/distro/poky.conf", e.data) or check_conf_exists("conf/distro/include/poky.inc", e.data) ):
            messages = messages + "DISTRO '%s' not found. Please set a valid DISTRO in your local.conf\n" % data.getVar("DISTRO", e.data, True )

    missing = ""

    if not check_app_exists("make", e.data):
        missing = missing + "GNU make,"

    if not check_app_exists('gcc', e.data):
        missing = missing + "C Compiler (%sgcc)," % data.getVar("BUILD_PREFIX", e.data, True)

    if not check_app_exists('g++', e.data):
        missing = missing + "C++ Compiler (%sg++)," % data.getVar("BUILD_PREFIX", e.data, True)

    required_utilities = e.data.getVar('SANITY_REQUIRED_UTILITIES', True)

    if "qemu-native" in assume_provided:
        if not check_app_exists("qemu-arm", e.data):
            messages = messages + "qemu-native was in ASSUME_PROVIDED but the QEMU binaries (qemu-arm) can't be found in PATH"

    if "." in data.getVar('PATH', e.data, True).split(":"):
        messages = messages + "PATH contains '.' which will break the build, please remove this"

    if data.getVar('TARGET_ARCH', e.data, True) == "arm":
        # This path is no longer user-readable in modern (very recent) Linux
        try:
            if os.path.exists("/proc/sys/vm/mmap_min_addr"):
                f = open("/proc/sys/vm/mmap_min_addr", "r")
                try:
                    if (int(f.read().strip()) > 65536):
                        messages = messages + "/proc/sys/vm/mmap_min_addr is not <= 65536. This will cause problems with qemu so please fix the value (as root).\n\nTo fix this in later reboots, set vm.mmap_min_addr = 65536 in /etc/sysctl.conf.\n"
                finally:
                    f.close()
        except:
            pass

    for util in required_utilities.split():
        if not check_app_exists( util, e.data ):
            missing = missing + "%s," % util

    if missing != "":
        missing = missing.rstrip(',')
        messages = messages + "Please install following missing utilities: %s\n" % missing

    pseudo_msg = check_pseudo_wrapper()
    if pseudo_msg != "":
        messages = messages + pseudo_msg + '\n'

    check_supported_distro(e)

    # Check if DISPLAY is set if IMAGETEST is set
    if not data.getVar( 'DISPLAY', e.data, True ) and data.getVar( 'IMAGETEST', e.data, True ) == 'qemu':
        messages = messages + 'qemuimagetest needs a X desktop to start qemu, please set DISPLAY correctly (e.g. DISPLAY=:1.0)\n'

    omask = os.umask(022)
    if omask & 0755:
        messages = messages + "Please use a umask which allows a+rx and u+rwx\n"
    os.umask(omask)

    oes_bb_conf = data.getVar( 'OES_BITBAKE_CONF', e.data, True )
    if not oes_bb_conf:
        messages = messages + 'You do not include OpenEmbeddeds version of conf/bitbake.conf. This means your environment is misconfigured, in particular check BBPATH.\n'

    nolibs = data.getVar('NO32LIBS', e.data, True)
    if not nolibs:
        lib32path = '/lib'
        if os.path.exists('/lib64') and ( os.path.islink('/lib64') or os.path.islink('/lib') ):
           lib32path = '/lib32'

        if os.path.exists('%s/libc.so.6' % lib32path) and not os.path.exists('/usr/include/gnu/stubs-32.h'):
            messages = messages + "You have a 32-bit libc, but no 32-bit headers.  You must install the 32-bit libc headers.\n"

    tmpdir = data.getVar('TMPDIR', e.data, True)
    sstate_dir = data.getVar('SSTATE_DIR', e.data, True)

    # Check saved sanity info
    last_sanity_version = 0
    last_tmpdir = ""
    last_sstate_dir = ""
    sanityverfile = 'conf/sanity_info'
    if os.path.exists(sanityverfile):
        f = file(sanityverfile, 'r')
        for line in f:
            if line.startswith('SANITY_VERSION'):
                last_sanity_version = int(line.split()[1])
            if line.startswith('TMPDIR'):
                last_tmpdir = line.split()[1]
            if line.startswith('SSTATE_DIR'):
                last_sstate_dir = line.split()[1]

    sanity_version = int(data.getVar('SANITY_VERSION', e.data, True) or 1)
    if last_sanity_version < sanity_version:
        messages = messages + check_sanity_version_change(e.data)
        messages = messages + check_sanity_tmpdir_change(tmpdir, e.data)
        messages = messages + check_sanity_sstate_dir_change(sstate_dir, e.data)
    else:
        if last_tmpdir != tmpdir:
            messages = messages + check_sanity_tmpdir_change(tmpdir, e.data)
        if last_sstate_dir != sstate_dir:
            messages = messages + check_sanity_sstate_dir_change(sstate_dir, e.data)

    if os.path.exists("conf"):
        f = file(sanityverfile, 'w')
        f.write("SANITY_VERSION %s\n" % sanity_version)
        f.write("TMPDIR %s\n" % tmpdir)
        f.write("SSTATE_DIR %s\n" % sstate_dir)

    #
    # Check that TMPDIR hasn't changed location since the last time we were run
    #
    checkfile = os.path.join(tmpdir, "saved_tmpdir")
    if os.path.exists(checkfile):
        f = file(checkfile, "r")
        saved_tmpdir = f.read().strip()
        if (saved_tmpdir != tmpdir):
            messages = messages + "Error, TMPDIR has changed location. You need to either move it back to %s or rebuild\n" % saved_tmpdir
    else:
        f = file(checkfile, "w")
        f.write(tmpdir)
    f.close()

    #
    # Check the 'ABI' of TMPDIR
    #
    current_abi = data.getVar('OELAYOUT_ABI', e.data, True)
    abifile = data.getVar('SANITY_ABIFILE', e.data, True)
    if os.path.exists(abifile):
        f = file(abifile, "r")
        abi = f.read().strip()
        if not abi.isdigit():
            f = file(abifile, "w")
            f.write(current_abi)
        elif abi == "2" and current_abi == "3":
            bb.note("Converting staging from layout version 2 to layout version 3")
            os.system(e.data.expand("mv /media/OE/poky/meta-ettus/recipes/hello/build/tmp/staging /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots"))
            os.system(e.data.expand("ln -s sysroots /media/OE/poky/meta-ettus/recipes/hello/build/tmp/staging"))
            os.system(e.data.expand("cd /media/OE/poky/meta-ettus/recipes/hello/build/tmp/stamps; for i in */*do_populate_staging; do new=`echo $i | sed -e 's/do_populate_staging/do_populate_sysroot/'`; mv $i $new; done"))
            f = file(abifile, "w")
            f.write(current_abi)
        elif abi == "3" and current_abi == "4":
            bb.note("Converting staging layout from version 3 to layout version 4")
            if os.path.exists(e.data.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux")):
                os.system(e.data.expand("mv /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin/crossscripts"))
                os.system(e.data.expand("ln -s /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/qemux86/usr/bin/crossscripts /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/usr/bin/i586-poky-linux"))

            f = file(abifile, "w")
            f.write(current_abi)
        elif abi == "4":
            messages = messages + "Staging layout has changed. The cross directory has been deprecated and cross packages are now built under the native sysroot.\nThis requires a rebuild.\n"
        elif abi == "5" and current_abi == "6":
            bb.note("Converting staging layout from version 5 to layout version 6")
            os.system(e.data.expand("mv /media/OE/poky/meta-ettus/recipes/hello/build/tmp/pstagelogs /media/OE/poky/meta-ettus/recipes/hello/build/tmp/sstate-control"))
            f = file(abifile, "w")
            f.write(current_abi)
        elif abi == "7" and current_abi == "8":
            messages = messages + "Your configuration is using stamp files including the sstate hash but your build directory was built with stamp files that do not include this.\nTo continue, either rebuild or switch back to the OEBasic signature handler with BB_SIGNATURE_HANDLER = 'OEBasic'.\n"
        elif (abi != current_abi):
            # Code to convert from one ABI to another could go here if possible.
            messages = messages + "Error, TMPDIR has changed its layout version number (%s to %s) and you need to either rebuild, revert or adjust it at your own risk.\n" % (abi, current_abi)
    else:
        f = file(abifile, "w")
        f.write(current_abi)
    f.close()

    oeroot = data.getVar('COREBASE', e.data)
    if oeroot.find ('+') != -1:
        messages = messages + "Error, you have an invalid character (+) in your COREBASE directory path. Please move the installation to a directory which doesn't include a +."
    elif oeroot.find (' ') != -1:
        messages = messages + "Error, you have a space in your COREBASE directory path. Please move the installation to a directory which doesn't include a space."

    if messages != "":
        raise_sanity_error(messages)
}


python generate_git_config () {
def generate_git_config(e):
        from bb import data

        if data.getVar('GIT_CORE_CONFIG', e.data, True):
                gitconfig_path = e.data.getVar('GIT_CONFIG', True)
                proxy_command = "    gitProxy = %s\n" % data.getVar('OE_GIT_PROXY_COMMAND', e.data, True)

                bb.mkdirhier(e.data.expand("/media/OE/poky/meta-ettus/recipes/hello/build/tmp/sysroots/x86_64-linux/etc"))
                if (os.path.exists(gitconfig_path)):
                        os.remove(gitconfig_path)

                f = open(gitconfig_path, 'w')
                f.write("[core]\n")
                ignore_hosts = data.getVar('GIT_PROXY_IGNORE', e.data, True).split()
                for ignore_host in ignore_hosts:
                        f.write("    gitProxy = none for %s\n" % ignore_host)
                f.write(proxy_command)
                f.close
}

